{
  "hash": "16c76ac90b047f3ef67e16edc5922c2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"16: Hypothesis Testing (1)\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-11-5\"\nformat:\n  html:\n    toc: true\n    theme: cerulean\n---\n\n\n\n# SML 201\n\n::: {.callout-note collapse=\"true\"}\n## Libraries and Helper Functions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"infer\")         #pipeline workflow for hypothesis testing\nlibrary(\"janitor\")       #compute proportions easily\nlibrary(\"moderndive\")    #textbook's package and data\nlibrary(\"patchwork\")     #easily let's me show graphs side-by-side\nlibrary(\"tidyverse\")     #the overall programming style universe\n\n# school colors\nprinceton_orange <- \"#E77500\"\nprinceton_black  <- \"#121212\"\n\n# data set: SML 201 demographics survey\ndemo_df <- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")\n\n# helper function\nvnorm <- function(x, mu = 0, sigma = 1, section = \"lower\"){\n  \n  # bell curve\n  x_vals <- seq(mu - 4*sigma, mu + 4*sigma, length.out = 201)\n  y_vals <- dnorm(x_vals, mu, sigma)\n  df_for_graph <- data.frame(x_vals, y_vals)\n\n  # outline shaded regions\n  if(length(x) == 1){\n    shade_left <- rbind(c(x[1],0), df_for_graph |>\n                        filter(x_vals < x[1]))\n    shade_right <- rbind(c(x[1],0), df_for_graph |>\n                        filter(x_vals > x[1]))\n  }\n  if(length(x) == 2){\n    shade_between <- rbind(c(x[1],0),\n                       df_for_graph |>\n                         filter(x_vals > x[1] &\n                                  x_vals < x[2]),\n                       c(x[2],0))\n    shade_tails <- rbind(df_for_graph |>\n                        filter(x_vals < x[1]),\n                     c(x[1],0),\n                     c(x[2],0),\n                     df_for_graph |>\n                        filter(x_vals > x[2]))\n  }\n  if(section == \"lower\"){\n    bell_curve <- df_for_graph |>\n      ggplot(aes(x_vals, y_vals)) +\n      geom_polygon(aes(x = x_vals, y = y_vals),\n                   data = shade_left,\n                   fill = \"#E77500\",) +\n      geom_line(color = \"gray50\", linewidth = 2)\n    prob_val <- round(pnorm(x,mu,sigma), 4)\n  }\n  if(section == \"upper\"){\n    bell_curve <- df_for_graph |>\n      ggplot(aes(x_vals, y_vals)) +\n      geom_polygon(aes(x = x_vals, y = y_vals),\n                   data = shade_right,\n                   fill = \"#E77500\",) +\n      geom_line(color = \"gray50\", linewidth = 2)\n    prob_val <- 1 - round(pnorm(x,mu,sigma), 4)\n  }\n  if(section == \"between\"){\n    bell_curve <- df_for_graph |>\n      ggplot(aes(x_vals, y_vals)) +\n      geom_polygon(aes(x = x_vals, y = y_vals),\n                   data = shade_between,\n                   fill = \"#E77500\",) +\n      geom_line(color = \"gray50\", linewidth = 2)\n    prob_val <- round(diff(pnorm(x,mu,sigma)), 4)\n  }\n  if(section == \"tails\"){\n    bell_curve <- df_for_graph |>\n      ggplot(aes(x_vals, y_vals)) +\n      geom_polygon(aes(x = x_vals, y = y_vals),\n                   data = shade_tails,\n                   fill = \"#E77500\",) +\n      geom_line(color = \"gray50\", linewidth = 2)\n    prob_val <- round(1 - diff(pnorm(x,mu,sigma)), 4)\n  }\n  \n  # plot bell curve\n  bell_curve + \n    labs(subtitle = paste0(\"Probability: \", prob_val),\n         caption = \"SML 201\", y = \"\") +\n    theme_minimal()\n}\n```\n:::\n\n\n\n:::\n\n## Start\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n* **Goal**: Explore hypothesis testing and one-sided tests\n\n* **Objective**: Deploy t-tests and null distributions\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"40%\"}\n\n:::\n\n::::\n\n\n# Case Study: Job Promotions\n\n::::: {.panel-tabset}\n\n## Data\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* data from a *Journal of Applied Psychology* study published in 1974\n* 48 bank supervisors asked to look at a resume\n* identical resume except the name at the top: 24 \"female\" names and 24 \"male\" names\n\n\n\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n![The Office same-picture meme](office_same_picture_meme.png)\n\nSource:  **Statistical Inference via Data Science:** *A Modern Dive into R and the Tidyverse*\n\n* Chapter 9: Hypothesis Testing\n* [https://moderndive.com/9-hypothesis-testing.html](https://moderndive.com/9-hypothesis-testing.html)\n\n:::\n\n::::\n\n## Glimpse\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20241104)\npromotions %>%\n  sample_n(size = 10) %>%\n  arrange(id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 Ã— 3\n      id decision gender\n   <int> <fct>    <fct> \n 1     6 promoted male  \n 2    15 promoted male  \n 3    24 promoted female\n 4    29 promoted female\n 5    32 promoted female\n 6    36 not      male  \n 7    39 not      female\n 8    41 not      female\n 9    45 not      female\n10    46 not      female\n```\n\n\n:::\n:::\n\n\n\n:::::\n\n## Stacked Bar Chart\n\n::::: {.panel-tabset}\n\n## plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions |>\n  ggplot(aes(x = gender)) +\n  geom_bar(aes(fill = decision),\n           stat = \"count\") +\n  labs(title = \"Bank Promotions Study\",\n       subtitle = \"Identical resumes except for applicant name\",\n       caption = \"Source: Journal of Applied Psychology\",\n       x = \"Gender of name on resume\") +\n  theme_minimal(base_size = 16)\n```\n:::\n\n\n\n:::::\n\n## Observed Proportions\n\n::::: {.panel-tabset}\n\n## Cross Tabulation\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n gender not promoted\n   male   3       21\n female  10       14\n```\n\n\n:::\n:::\n\n\n\n## percentages\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n gender    not promoted\n   male 12.50%   87.50%\n female 41.67%   58.33%\n```\n\n\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npromotions |>\n  tabyl(gender, decision) |>\n  adorn_percentages(\"row\") |>\n  adorn_pct_formatting(digits = 2)\n```\n:::\n\n\n\n:::::\n\n* male promotion rate: 21/24 = 0.875\n* female promotion rate: 14/24 = 0.583\n* *difference in rates*: 0.875 - 0.583 = 0.292\n\n$$\\hat{p}_{m} - \\hat{p}_{f} = 0.292$$\n\n## Permutation Test\n\n::: {.callout-important}\n## Key Observation\n\nIf `gender` did not matter when it comes to these job promotions, then it should not matter if we shuffle the `gender` labels in the data.\n:::\n\n## Shuffling\n\n::::: {.panel-tabset}\n\n## patchwork\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noriginal_bar_graph <- ggplot(promotions, aes(x = gender, fill = decision)) +\n  geom_bar() +\n  labs(title = \"original\",\n       x = \"Gender of name on resume\") +\n  theme(legend.position = \"none\")\n\ngender_shuffled <- promotions\n\nset.seed(20241104)\ngender_shuffled$gender <- sample(promotions$gender) \n#sampled without replacement\n\nshuffled_bar_graph <- gender_shuffled %>%\n  ggplot(aes(x = gender, fill = decision)) +\n  geom_bar() +\n  labs(title = \"shuffled\",\n       x = \"Gender of name on resume\")\n\n# patchwork\noriginal_bar_graph + shuffled_bar_graph\n```\n:::\n\n\n\n:::::\n\n\n# NHST Concepts\n\n::: {.callout-note collapse=\"true\"}\n## Terminology\n\n* In the previous session, we did a **bootstrap method** that used *sampling with replacement*\n* Here, we are performing a **permutation test** that uses *sampling without replacement*\n:::\n\n## Hypothesis Test of Proportions\n\n::::: {.panel-tabset}\n\n## 1\n\n\"First, a *hypothesis* is a statement about the value of an unknown population parameter. In our resume activity, our population parameter is the difference in population proportions $p_{m} - p_{f}$\"\n\n## 2\n\n\"Second, a hypothesis test consists of a test between two competing hypotheses ... Generally the *null hypothesis* is a claim that there really is 'no effect' or 'no difference.'\" Here our null hypothesis is\n\n* $H_{0}$: men and women are promoted at the same rate\n\n\"Generally the *alternative hypothesis* is the claim the experimenter or researcher wants to establish or find evidence for and is viewed as a 'challenger' hypothesis to the null hypothesis\".  Here our alternative hypothesis is\n\n* $H_{a}$: men are promoted at a higher rate than women\n\nIn math symbols, we have\n\n$$\\begin{array}{rrcl}\n  H_{o}: p_{m} - p_{f} & = & 0 \\\\\n  H_{a}: p_{m} - p_{f} & > & 0 \\\\\n\\end{array}$$\n\n## 3\n\n\"Third, a *test statistic* is a point estimate/sample statistic formula used for hypothesis testing, where a sample statistic is merely a summary statistic based on a sample of observations.\"  Here, our test statistic $\\hat{p}_{m} - \\hat{p}_{f}$ estimates the parameter of interest: the difference in population proportions $p_{m} - p_{f}$\n\n## 4\n\n\"Fourth, the observed test statistic is the value of the test statistic that we observed in real-life.\"  In this example the observed difference was\n\n$$\\hat{p}_{m} - \\hat{p}_{f} = 0.875 - 0.583 = 0.292$$\n\n## 5\n\n\"Fifth, the null distribution is the sampling distribution of the test statistic assuming the null hypothesis $H_0$ is true.\"\n\n## 6\n\n::: {.callout-tip}\n## p-value\n\n\"The **p-value** is the probability of obtaining a test statistic just as extreme or more extreme than the observed test statistic assuming the null hypothesis $H_0$ is true\"\n:::\n\n:::::\n\n# Modern NHST (infer)\n\n## Null Distribution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_distribution <- promotions %>% \n  specify(formula = decision ~ gender, success = \"promoted\") %>% \n  hypothesize(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(stat = \"diff in props\", order = c(\"male\", \"female\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_distribution |>\n  visualize(bins = 10)\n```\n\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n## Observed Difference\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# observed difference in proportions\nobs_diff_prop <- promotions %>% \n  specify(decision ~ gender, success = \"promoted\") %>% \n  calculate(stat = \"diff in props\", order = c(\"male\", \"female\"))\n#print(obs_diff_prop) #0.292\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_distribution |>\n  visualize(bins = 10) +\n  \n  # choices for direction are \"right\", \"left\", and \"both\"\n  shade_p_value(obs_stat = obs_diff_prop,\n                direction = \"right\")\n```\n\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n## p-value\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_distribution %>% \n  get_p_value(obs_stat = obs_diff_prop, \n              direction = \"right\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 1\n  p_value\n    <dbl>\n1   0.029\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n## When p-value < 0.05\n\nFor NHST (null hypothesis significance testing), many scientists compare the p-value to a significance level of $\\alpha = 0.05$.  Since the p-value < 0.05, we *reject the null hypothesis* of equal proportions of promotions among men and women.\n:::\n\n\n# Review: Confidence Intervals\n\n## Data Cleaning\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(demo_df$SAT)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0    1500    1540    1617    1560   15560      24 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nSAT_df <- demo_df |>\n  select(SAT) |>\n  filter(SAT >= 400 & SAT <= 1600)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(SAT_df$SAT)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1100    1500    1540    1516    1560    1600 \n```\n\n\n:::\n\n```{.r .cell-code}\n# observed sample mean: xbar = 1516\n```\n:::\n\n\n\n## Bootstrap Method\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20241104)\nbootstrap_distribution <- SAT_df |>\n  specify(response = SAT) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution |>\n  visualize() +\n  shade_ci(endpoints = bootstrap_distribution |>\n             get_ci(level = 0.95))\n```\n\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution |> get_ci(level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1    1499.    1530.\n```\n\n\n:::\n:::\n\n\n\nWe are 95 percent confident that the true average SAT score for a Princeton student is in between 1499 and 1530.\n\n\n# Old NHST (t-test)\n\n## Design\n\n* Colloquially: The average SAT score for a Princeton student is *above* 1510.\n* Null hypothesis: The average SAT score for a Princeton student *is* 1510.\n* Alternative hypothesis: The average SAT score for a Princeton student is *above* 1510.\n\n$$H_{0}: \\mu = 1510$$\n$$H_{a}: \\mu > 1510$$\n\n## Boxplot\n\n::::: {.panel-tabset}\n\n## Median\n\nUsually, the middle line in a boxplot corresponds to the sample median.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n## Mean\n\nThere is an option to change the middle line in a boxplot to refer to the sample mean (but this is rarely done in practice)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSAT_df |>\n  ggplot() +\n  geom_hline(yintercept = 1510, color = \"red\", linewidth = 3) +\n  geom_boxplot(aes(y = SAT),\n               middle = mean(SAT_df$SAT),\n               alpha = 0.5,\n               color = princeton_black,\n               fill = princeton_orange) +\n  labs(title = \"SAT Scores for Princeton Students\",\n       subtitle = \"middle line: mean\",\n       caption = \"Sample among SML 201 students\", \n       x = \"\", y = \"SAT score\") +\n  scale_y_continuous(limits = c(1400, 1600)) +\n  theme_minimal()\n```\n:::\n\n\n\n:::::\n\n## t statistic\n\n$$t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn      <- sum(!is.na(SAT_df$SAT))\nxbar   <- mean(SAT_df$SAT, na.rm = TRUE)\ns      <- sd(SAT_df$SAT, na.rm = TRUE)\nmu     <- 1510\nt_stat <- (xbar - mu) / (s/sqrt(n))\n```\n:::\n\n\n\n## Critical Region\n\n::::: {.panel-tabset}\n\n## plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# significance level: alpha = 0.05 ==> top 5 percentile\n# df: degrees of freedom\ncrit_value <- qt(0.95, df = n-1)\n\nvnorm(crit_value, section = \"upper\") +\n  labs(title = \"Critical Region\",\n       subtitle = \"One-sided hypothesis test\",\n       caption = \"SML 201\",\n       x = \"t distribution\")\n```\n:::\n\n\n\n## disclaimer\n\n::: {.callout-warning}\n## Normal Distribution Uusage\n\nWe used the normal distribution here in this example since\n\n* $n > 30$\n* The Central Limit Theorem said that sample distributions of the mean converge toward the normal distribution\n* Teacher Derek didn't have a t-distribution analogue for the `vnorm` helper function at this time.\n:::\n\n:::::\n\n## Comparison\n\n::::: {.panel-tabset}\n\n## plots\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-important}\n## Critical Region\n\nThat is, in order to *reject* the null hypothesis, we wanted the $t$ statistic to be inside of the critical region.\n:::\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- vnorm(crit_value, section = \"upper\") +\n  geom_vline(aes(xintercept = t_stat),\n             color = \"red\", linewidth = 2) +\n  labs(title = \"Critical Region\",\n       subtitle = \"One-sided hypothesis test\",\n       caption = \"SML 201\",\n       x = \"t distribution\") +\n  scale_x_continuous(breaks = t_stat,\n                     labels = \"t statistic\")\n\np2 <- vnorm(t_stat, section = \"upper\") +\n  geom_vline(aes(xintercept = t_stat),\n             color = \"red\", linewidth = 2) +\n  labs(title = \"p-value\",\n       subtitle = \"One-sided hypothesis test\",\n       caption = \"SML 201\",\n       x = \"t distribution\") +\n  scale_x_continuous(breaks = t_stat,\n                     labels = \"t statistic\")\n\n# patchwork\np1 + p2\n```\n:::\n\n\n\n:::::\n\n## t.test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(SAT_df$SAT, mu = 1510, alterative = \"greater\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  SAT_df$SAT\nt = 0.74335, df = 105, p-value = 0.4589\nalternative hypothesis: true mean is not equal to 1510\n95 percent confidence interval:\n 1500.719 1530.413\nsample estimates:\nmean of x \n 1515.566 \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n## When p-value > 0.05\n\nFor NHST (null hypothesis significance testing), many scientists compare the p-value to a significance level of $\\alpha = 0.05$.  Since the p-value > 0.05, we *fail to reject the null hypothesis* that the average SAT score of Princeton students is 1510.\n:::\n\n::: {.callout-warning}\n## Leaving the t distribution behind\n\nFor these calculations\n\n$$t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$$\n\n* rely more on *summary statistics* rather than all of the gathered data\n* \"degrees of freedom\" is a rather convoluted notion\n* t-distribution is itself an approximation\n* leads to more reliance on abstract probability distributions\n* departs from frequentist probability philosophy\n* more useful before calculators and computers\n:::\n\n\n# Modern NHST (infer)\n\n## Design\n\n* Colloquially: The average SAT score for a Princeton student is *above* 1500.\n* Null hypothesis: The average SAT score for a Princeton student is *at most* 1500.\n* Alternative hypothesis: The average SAT score for a Princeton student is *above* 1500.\n\n$$H_{0}: \\mu \\leq 1500$$\n$$H_{a}: \\mu > 1500$$\n\n## Bootstrap Distribution\n\nFor one-sided hypothesis tests, we still employ a bootstrap distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution <- SAT_df |>\n  specify(response = SAT) |>\n  hypothesize(null = \"point\", mu = 1500) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n```\n:::\n\n\n\n## Observed Stat\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_mean <- SAT_df |>\n  specify(response = SAT) |>\n  # hypothesize(null = \"point\", mu = 40) |>\n  # generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"mean\")\n```\n:::\n\n\n\n## p-value\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution |>\n  visualize() +\n  shade_p_value(obs_mean, direction = \"right\")\n```\n\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_distribution |>\n  get_p_value(obs_mean, direction = \"right\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 1\n  p_value\n    <dbl>\n1   0.012\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-important}\n## When p-value < 0.05\n\nSince the p-value < 0.05, we *reject the null hypothesis* that the average SAT score of Princeton students is at most 1500.\n:::\n\n\n# Inequalities in the Null Hypothesis\n\n$$H_{0}: \\mu \\leq 1500$$\n$$H_{a}: \\mu > 1500$$\n\nWriting null hypotheses with inequalities ($\\leq$ or $\\geq$() instead of an equals sign (=) is a relatively recent trend in textbooks.  Let is explore why we are doing this.\n\n::::: {.panel-tabset}\n\n## plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](16_NHST_one_sided_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n## code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_vals <- seq(1400, 1600, by = 5)\nN       <- length(mu_vals)\np_vals  <- rep(NA, N)\n\nobs_mean <- SAT_df |>\n  specify(response = SAT) |>\n  calculate(stat = \"mean\")\n\nfor(i in 1:N){\n  p_vals[i] <- SAT_df |>\n    specify(response = SAT) |>\n    hypothesize(null = \"point\", mu = mu_vals[i]) |>\n    generate(reps = 1000, type = \"bootstrap\") |>\n    calculate(stat = \"mean\") |>\n    get_p_value(obs_mean, direction = \"greater\") |>\n    pull()\n}\n\ndf_for_graph <- data.frame(mu_vals, p_vals)\ndf_for_graph |>\n  mutate(conclusion = ifelse(p_vals < 0.05,\n                             \"reject\", \"fail to reject\")) |>\n  ggplot() +\n  geom_point(aes(x = mu_vals, y = p_vals, color = conclusion),\n             size = 3) +\n  labs(title = \"Various Null Hypotheses\",\n       subtitle = \"Null hypotheses: mu <= mu_0\",\n       caption = \"SML 201\",\n       x = \"mu_0\", y = \"p-value\") +\n  theme_minimal()\n```\n:::\n\n\n\n:::::\n\n\n\n\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n* Precept 8\n* Historical Case Studies and Ethics \n* Project 3 (assigned Nov 11)\n* Exam 2 (December 5)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n![The Trading Gap Shuffle](null_distribution_meme.jpg)\n\n* image source: [The Simpsons](https://www.youtube.com/watch?v=kh2fONPkoAU)\n\n:::\n\n::::\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n## (optional) Additional Resources\n\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n [5] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n [9] ggplot2_3.5.1    tidyverse_2.0.0  patchwork_1.3.0  moderndive_0.7.0\n[13] janitor_2.2.0    infer_1.0.7     \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4           generics_0.1.3       stringi_1.8.4       \n [4] hms_1.1.3            digest_0.6.35        magrittr_2.0.3      \n [7] evaluate_1.0.1       grid_4.4.1           timechange_0.3.0    \n[10] fastmap_1.2.0        operator.tools_1.6.3 jsonlite_1.8.8      \n[13] backports_1.5.0      fansi_1.0.6          scales_1.3.0        \n[16] cli_3.6.3            crayon_1.5.3         rlang_1.1.4         \n[19] bit64_4.5.2          munsell_0.5.1        withr_3.0.2         \n[22] yaml_2.3.8           parallel_4.4.1       tools_4.4.1         \n[25] tzdb_0.4.0           colorspace_2.1-1     curl_5.2.3          \n[28] broom_1.0.7          vctrs_0.6.5          R6_2.5.1            \n[31] lifecycle_1.0.4      snakecase_0.11.1     bit_4.5.0           \n[34] htmlwidgets_1.6.4    vroom_1.6.5          pkgconfig_2.0.3     \n[37] pillar_1.9.0         gtable_0.3.5         glue_1.8.0          \n[40] xfun_0.48            tidyselect_1.2.1     rstudioapi_0.17.0   \n[43] knitr_1.48           farver_2.1.2         htmltools_0.5.8.1   \n[46] labeling_0.4.3       rmarkdown_2.28       formula.tools_1.7.1 \n[49] compiler_4.4.1      \n```\n\n\n:::\n:::\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Example Callout Block\n\n`note`, `tip`, `warning`, `caution`, or `important`\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::",
    "supporting": [
      "16_NHST_one_sided_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}