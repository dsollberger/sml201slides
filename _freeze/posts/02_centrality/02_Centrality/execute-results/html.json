{
  "hash": "1187ed7a0c2be29da35057e285655968",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"2: Centrality\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-09-05\"\n# format:\n#   revealjs:\n#     scrollable: true\nformat:\n  html:\n    toc: true\n---\n\n::: {.cell}\n\n:::\n\n\n# SML 201\n\n## Start\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* **Goal**: Summarize data by centrality\n\n* **Objective**: Compute mean, median, and mode\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n![The limit does not exist!](median_girls_meme.png)\n:::\n\n::::\n\n## Advice\n\n* create a folder on your computer desktop called \"SML 201\"\n\n    * later: place all code scripts and data sets in this folder\n    \n* open RStudio and create a new Quarto document\n\n    * `File` --> `New File` --> `Quarto Document ...`\n    * save the file into your `SML 201` folder\n    \n* To run a line of code, the keyboard short cut is\n\n    * Windows: CTRL + ENTER\n    * Mac: CMD + ENTER\n\n# Mean\n\n## Definition\n\nFor a list of data\n\n$$\\{a_{1}, a_{2}, ..., a_{n}\\}$$\n\nthe **mean** or **average** of the data is defined as\n\n$$\\bar{x} = \\displaystyle\\frac{1}{n}\\sum_{i = 1}^{n} a_{i}$$\nwhere \"x bar\" denotes a **sample mean**\n\n## In R\n\nRun each of these lines of code, and describe the code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsome_data <- c(32, 45, 16, 78, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)\n```\n:::\n\n\n## Missing Data\n\nRun each of these lines of code, and describe the code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsome_data <- c(32, 45, 16, 78, NA, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)\nmean(some_data, na.rm = TRUE)\n```\n:::\n\n\n\n# Median\n\nRun each of these lines of code, and describe the code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsome_data <- c(32, 45, 16, 78, 39)\nsort(some_data)\nmedian(some_data)\n\nsome_data2 <- c(32, 45, 16, 78, 39, 5)\nsort(some_data2)\nmedian(some_data2)\n```\n:::\n\n\n\n# Case Study: Weights of Olympians\n\n## Loading the Data\n\nI have supplied a couple of data sets to a GitHub repository to ease the loading of data for classroom work.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nolympic_df1 <- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv\")\nolympic_df2 <- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv\")\n```\n:::\n\n\n## Summary Statistics\n\nRun each of these lines of code, and describe the code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(olympic_df1$weight)\nmean(olympic_df1$weight, na.rm = TRUE)\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## The fix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nolympic_df1$weight[olympic_df1$weight <= 0] <- NA\nolympic_df2$weight[olympic_df2$weight <= 0] <- NA\n```\n:::\n\n\n:::\n\n\n# Case Study: Ages of Olympians\n\n## Filter\n\nFor this demonstration, let us focus on the athletes from Turkey.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTurkey_df1 <- olympic_df1 |>\n  filter(country_code == \"TUR\")\n```\n:::\n\n\n\n## Dotplot\n\nEarly in an introductory statistics course, a **dotplot** is useful for visualizing *integer* data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_1 <- mean(Turkey_df1$age, na.rm = TRUE)\n\nTurkey_df1 |>\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")\n```\n\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n## The Outlier\n\n:::: {.columns}\n\n::: {.column width=\"55%\"}\n![Yusuf Dikec](Yusuf_Dikec.png)\n\n* image source: News 18\n:::\n\n::: {.column width=\"5%\"}\n\t\n:::\n\n::: {.column width=\"40%\"}\n* Yusuf Dikec\n* Turkish sharpshooter\n\n    * silver medalist (2024 Olympics)\n    * 10m air pistol mixed team\n\n* Age: 51\n:::\n\n::::\n\n## Filtered Again\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTurkey_df2 <- olympic_df2 |>\n  filter(country_code == \"TUR\")\n```\n:::\n\n\n## Dotplot Revisited\n\nEarly in an introductory statistics course, a **dotplot** is useful for visualizing *integer* data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_1 <- mean(Turkey_df1$age, na.rm = TRUE)\nmean_2 <- mean(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |>\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  geom_vline(xintercept = mean_2, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")\n```\n\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Medians\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian_1 <- median(Turkey_df1$age, na.rm = TRUE)\nmedian_2 <- median(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |>\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = median_1, color = \"red\", linewidth = 3) +\n  geom_vline(xintercept = median_2, color = \"red\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"median in red\",\n       caption = \"SML 201\")\n```\n\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Difference in Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_1 - mean_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.92449\n```\n\n\n:::\n\n```{.r .cell-code}\nabs(mean_1 - mean_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.92449\n```\n\n\n:::\n:::\n\n\n## Difference in Medians\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian_1 - median_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\nabs(median_1 - median_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n## Punchline\n\n![Invincible](median_robust.png)\n\n* The median is *robust* against outliers!\n* image source: [Know Your Meme](https://knowyourmeme.com/memes/look-what-they-need-to-mimic-a-fraction-of-our-power)\n\n# Reporting\n\n## Why the mean?\n\nLater, we use the mean for:\n\n* normal distributions (\"bell curves\")\n* linear regression goes through center of mass\n* estimators and other statistical theory\n\n## Which do we use?\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n### When feasible, compute and report both the mean and median.\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"30%\"}\n![Why not both?](why_not_both.png)\n\n* image source: [Know Your Meme](https://knowyourmeme.com/memes/why-not-both-why-dont-we-have-both)\n:::\n\n::::\n\n\n# Side Quest: Median Stack\n\n:::: {.panel-tabset}\n\n## Computer Vision\n\n![RGB matrices](RBG_matrices.png)\n\n* image credit: Ben Mauss\n\n## Outlier Pixels\n\n![Salt and pepper noise](salt_and_pepper_noise.png)\n\n## Align Matrices\n\n![take many still photos](many_shots.png)\n\n## Median Stack Filter\n\n![apply a median!](median_stack_result.png)\n\n* source: [making people disappear from a photo](https://photofocus.com/software/photoshop-magic-making-people-disappear-from-a-scene/)\n\n::::\n\n# Application: Rolling Mean\n\n:::: {.panel-tabset}\n\n## Data \n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* source: [TidyTuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-12-03) (2019-12-03)\n\n* [Open Data Philly](https://opendataphilly.org/datasets/parking-violations/)\n\n    * filtered to year 2017 data that had latitude/longitude\t\n    \n* objective: summarize trends in ticketing\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n![Philadelphia Parking Authority](PPA.png)\n\n* image source: Matt Rourke/AP Photo\n:::\n\n::::\n\n## Wrangling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# i.e. started with a very large data set\n# and needed to pare it down\ntickets_raw <- readr::read_csv(\"tickets.csv\")\ntickets_days <- tickets_raw |>\n  separate(issue_datetime, sep = \" \",\n           into = c(\"date\", \"time\")) |>\n  group_by(date) |>\n  count(date) |>\n  ungroup() |>\n  select(date, n)\nreadr::write_csv(tickets_days, \"tickets_days.csv\")\n\ntickets_df <- readr::read_csv(\"tickets_days.csv\")\n```\n:::\n\n\n\n::::\n\n## Time Series\n\n:::: {.panel-tabset}\n\n## Viz\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntickets_df |>\n  ggplot(aes(x = date, y = n)) +\n  geom_line() +\n  labs(title = \"Parking Tickets in Philadelphia\",\n       subtitle = \"Street Sweeping Violations (2017)\",\n       caption = \"Source: Open Data Philly\",\n       y = \"number of tickets\") +\n  theme_minimal()\n```\n:::\n\n\n::::\n\n## Moving Average\n\n:::: {.panel-tabset}\n\n## Concept\n\nA **rolling mean** or **moving average** compues the mean across a group of $L$ (lag) consecutive data points in a time series and slides the \"window\".\n\n## 3\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## 5\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## 7\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## 9\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## 11\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntickets_df |>\n  mutate(roll_mean = zoo::rollapply(\n    n, 3, mean, align = 'left', fill = NA\n  )) |>\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_mean),\n            color = \"blue\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling mean in blue (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()\n```\n:::\n\n\n::::\n\n## Rolling Median\n\n:::: {.panel-tabset}\n\n## 3\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n## 5\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## 7\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n## 9\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## 11\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](02_Centrality_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntickets_df |>\n  mutate(roll_mean = zoo::rollapply(\n    n, 3, median, align = 'left', fill = NA\n  )) |>\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_mean),\n            color = \"red\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling median in red (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()\n```\n:::\n\n\n::::\n\n# Mode\n\nIt appears that `R` doesn't have a built-in function to compute a statistical mode, so programmers over the years employed a user-defined function, such as the one found [here](https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode)\n\nRun each of these lines of code, and describe the code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmode_of_data <- function(x) {\n  ux <- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nsome_data_2 <- c(1, 3, 5, 7, 7, 9)\nmode_of_data(some_data_2)\n\nsome_data_3 <- c(1, 3, 3, 5, 7, 7, 9)\nmode_of_data(some_data_3)\n```\n:::\n\n\nIn that thread, there was an even better function for computing the mode.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmode_of_data <- function(x) {\n  ux <- unique(x)\n  tab <- tabulate(match(x, ux))\n  ux[tab == max(tab)]\n}\n\nsome_data_2 <- c(1, 3, 5, 7, 7, 9)\nmode_of_data(some_data_2)\n\nsome_data_3 <- c(1, 3, 3, 5, 7, 7, 9)\nmode_of_data(some_data_3)\n```\n:::\n\n\n\n\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* Assignments:\n\n    * Software Installation\n    * Precept 1\n    * CLO Assessment\n    * Demographics Survey\n    * BLT0910\n    \n* Project 1:\n\n    * assigned: Sept 23\n    * due: Oct 2\n    \n* Exam 1: Oct 10\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n![](statistics_rhyme.png)\n:::\n\n::::\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n## (optional) How the data set was altered\n\nI altered the following `olympics_data.csv` to make classroom demonstrations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nQ <- readr::read_csv(\"athletes.csv\")\nQ$weight[Q$weight <=0] <- -99 #imitate old-fashioned missing value recording\nQ$age <- lubridate::year(\"2024-07-26\") - lubridate::year(Q$birth_date)\nW <- Q |> dplyr::filter(age <= 30)\nreadr::write_csv(Q, \"olympic_data2.csv\")\nreadr::write_csv(W, \"olympic_data.csv\")\n```\n:::\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources\n\n* great explanation of a [moving average](https://www.ablebits.com/office-addins-blog/moving-average-excel/)\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.0 (2024-04-24 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] zoo_1.8-12      lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n [5] hms_1.1.3         digest_0.6.35     magrittr_2.0.3    evaluate_0.24.0  \n [9] grid_4.4.0        timechange_0.3.0  fastmap_1.2.0     jsonlite_1.8.8   \n[13] fansi_1.0.6       scales_1.3.0      cli_3.6.2         rlang_1.1.4      \n[17] crayon_1.5.3      bit64_4.0.5       munsell_0.5.1     withr_3.0.1      \n[21] yaml_2.3.8        tools_4.4.0       parallel_4.4.0    tzdb_0.4.0       \n[25] colorspace_2.1-1  vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n[29] htmlwidgets_1.6.4 bit_4.0.5         vroom_1.6.5       pkgconfig_2.0.3  \n[33] archive_1.1.8     pillar_1.9.0      gtable_0.3.5      glue_1.7.0       \n[37] xfun_0.44         tidyselect_1.2.1  rstudioapi_0.16.0 knitr_1.48       \n[41] farver_2.1.2      htmltools_0.5.8.1 rmarkdown_2.27    labeling_0.4.3   \n[45] compiler_4.4.0   \n```\n\n\n:::\n:::\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n:::: {.panel-tabset}\n\n\n\n::::",
    "supporting": [
      "02_Centrality_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}