{
  "hash": "329600a1d3e61d7f57539e535cb113a9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"4: Categories\"\nauthor: \"Derek Sollberger\"\ndate: \"2025-02-05\"\n# format:\n#   revealjs:\n#     scrollable: true\nformat:\n  html:\n    toc: true\n---\n\n# SML 201\n\n## Start\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* **Goal**: Explore data wrangling with categorical variables\n\n* **Objective**: Compute counts, make bar graphs, and discuss data\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n![demographics survey](short_names.png)\n:::\n\n::::\n\n# First Glance\n\n## Obtaining the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tidyverse\")\n\n# downloading data directly from Derek's (online) GitHub repository\n# demo_df <- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/data/demographics_data.csv.csv\")\n\n# or if you have the file also in your SML 201 folder\ndemo_df <- readr::read_csv(\"demographics_data.csv\")\n```\n:::\n\n\n## Quick Exploration\n\n:::: {.panel-tabset}\n\n### head\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(demo_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 89\n  course  stats_background   class_standing num_courses_past major            \n  <chr>   <chr>              <chr>                     <dbl> <chr>            \n1 SML 201 No                 Senior                       31 Chemistry        \n2 SML 201 No                 Sophomore                    14 Molecular Biology\n3 SML 201 No                 Sophomore                    12 Molecular Biology\n4 SML 201 Yes: AP Statistics Sophomore                    12 Anthropology     \n5 SML 201 No                 Sophomore                    14 Neuroscience     \n6 SML 201 Yes: AP Statistics Sophomore                    13 Molecular Biology\n# ℹ 84 more variables: residential_college <chr>, dining_hall <chr>,\n#   GPA_uni <dbl>, gender <chr>, hours_study <dbl>, birth_month <chr>,\n#   age <dbl>, height <dbl>, shoe_size <dbl>, weight <dbl>, calories <dbl>,\n#   exercise <dbl>, sleep_start <chr>, sleep_duration <dbl>,\n#   social_media <chr>, smart_phones <chr>, baseball <chr>, football <chr>,\n#   basketball <chr>, hockey <chr>, politics <dbl>, religious <dbl>,\n#   sexuality <chr>, happiness_campus <dbl>, happiness_city <dbl>, …\n```\n\n\n:::\n:::\n\n\n### structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(demo_df, give.attr = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspc_tbl_ [161 × 89] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ course               : chr [1:161] \"SML 201\" \"SML 201\" \"SML 201\" \"SML 201\" ...\n $ stats_background     : chr [1:161] \"No\" \"No\" \"No\" \"Yes: AP Statistics\" ...\n $ class_standing       : chr [1:161] \"Senior\" \"Sophomore\" \"Sophomore\" \"Sophomore\" ...\n $ num_courses_past     : num [1:161] 31 14 12 12 14 13 16 22 NA 21 ...\n $ major                : chr [1:161] \"Chemistry\" \"Molecular Biology\" \"Molecular Biology\" \"Anthropology\" ...\n $ residential_college  : chr [1:161] \"Yeh College\" \"Mathey\" \"Rockefeller\" \"Rockefeller\" ...\n $ dining_hall          : chr [1:161] \"Yeh\" \"Yeh\" \"Yeh\" \"Whitman\" ...\n $ GPA_uni              : num [1:161] NA NA NA 3.89 3.5 3.35 NA 3.9 4 NA ...\n $ gender               : chr [1:161] \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ hours_study          : num [1:161] 24 NA NA 21 10 15 NA 20 60 NA ...\n $ birth_month          : chr [1:161] \"August\" \"August\" \"July\" \"January\" ...\n $ age                  : num [1:161] 21 20 19 19 19 20 19 20 18 20 ...\n $ height               : num [1:161] 70 67 NA 71 52 61 63 69 64 62 ...\n $ shoe_size            : num [1:161] 9.5 6.5 5 11 7.5 6 7.5 10.5 7 NA ...\n $ weight               : num [1:161] 160 115 130 172 128 105 NA 135 120 NA ...\n $ calories             : num [1:161] 1200 NA 1500 3000 1200 1500 NA 2200 1500 NA ...\n $ exercise             : num [1:161] 5 8 2 8 2 1 NA 7 2 NA ...\n $ sleep_start          : chr [1:161] \"2 AM\" \"12 midnight\" \"1 AM\" \"12 midnight\" ...\n $ sleep_duration       : num [1:161] 7 7 6 7 5 7 6 8 8 NA ...\n $ social_media         : chr [1:161] \"Instagram\" \"Instagram\" \"Instagram\" \"Instagram\" ...\n $ smart_phones         : chr [1:161] \"iPhone\" \"iPhone\" \"iPhone\" \"iPhone\" ...\n $ baseball             : chr [1:161] \"Los Angeles Dodgers\" \"Texas Rangers\" NA \"Pittsburgh Pirates\" ...\n $ football             : chr [1:161] NA \"Dallas Cowboys\" NA \"Pittsburgh Steelers\" ...\n $ basketball           : chr [1:161] \"Los Angeles Lakers\" \"Dallas Mavericks\" NA \"Los Angeles Lakers\" ...\n $ hockey               : chr [1:161] NA \"Dallas Stars\" NA \"Pittsburgh Penguins\" ...\n $ politics             : num [1:161] 37 NA 0 10 100 30 NA 50 30 NA ...\n $ religious            : num [1:161] 20 80 60 30 29 75 NA 90 50 0 ...\n $ sexuality            : chr [1:161] \"0\" \"0\" \"0\" \"5\" ...\n $ happiness_campus     : num [1:161] 90 92 100 90 67 70 NA 90 40 NA ...\n $ happiness_city       : num [1:161] 90 85 80 60 8 30 NA 90 30 NA ...\n $ anxious_201          : num [1:161] 30 35 100 30 78 80 NA 25 80 NA ...\n $ high_school_type     : chr [1:161] \"public school\" \"private school\" \"private school\" \"public school\" ...\n $ college_transition   : num [1:161] 70 NA 50 50 67 80 NA 75 60 NA ...\n $ drug_use             : chr [1:161] \"No\" \"No\" \"No\" \"Yes\" ...\n $ first_generation     : chr [1:161] \"No\" \"No\" \"Yes\" \"No\" ...\n $ languages_spoken     : num [1:161] 1.2 1 2 1.5 2.3 3 2 2.5 1.7 NA ...\n $ making_friends       : num [1:161] 90 90 60 70 59 80 NA 50 20 NA ...\n $ campus_sports        : chr [1:161] \"Yes: intramural team\" \"Yes: athletic scholarship\" \"No\" \"Yes: intramural team\" ...\n $ office_hours         : num [1:161] 90 75 50 100 87 60 NA 90 70 NA ...\n $ study_groups         : num [1:161] 50 80 80 40 89 60 NA 90 0 NA ...\n $ financial_planning   : chr [1:161] \"Yes\" \"No\" \"No\" \"Yes\" ...\n $ happiness            : num [1:161] 85 90 70 70 78 70 NA 90 50 NA ...\n $ intelligence         : num [1:161] 70 80 60 90 99 80 NA 80 50 NA ...\n $ attractiveness       : num [1:161] 45 NA 60 75 100 70 NA 65 30 NA ...\n $ favorite_color       : chr [1:161] \"blue\" \"Purple\" \"pink\" \"green\" ...\n $ favorite_number      : num [1:161] 4 37 11 6 11 10 7 7 27 NA ...\n $ showering            : num [1:161] 7 9 7 7 7 11 NA 7 7 NA ...\n $ brushing_teeth       : num [1:161] 13 NA 7 14 14 14 14 14 14 14 ...\n $ flossing             : num [1:161] 0 NA 2 0 7 7 7 7 14 7 ...\n $ hair_washing         : num [1:161] 7 3 3 7 1 2 NA 7 1 NA ...\n $ water_drinking       : num [1:161] 2 NA 3 18 2 2 NA 10 30 NA ...\n $ financial_aid        : num [1:161] 0 NA 70 100 100 80 100 50 0 NA ...\n $ future_career        : num [1:161] 70 70 80 80 0 90 NA 90 50 NA ...\n $ siblings             : num [1:161] 1 2 2 1 4 4 NA 1 3 1 ...\n $ favorite_movie       : chr [1:161] \"Star Wars\" NA \"Dead Poets Society\" \"hunger games \" ...\n $ loneliness           : num [1:161] 40 NA 50 20 50 70 NA 30 40 NA ...\n $ organized            : num [1:161] 75 NA 70 80 38 40 NA 80 50 NA ...\n $ GPA_HS               : num [1:161] NA NA NA 4 4 3.9 4 4 4 NA ...\n $ SAT                  : num [1:161] NA NA NA 1540 NA 1510 NA 1560 1570 NA ...\n $ social_active        : num [1:161] 55 NA 70 60 37 60 NA 80 40 NA ...\n $ num_friends          : num [1:161] 20 NA 15 25 7 5 NA 20 4 NA ...\n $ music_studying       : chr [1:161] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ family_influence     : num [1:161] 0 NA NA 30 50 50 NA 50 30 NA ...\n $ living_on_campus     : chr [1:161] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ college_job          : chr [1:161] \"No\" \"No\" \"No\" \"No\" ...\n $ campus_groups        : chr [1:161] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ attendance           : num [1:161] 70 98 95 99 98 100 NA 90 100 NA ...\n $ pancakes_waffles     : chr [1:161] \"waffles\" \"pancakes\" \"pancakes\" \"waffles\" ...\n $ coffee_tea           : chr [1:161] \"tea\" \"(neither)\" \"tea\" \"coffee\" ...\n $ dogs_cats            : chr [1:161] \"cats\" \"dogs\" \"dogs\" \"dogs\" ...\n $ ocean_snow           : chr [1:161] \"ocean\" \"ocean\" \"ocean\" \"ocean\" ...\n $ pineapple_pizza      : chr [1:161] \"tolerable\" NA \"No!\" \"No!\" ...\n $ spicy_food           : num [1:161] 3 NA NA 3 6 4 NA 4 5 NA ...\n $ campus_acceptance    : num [1:161] 100 90 NA 70 67 70 NA 90 70 NA ...\n $ social_media_duration: num [1:161] 7 NA 3 3 7 5 NA 3 0 NA ...\n $ continents           : num [1:161] 3 2 NA 2 2 1 NA 3 6 2 ...\n $ superhero            : chr [1:161] \"Spider-Man\" NA NA \"green arrow \" ...\n $ supervillain         : chr [1:161] \"Doctor Doom\" NA NA \"octoman\" ...\n $ season               : chr [1:161] \"Spring\" \"Fall\" \"Fall\" \"Summer\" ...\n $ handedness           : chr [1:161] \"right-handed\" \"right-handed\" \"right-handed\" \"left-handed\" ...\n $ musical              : chr [1:161] \"No\" \"Yes, casually\" \"Yes, casually\" \"No\" ...\n $ campus_safety        : num [1:161] 90 NA 80 100 98 90 NA 95 70 NA ...\n $ campus_resources     : num [1:161] 70 NA 80 80 89 70 NA 100 60 NA ...\n $ laundry              : num [1:161] 2 NA 4 5 4 1 NA 4 2 NA ...\n $ favorite_class       : chr [1:161] \"EAS 224\" NA NA \"FRS 135\" ...\n $ favorite_teacher     : chr [1:161] \"Dr. VanderKam\" NA NA \"Susanna Moore \" ...\n $ uni_applied          : num [1:161] 20 1 21 2 NA 10 10 17 3 19 ...\n $ gap_year             : chr [1:161] \"No\" \"No\" \"No\" \"No\" ...\n $ survey_comfort       : num [1:161] 90 90 60 100 67 40 NA 100 50 NA ...\n```\n\n\n:::\n:::\n\n\n### column names\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(demo_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"course\"                \"stats_background\"      \"class_standing\"       \n [4] \"num_courses_past\"      \"major\"                 \"residential_college\"  \n [7] \"dining_hall\"           \"GPA_uni\"               \"gender\"               \n[10] \"hours_study\"           \"birth_month\"           \"age\"                  \n[13] \"height\"                \"shoe_size\"             \"weight\"               \n[16] \"calories\"              \"exercise\"              \"sleep_start\"          \n[19] \"sleep_duration\"        \"social_media\"          \"smart_phones\"         \n[22] \"baseball\"              \"football\"              \"basketball\"           \n[25] \"hockey\"                \"politics\"              \"religious\"            \n[28] \"sexuality\"             \"happiness_campus\"      \"happiness_city\"       \n[31] \"anxious_201\"           \"high_school_type\"      \"college_transition\"   \n[34] \"drug_use\"              \"first_generation\"      \"languages_spoken\"     \n[37] \"making_friends\"        \"campus_sports\"         \"office_hours\"         \n[40] \"study_groups\"          \"financial_planning\"    \"happiness\"            \n[43] \"intelligence\"          \"attractiveness\"        \"favorite_color\"       \n[46] \"favorite_number\"       \"showering\"             \"brushing_teeth\"       \n[49] \"flossing\"              \"hair_washing\"          \"water_drinking\"       \n[52] \"financial_aid\"         \"future_career\"         \"siblings\"             \n[55] \"favorite_movie\"        \"loneliness\"            \"organized\"            \n[58] \"GPA_HS\"                \"SAT\"                   \"social_active\"        \n[61] \"num_friends\"           \"music_studying\"        \"family_influence\"     \n[64] \"living_on_campus\"      \"college_job\"           \"campus_groups\"        \n[67] \"attendance\"            \"pancakes_waffles\"      \"coffee_tea\"           \n[70] \"dogs_cats\"             \"ocean_snow\"            \"pineapple_pizza\"      \n[73] \"spicy_food\"            \"campus_acceptance\"     \"social_media_duration\"\n[76] \"continents\"            \"superhero\"             \"supervillain\"         \n[79] \"season\"                \"handedness\"            \"musical\"              \n[82] \"campus_safety\"         \"campus_resources\"      \"laundry\"              \n[85] \"favorite_class\"        \"favorite_teacher\"      \"uni_applied\"          \n[88] \"gap_year\"              \"survey_comfort\"       \n```\n\n\n:::\n:::\n\n\n::::\n\n## Preprocessing\n\n::: {.callout-note collapse=\"true\"}\n### Here is how the data was cleaned\n\n* Advice: you should understand each part of this code by the first exam.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_raw <- readr::read_csv(\"Demographics Survey Survey Student Analysis Report.csv\",\n                          col_names = FALSE, skip = 1)\n\nshort_names <- c(\"course\", \"stats_background\", \"class_standing\",\n                 \"num_courses_past\", \"major\", \"minor1\",\n                 \"minor2\", \"residential_college\", \"dining_hall\",\n                 \"GPA_uni\", \"gender\", \"ethnicity\",\n                 \"hours_study\", \"birth_month\", \"age\",\n                 \"height\", \"shoe_size\", \"weight\",\n                 \"calories\", \"exercise\", \"sleep_start\",\n                 \"sleep_duration\", \"social_media\", \"smart_phones\",\n                 \"baseball\", \"football\", \"basketball\", \n                 \"hockey\", \"politics\", \"religious\",\n                 \"sexuality\", \"happiness_campus\", \"happiness_city\",\n                 \"anxious_201\", \"high_school_type\", \"college_transition\",\n                 \"drug_use\", \"first_generation\", \"languages_spoken\",\n                 \"making_friends\", \"campus_sports\", \"office_hours\",\n                 \"study_groups\", \"financial_planning\", \"happiness\",\n                 \"intelligence\", \"attractiveness\", \"favorite_color\",\n                 \"favorite_number\", \"showering\", \"brushing_teeth\",\n                 \"flossing\", \"hair_washing\", \"water_drinking\",\n                 \"financial_aid\", \"future_career\", \"siblings\",\n                 \"favorite_movie\", \"loneliness\", \"organized\",\n                 \"GPA_HS\", \"SAT\", \"social_active\",\n                 \"num_friends\", \"music_studying\", \"family_influence\",\n                 \"living_on_campus\", \"college_job\", \"campus_groups\",\n                 \"attendance\", \"pancakes_waffles\", \"coffee_tea\",\n                 \"dogs_cats\", \"ocean_snow\", \"pineapple_pizza\",\n                 \"spicy_food\", \"campus_acceptance\", \"social_media_duration\",\n                 \"continents\", \"superhero\", \"supervillain\",\n                 \"season\", \"handedness\", \"musical\",\n                 \"campus_safety\", \"campus_resources\", \"laundry\",\n                 \"favorite_class\", \"favorite_teacher\", \"uni_applied\",\n                 \"uni_accepted\", \"gap_year\", \"survey_comfort\", \n                 \"additional_questions\"\n                 )\n\ndemo_df <- demo_raw |>\n  # remove student names and Canvas metadeta\n  select(seq(9, 193, 2)) |>\n\n  # apply short column names (i.e. ease programming)\n  setNames(short_names) |>\n  \n  # shuffle all rows (i.e. no longer alphabetical by student name)\n  sample_frac(1.0) |>\n  \n  # mask majors who are underrepresented\n  group_by(major) |>\n  mutate(majorCount = n()) |>\n  ungroup() |>\n  mutate(major = ifelse(majorCount >= 3, major, \"other\")) |>\n  select(-majorCount) |>\n  \n  # remove other possible ID factors\n  select(-c(ethnicity, minor1, minor2, uni_accepted)) |>\n  mutate(age = ifelse(age < 19 | age > 21, NA, age)) |>\n  mutate(class_standing = ifelse(class_standing %in% c(\"Sophomore\", \"Junior\", \"Senior\"), class_standing, \"Senior\")) |>\n  mutate(gender = ifelse(gender %in% c(\"Female\", \"Male\"), gender, NA)) |>\n  mutate(num_courses_past = ifelse(num_courses_past < 10, NA, num_courses_past)) |>\n  \n  # remove outliers\n  mutate(GPA_uni = ifelse(GPA_uni < 2 | GPA_uni > 4, NA, GPA_uni)) |>\n  mutate(GPA_HS = ifelse(GPA_HS < 3 | GPA_HS > 4, NA, GPA_HS)) |>\n  mutate(SAT = ifelse(SAT < 1200 | SAT > 1600, NA, SAT)) |>\n  mutate(politics = ifelse(politics < 0, 0, politics)) |>\n  mutate(politics = ifelse(politics > 100, 100, politics)) |>\n  mutate(siblings = ifelse(siblings > 4, 4, siblings)) |>\n  mutate(spicy_food = ifelse(spicy_food > 7, 7, spicy_food))\n\nreadr::write_csv(demo_df, \"demographics_data..csv\")\n```\n:::\n\n:::\n\n::: {.callout-warning}\n# DCP1\n:::\n\n# Queries\n\n:::: {.columns}\n\n::: {.column width=\"20%\"}\nFor the *Demographics Survey*, here are the variable names that represent the responses to the survey questions.\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"70%\"}\n![demographics survey](short_names.png)\n:::\n\n::::\n\n## Numerical Summary\n\n\"On a scale from 0 to 100---with 0 = very anxious and 100 = comfortable---how comfortable were you taking this survey?\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(demo_df$survey_comfort)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   71.25   90.00   84.62  100.00  100.00      15 \n```\n\n\n:::\n:::\n\n\n## Categorical Summary\n\n\"What is your favorite season?\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(demo_df$season)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Fall Spring Summer Winter \n    48     43     59      6 \n```\n\n\n:::\n:::\n\n\n## Cross-Tabulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(demo_df$season, demo_df$gap_year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        \n         No Yes\n  Fall   43   4\n  Spring 38   3\n  Summer 51   6\n  Winter  6   0\n```\n\n\n:::\n:::\n\n\n::: {.callout-warning}\n# DCP2\n:::\n\n## Numerical Across a Category\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_df |>\n  group_by(gap_year) |>\n  summarize(avg_age = mean(age, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  gap_year avg_age\n  <chr>      <dbl>\n1 No          19.5\n2 Yes         20.8\n3 <NA>        19.8\n```\n\n\n:::\n:::\n\n\n## Seeking Proportions\n\n\"Did you take a gap year?\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# carefully defining denominator without missing values\nn <- sum(!is.na(demo_df$gap_year))\ntable(demo_df$gap_year) / n\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n        No        Yes \n0.90967742 0.09032258 \n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(demo_df$gap_year == \"Yes\", na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.09032258\n```\n\n\n:::\n:::\n\n\n## Bar Chart --- Count\n\n\"Do you play a musical instrument(s)?\"\n\n* Later: discern difference between `stat = \"count\"` and `stat = \"identity\"`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_df |>\n  # filter(!is.na(musical)) |>\n  ggplot(aes(x = musical)) +\n  geom_bar(color = \"black\", fill = \"green\", stat = \"count\") +\n  labs(title = \"Do you play a musical instrument(s)?\",\n       subtitle = \"SML 201, Spring 2026\",\n       x = \"\",\n       y = \"count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](04_categories_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n## Most Represented Major by Residential College\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_df |>\n  group_by(residential_college, major) |>\n  mutate(major_count = n()) |>\n  ungroup() |>\n  group_by(residential_college) |>\n  filter(major_count == max(major_count)) |>\n  ungroup() |>\n  select(residential_college, major) |>\n  distinct() |>\n  arrange(residential_college)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   residential_college major                                               \n   <chr>               <chr>                                               \n 1 Butler              Neuroscience                                        \n 2 Butler              Molecular Biology                                   \n 3 Forbes              Princeton School of Public and International Affairs\n 4 Forbes              Molecular Biology                                   \n 5 Forbes              Neuroscience                                        \n 6 Mathey              Molecular Biology                                   \n 7 New College West    Neuroscience                                        \n 8 Rockefeller         Molecular Biology                                   \n 9 Whitman             Molecular Biology                                   \n10 Yeh College         Molecular Biology                                   \n```\n\n\n:::\n:::\n\n\n::: {.callout-warning}\n# DCP3\n:::\n\n\n# Case Study: AI Detection\n\nSuppose that we had a controlled experiment where we\n\n* asked students to write an essay\n\n    * without extra assistance (\"not cheat\")\n    * with chatbot assistance (\"cheat\")\n\n* then asked an AI detection bot to try to detect each essay as AI assisted or not.\n\n::: {.callout-note collapse=\"true\"}\n## Creating Synthetic Data\n\n* Advice: you should understand each part of this code by the second exam\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(201) #supress randomization\nessay_cheat <- sample(c(TRUE, FALSE), \n                      size = 201,\n                      prob = c(0.45, 0.55), \n                      replace = TRUE)\ndetect_cheat <- sample(c(TRUE, FALSE),\n                       size = 201,\n                       prob = c(0.75, 0.25),\n                       replace = TRUE)\n\n# make data frame\nbot_df <- data.frame(student_id = 1:201,\n                     essay_cheat,\n                     detect_cheat)\n```\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(bot_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  student_id essay_cheat detect_cheat\n1          1        TRUE         TRUE\n2          2       FALSE         TRUE\n3          3       FALSE         TRUE\n4          4       FALSE        FALSE\n5          5        TRUE        FALSE\n6          6       FALSE         TRUE\n```\n\n\n:::\n:::\n\n\n## Outcomes\n\n### Logical AND\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbot_df <- bot_df |>\n  mutate(outcome = case_when(\n    essay_cheat & detect_cheat ~ \"true positive\",\n    !essay_cheat & detect_cheat ~ \"false positive\",\n    essay_cheat & !detect_cheat ~ \"false negative\",\n    !essay_cheat & !detect_cheat ~ \"true negative\",\n    TRUE ~ \"unknown classification\"\n  ))\n```\n:::\n\n\n## Counts\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTP <- sum(bot_df$outcome == \"true positive\")\nTN <- sum(bot_df$outcome == \"true negative\")\nFP <- sum(bot_df$outcome == \"false positive\")\nFN <- sum(bot_df$outcome == \"false negative\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(bot_df$essay_cheat, bot_df$detect_cheat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n        FALSE TRUE\n  FALSE    32   87\n  TRUE     25   57\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(paste0(\"There were \", TP, \" true positives\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"There were 57 true positives\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(paste0(\"There were \", TN, \" true negatives\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"There were 32 true negatives\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(paste0(\"There were \", FP, \" false positives\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"There were 87 false positives\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(paste0(\"There were \", FN, \" false negatives\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"There were 25 false negatives\"\n```\n\n\n:::\n:::\n\n\n\n\n## Metrics\n\n### Logical OR\n\n::: {.callout-note}\n### Accuracy\n\n**Accuracy** is the ratio of true positives OR true negatives over all outcomes\n\n$$\\text{accuracy} = \\frac{TP + TN}{TP + FP + FN + TN}$$\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# accuracy = (TP + TN) / (TP + FP + FN + TN)\naccuracy <- mean(bot_df$outcome == \"true positive\" |\n               bot_df$outcome == \"true negative\")\nprint(round(accuracy, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.44\n```\n\n\n:::\n:::\n\n* This AI bot made correct classifications 44 percent of the time.\n\n\n### Precision\n\n$$\\text{precision} = \\frac{TP}{TP + FP}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecision = TP / (TP + FP)\nprint(round(precision, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4\n```\n\n\n:::\n:::\n\n* Out of all of the essays were participants intentionally cheated, the bot correctly classified those essays as \"AI assisted\" 40 percent of the time.\n\n### Recall\n\n$$\\text{recall} = \\frac{TP}{TP + FN}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecall = TP / (TP + FN)\nprint(round(recall, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7\n```\n\n\n:::\n:::\n\n\n* Among all of the essays that were marked as \"AI assisted\", 70 percent of those were created by cheating.\n\n::: {.callout-note}\n### Sensitivity and specificity\n\nAll of these contingency table formulas are collected nicely on the Wikipedia page for [sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity).\n:::\n\n\n\n\n\n\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* Assignments (due Friday):\n\n    * Precept 2\n    * Pick Group Partners\n    * Coloring Assignment 1\n    \n* Project 1:\n\n    * assigned: Feb 9\n    * due: Feb 24\n    \n* Exam 1: Mar 5\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\"The first [lesson] was always to make the choice to learn.  That meant embracing change and mustering the courage to fail; success and failure are two sides of the same coin.  You cannot succeed if at some point you haven't failed\" --- Maria Ressa\n\n:::\n\n::::\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources\n\n* Colors: [useful glossary](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf) by Dr Ying Wei\n* a great [blog post](https://blog.albertkuo.me/post/2022-01-04-reordering-geom-col-and-geom-bar-by-count-or-value/) about the `forcats` package by Albert Kuo\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.2 (2025-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n [5] purrr_1.1.0     readr_2.1.5     tidyr_1.3.1     tibble_3.3.0   \n [9] ggplot2_4.0.0   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] bit_4.6.0          gtable_0.3.6       jsonlite_2.0.0     crayon_1.5.3      \n [5] compiler_4.5.2     tidyselect_1.2.1   parallel_4.5.2     scales_1.4.0      \n [9] yaml_2.3.10        fastmap_1.2.0      R6_2.6.1           labeling_0.4.3    \n[13] generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4  pillar_1.11.0     \n[17] RColorBrewer_1.1-3 tzdb_0.5.0         rlang_1.1.6        utf8_1.2.6        \n[21] stringi_1.8.7      xfun_0.52          S7_0.2.0           bit64_4.6.0-1     \n[25] timechange_0.3.0   cli_3.6.5          withr_3.0.2        magrittr_2.0.3    \n[29] digest_0.6.37      grid_4.5.2         vroom_1.6.5        rstudioapi_0.17.1 \n[33] hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5        evaluate_1.0.4    \n[37] glue_1.8.0         farver_2.1.2       rmarkdown_2.29     tools_4.5.2       \n[41] pkgconfig_2.0.3    htmltools_0.5.8.1 \n```\n\n\n:::\n:::\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n:::: {.panel-tabset}\n\n\n\n::::",
    "supporting": [
      "04_categories_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}