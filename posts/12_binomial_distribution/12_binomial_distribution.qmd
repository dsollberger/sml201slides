---
title: "12: Binomial Distribution"
author: "Derek Sollberger"
date: "2024-10-22"
format:
  html:
    toc: true
    theme: cerulean
---

```{r}
#| message: false
#| warning: false
library("gt")        #great tables
library("patchwork") #easy side-by-side plots
library("tidyverse") #tools for data wrangling and visualization

# school colors
princeton_orange <- "#E77500"
princeton_black  <- "#121212"
```


# SML 201

## Start

:::: {.columns}

::: {.column width="50%"}
* **Goal**: Introduce concepts of probability

* **Objective**: Compute probabilities with the discrete binomial distribution
:::

::: {.column width="10%"}

:::

::: {.column width="40%"}


:::

::::


# Brief History of Probability

## Terminology

::::: {.panel-tabset}

## Definition

For event $X$ with outcomes $x$, the probability $P(x)$ has properties

* each probability is between zero and one (inclusive inequalities)

$$0 \leq P(x) \leq 1$$

* all probabilities add up to one (i.e. 100 percent)

$$\sum_{x \in X} P(x) = 1$$

## Fork

If a pair of parents have two children, should the genders of the children be represented as

> {two girls, mixed, two boys}

OR

> {{girl, girl}, {girl, boy}, {boy, girl}, {boy, boy}}

## Frameworks

* Classical probability: fraction from known observations

    * example: With two children, the probability of having one girl and one boy is $\frac{2}{4}$
    
* **Frequentist probability**: If we could repeat an experiment infinitely many iterations, what would the proportion be?

    * example: Surveying all families with multiple children, among the first two children, the probability of having one girl and one boy is converging toward 50 percent.
    * SML 201
    
* Bayesian probability: A posterior distribution is the update from multiplying likelihoods to the prior distribution.

    * example: If the first child is a girl, what is the probability that the second child is a boy?
    * SML 320

:::::

## Coins

::::: {.panel-tabset}

## Fair Coin

For a flip of a fair coin, the probability of observing "Heads" is 50 percent.  The complement, observing "Tails", also has a probability of 50 percent.

$$P(H) = 0.50, \quad P(T) = 0.50$$
![coins](onecoin.png)

## 3 Coins

```{r}
#| echo: false
coin <- c("H", "T")
df <- data.frame(expand.grid(coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3"),
               sep = "", remove = FALSE)
# print
dput(df$obs)
```

## 4 Coins

```{r}
#| echo: false
coin <- c("H", "T")
df <- data.frame(expand.grid(coin, coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3", "Var4"),
               sep = "", remove = FALSE)
# print
dput(df$obs)
```

## 5 Coins

```{r}
#| echo: false
coin <- c("H", "T")
df <- data.frame(expand.grid(coin, coin, coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3", "Var4", "Var5"),
               sep = "", remove = FALSE)
# print
dput(df$obs)
```

## Code

```{r}
#| eval: false

# 3 coins
coin <- c("H", "T")
df <- data.frame(expand.grid(coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3"),
               sep = "", remove = FALSE)
dput(df$obs)

# 4 coins
df <- data.frame(expand.grid(coin, coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3", "Var4"),
               sep = "", remove = FALSE)
dput(df$obs)

# 5 coins
df <- data.frame(expand.grid(coin, coin, coin, coin, coin)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3", "Var4", "Var5"),
               sep = "", remove = FALSE)
dput(df$obs)

```

## Exactly

* Example: For 6 coin flips, in how many permutations do we observe exactly 2 heads?

* one instance:

$${H, H, T, T, T, T}$$

* answer:

$$\frac{6!}{2!4!} = 15$$

:::::


## Choose

::::: {.panel-tabset}

## Definition

:::: {.columns}


::: {.column width="67%"}
$$\binom{n}{k} = \frac{n!}{k!(n-k)!}$$

- said ``n choose k''
- note $0! = 1$ (to avoid dividing by zero)
:::

::: {.column width="33%"}
![from The Simpsons](choochoochooseyou.png)
:::

::::

## Discussion

:::: {.columns}


::: {.column width="67%"}
* In SML 201, you will never be directly asked for the distinction between 

    * **permutations**: number of arrangements when order matters
    * **combinations**: number of arrangements when order does not matter
    
* Example: To open a *combination* lock, you need to apply the correct *permutation*

* But $\binom{n}{k}$ is "nCr" on a calculator!

    * This choose operator keeps track of the number of permutations in a certain combination
:::

::: {.column width="33%"}
![combination lock](combination_lock.png)
:::

::::

## Binomial Distribution

$$P(x = k) = \binom{n}{k} p^{k}(1-p)^{n-k}$$

- $0 \leq k \leq n$, where $n$ and $k$ are whole numbers
- $0 \leq p \leq 1$

:::::


# dbinom

## Example: Squirtle

::::: {.panel-tabset}

## Setup

:::: {.columns}

::: {.column width="45%"}
Historically, Squirtle defeats Charizard 32\% of the time.  If there are 5 battles, what is the probability that Squirtle wins exactly 2 times?	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Squirtle the underdog](charizard.png)
:::

::::

## Battle Arena

```{r}
#| echo: false
battle <- c("S", "C")
df <- data.frame(expand.grid(battle, battle, battle, battle, battle)) |>
  tidyr::unite("obs", c("Var1", "Var2", "Var3", "Var4", "Var5"),
               sep = "", remove = FALSE)
# print
dput(df$obs)
```


* But these observations have different weights!
* The outcomes are not uniformly distributed

## Math

$$P(k = 2) = \overbrace{\binom{5}{2}}^{\text{number of permutations}}\underbrace{(0.32)^{2}}_{\text{Squirtle wins}}\overbrace{(0.68)^{3}}^{\text{Charizard wins}}$$



## R

Historically, Squirtle defeats Charizard 32\% of the time.  If there are 5 battles, what is the probability that Squirtle wins exactly 2 times?	

* $n = 5$
* $k = 2$
* $p = 0.32$

```{r}
dbinom(2, 5, 0.32)
```


## Distribution

```{r}
k_obs <- 2
n     <- 5
p     <- 0.32
labels <- TRUE

# make data frame
k_vals <- 0:n
pk     <- dbinom(k_vals, n, p)
k_bool <- k_vals %in% k_obs
df_binom <- data.frame(k_vals, pk, k_bool)

# compute requested probability
answer_prob = round(sum(dbinom(k_obs, n, p)), 4)

# define bar plot
this_plot <- if(labels){
  df_binom |>
    ggplot(aes(x = factor(k_vals), y = pk, color = k_bool, fill = k_bool)) +
    geom_bar(stat = "identity") +
    geom_label(aes(x = factor(k_vals), y = pk, label = round(pk, 4)),
               color = "black", fill = "white") +
    labs(subtitle = paste0("n = ", n, ", k = ", list(k_obs), ", p = ", p, ", P(k = ", list(k_obs), ") = ", answer_prob),
         caption = "SML 201",
         y = "probability") +
    theme(
      legend.position = "bottom",
      panel.background = element_blank()
    )
} else{
  df_binom |>
    ggplot(aes(x = factor(k_vals), y = pk, color = k_bool, fill = k_bool)) +
    geom_bar(stat = "identity") +
    labs(subtitle = paste0("n = ", n, ", k = ", list(k_obs), ", p = ", p, ", P(k = ", list(k_obs), ") = ", answer_prob),
         caption = "SML 201",
         y = "probability") +
    theme(
      legend.position = "bottom",
      panel.background = element_blank()
    )
}

# plot bar chart
this_plot +
  
  # particular to this example
  scale_color_manual(values = c("black", "#ca7721")) +
  scale_fill_manual(values = c("gray70", "#297383")) +
  labs(title = "Squirtle Wins", 
       x = "wins", y = "probability")
```

:::::


## Example: Charizard

::::: {.panel-tabset}

## Setup

:::: {.columns}

::: {.column width="45%"}
Historically, Charizard defeats Squirtle 68\% of the time.  If there are 5 battles, what is the probability that Charizard wins exactly 3 times?	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Charizard the favored](charizard.png)
:::

::::

## Math

$$P(k = 3) = \overbrace{\binom{5}{3}}^{\text{number of permutations}}\underbrace{(0.68)^{3}}_{\text{Charizard wins}}\overbrace{(0.32)^{2}}^{\text{Squirtle wins}}$$

## R

Historically, Charizard defeats Squirtle 68\% of the time.  If there are 5 battles, what is the probability that Charizard wins exactly 3 times?	

* $n = 5$
* $k = 3$
* $p = 0.68$

```{r}
dbinom(3, 5, 0.68)
```

## Function

Let us make a *user-defined function* to help us *visualize* the binomial distribution in the future.

```{r}
vbinom <- function(k_obs, n, p, labels = TRUE){
# make data frame
k_vals <- 0:n
pk     <- dbinom(k_vals, n, p)
k_bool <- k_vals %in% k_obs
df_binom <- data.frame(k_vals, pk, k_bool)

# compute requested probability
answer_prob = round(sum(dbinom(k_obs, n, p)), 4)

# define bar plot
this_plot <- if(labels){
  df_binom |>
    ggplot(aes(x = factor(k_vals), y = pk, color = k_bool, fill = k_bool)) +
    geom_bar(stat = "identity") +
    geom_label(aes(x = factor(k_vals), y = pk, label = round(pk, 4)),
               color = "black", fill = "white") +
    labs(subtitle = paste0("n = ", n, ", k = ", list(k_obs), ", p = ", p, ", P(k = ", list(k_obs), ") = ", answer_prob),
         caption = "SML 201",
         y = "probability") +
    theme(
      legend.position = "bottom",
      panel.background = element_blank()
    )
} else{
  df_binom |>
    ggplot(aes(x = factor(k_vals), y = pk, color = k_bool, fill = k_bool)) +
    geom_bar(stat = "identity") +
    labs(subtitle = paste0("n = ", n, ", k = ", list(k_obs), ", p = ", p, ", P(k = ", list(k_obs), ") = ", answer_prob),
         caption = "SML 201",
         y = "probability") +
    theme(
      legend.position = "bottom",
      panel.background = element_blank()
    )
}

# plot bar chart
this_plot
}
```

## Distribution

```{r}
vbinom(3, 5, 0.68) +
  # particular to this example
  scale_color_manual(values = c("black", "#297383")) +
  scale_fill_manual(values = c("gray70", "#ca7721")) +
  labs(title = "Charizard Wins", 
       x = "wins", y = "probability")
```

:::::


# Symmetry

::::: {.panel-tabset}

## Examples

In the previous examples, we saw that

$$\begin{array}{rcl}
  \binom{5}{2}(0.32)^{2}(0.68)^{3} & = & \binom{5}{3}(0.68)^{3}(0.32)^{2} \\
  \binom{5}{2} & = & \binom{5}{3} \\
  10 & = & 10 \\
\end{array}$$

## Proof

**Claim**:  

$$\binom{n}{k} = \binom{n}{n-k}$$

**Proof**:

$$\binom{n}{n-k} = \frac{n!}{(n-k)!(n - (n-k))!} = \frac{n!}{(n-k)!k!} = \frac{n!}{k!(n-k)!} = \binom{n}{k}$$

## Pascal

:::: {.columns}

::: {.column width="45%"}
![choose operator](choose_pascal_1.png)
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Pascal's Triangle](choose_pascal_2.png)
:::

::::

* Images credit: Go Figure Math

## Usage

For the binomial distribution

$$P(x = k) = \binom{n}{k} p^{k}(1-p)^{n-k}$$

* $n$ trials
* observing $k$ of that event
* population proportion $p$
* complement probability $1-p$

In a binomial setup (e.g. {success, failure}), it does not matter which label is associated with $p$ and $k$ as long as the rest of the task is presented consistently.

:::: {.columns}

::: {.column width="45%"}
Squirtle wins:

* $k = 2$
* $p = 0.32$
* $1 - p = 0.68$
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
Charizard wins:

* $k = 3$
* $p = 0.68$
* $1 - p = 0.32$
:::

::::

:::::

# Skew

::::: {.panel-tabset}

## Definition

In probability, the *skew* of a distribution is the measurement of how asymmetric the distribution is.  Loosely speaking, graphs of distributions are described by which tail---left or right---is more stretched away from the mode.

## Example

```{r}
p1 <- vbinom(2,5,0.32, labels = FALSE) + labs(title = "Right Skew")
p2 <- vbinom(3,5,0.68, labels = FALSE) + labs(title = "Left Skew")

# patchwork
p1 + p2
```

## Discussion

An old definition of skewness was

$$(\mu - \nu) / \sigma$$

* $\mu$: mean
* $\nu$: median
* $\sigma$: standard deviation

with then

* right skew: mean > median
* left skew: mean < median

However this definition has been [debunked](https://en.wikipedia.org/wiki/Skewness) in the past couple of decades

* We tend to discuss distribution skew in a subjective way rather than rigorous way.

:::::


# pbinom

## Example: Boba

::::: {.panel-tabset}

## Setup

:::: {.columns}

::: {.column width="45%"}
There are 4 parking spaces in front of the boba place.  Suppose that each parking space tends to be occupied about 57 percent of the time.	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![boba!](boba.png)
:::

::::

## Exactly

There are 4 parking spaces in front of the boba place.  Suppose that each parking space tends to be occupied about 57 percent of the time.	What is the probability that *exactly 3* of the parking spaces are open?

```{r}
dbinom(3, 4, 0.43)
```

```{r}
vbinom(3, 4, 0.43) +
  labs(title = "Exactly 3 parking spaces",
       x = "open parking spaces")
```

## At Most

There are 4 parking spaces in front of the boba place.  Suppose that each parking space tends to be occupied about 57 percent of the time.	What is the probability that *at most 2* of the parking spaces are open?

```{r}
sum(dbinom(0:2, 4, 0.43))
```

```{r}
vbinom(0:2, 4, 0.43) +
  labs(title = "Probability of at most 2 open parking spaces",
       x = "open parking spaces")
```
```{r}
pbinom(2, 4, 0.43) #same as sum(dbinom(0:2, 4, 0.43))
```

:::::

## Cumulative Probability

The `pbinom` function in `R` computes a cumulative probability (i.e. adds up probabilities).

$$P(i \leq k) = \sum_{i = 1}^{k}\binom{n}{i}p^{i}(1-p)^{n-i}$$

In `R`,

```{r}
#| eval: false
pbinom(k, n, p)
# is the same as
sum(dbinom(0:k, n, p))
```


## Example: Parking

::::: {.panel-tabset}

## Setup

:::: {.columns}

::: {.column width="45%"}
There are 32 parking spaces on a certain stretch of Nassau Street.  Suppose that each parking space tends to be occupied about 81 percent of the time.	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Nassau Street](nassau_street.png)
:::

::::



## More Than

There are 32 parking spaces on a certain stretch of Nassau Street.  Suppose that each parking space tends to be occupied about 81 percent of the time.	 What is the probability that *more than 5* of the parking spaces are open?

```{r}
vbinom(6:32, 32, 0.19, labels = FALSE) +
  labs(title = "Probability of more than 5 open parking spaces",
       x = "open parking spaces")
```

Each of the following are equivalent ways to compute the requested probability ("more than 5"))

```{r}
sum(dbinom(6:32, 32, 0.19))
1 - pbinom(5, 32, 0.19)
pbinom(5, 32, 0.19, lower.tail = FALSE)
```

:::::


# Brief History of Randomization

## Venetian Elections

:::: {.columns}

::: {.column width="25%"}
![Election of Doge](election_of_doge.png)
:::

::: {.column width="5%"}
	
:::

::: {.column width="40%"}
* left: "Sorting process for the election of the Doge of Venice", Jacob von Sandrart, 1687

    * image credit: The Ballot Boy
    
* right: elementary balls-and-urns probability setup

    * image credit: Professor Joyce, Clark University
:::

::: {.column width="5%"}
	
:::

::: {.column width="25%"}
![urns](urns.png)
:::

::::

## Discrete

In `R`, discrete sampling is handled with `sample`.

```{r}
sample(LETTERS[1:6], size = 5)
```

Asking for too many observations here leads to an error.

```{r}
#sample(LETTERS[1:6], size = 7)
```


Be default, the sampling is performed *without replacement*.  Sometimes we will need to perform sampling *with replacement*.

```{r}
sample(LETTERS[1:6], size = 7, replace = TRUE)
```

Sometimes, we want to suppress randomization.  More precisely, we want to replicate the creation of the pseudo-random numbers.  This is useful for working on simulations with groups of researchers (i.e. get the same answers).

```{r}
set.seed(201)
sample(LETTERS[1:6], size = 7, replace = TRUE)
```

## Continuous

The most common function for pseudo-random number generation in `R` is `runif`

* pronounced "r unif" (i.e. random numbers from a uniform distribution)
* default: random numbers between zero and one

```{r}
runif(5)
```

::: {.callout-note collapse="true"}
## (optional) Math: Discrete versus Continuous

In math classes, we tend to have the students pick up simplistic definitions:

* discrete data: can be written as a list

    * math: "countable"
    
* continous data: function can be drawn without lifting your pencil

    * math: "uncountable"
    
If anyone is curious, here are more rigorous definitions from Real Analysis

* A set $X$ is **discrete** if $\exists \epsilon\in\mathbb{R}$ such that

$$\forall x\in X, \exists c \in B(x,\epsilon) \text{ such that } c \in \mathbb{R}/X$$
where $B$ is a ball of center $x$ and radius $\epsilon$.

* A set $X$ is **continuous** if 

$$\forall x \in X, \forall\epsilon \in \mathbb{R}, \exists c \in B(x,\epsilon) \text{ such that } c\in X$$

:::

## Not Uniform

The previous sampling examples were chosing from uniform distributions (i.e. each outcome was equally likely).  We will have situations that are not uniform.  For example

$$P(red) = 1/3, \quad P(green) = 2/3$$

```{r}
sample(c("red", "green"), size = 20, replace = TRUE, prob = c(1/3, 2/3))
```


## Weighted Mean

::::: {.panel-tabset}

## Definition

* sample mean

$$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_{i}$$

* weighted mean

$$\bar{x} = \frac{\sum_{i=1}^{n} w_{i}*x_{i}}{\sum_{i=1}^{n} w_{i}}$$

## Example

This [banana slicer](https://www.amazon.com/Hutzler-3571-571-Banana-Slicer/dp/B0047E0EII/) is popular on Amazon.  We will replicate the calculation for the average rating.

:::: {.columns}

::: {.column width="60%"}
The average rating is not
$$\frac{1 + 2 + 3 + 4 + 5}{5}$$
but rather
```{r}
stars <- 1:5
probs <- c(4, 4, 8, 13, 71)/100

# weighted mean
sum(probs * stars) / sum(probs)
```

:::

::: {.column width="10%"}
	
:::

::: {.column width="30%"}
![banana slicer](banana_slicer.png)
:::

::::

:::::


# Scenario: Taco versus Sandwich

:::: {.columns}

::: {.column width="45%"}
The undergraduates at Princeton are choosing an official food item, and the two remaining candidates are "tacos" and "sandwiches".  Suppose also that with regards to prior events, some residential colleges are alloted more delegates than others.	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Tacos or Sandwiches?](taco_sandwich.png)
:::

::::



## Voter Info

```{r}
set.seed(201)
college <- c("Butler", "Forbes", "Mathey", "New College West", "Rockefeller", "Whitman", "Yeh College")
n <- length(college)
delegates <- sample(11:20, size = n, replace = FALSE)
taco_prop <- round(runif(n), 2)

# if you want to experiment with this example later, you can explicitly set the weights here
# college <- c("Butler", "Forbes", "Mathey", "New College West", "Rockefeller", "Whitman", "Yeh College")
# delegates <- c(13, 16, 17, 12, 11, 15, 18)
# taco_prop <- c(27, 10, 29, 57, 68, 61, 47) / 100

df_election <- data.frame(
  college, delegates, taco_prop
)
```

## Complement

```{r}
df_election <- df_election |>
  mutate(sandwich_prop = 1 - taco_prop)
```

## Simulate One Election

```{r}
set.seed(201)
df_election <- df_election |>
  rowwise() |>
  mutate(picks = sample(c("Taco", "Sandwich"), 
                        size = 1,
                        prob = c(taco_prop, sandwich_prop)))
```

## Count Votes

In this example, the votes are tabulated as a weighted mean.

```{r}
df_election <- df_election |>
  mutate(picks_bool = ifelse(picks == "Taco", 1, 0))

taco_share <- sum(df_election$delegates * df_election$picks_bool) / sum(df_election$delegates)

print(taco_share)
```

## Classify Result

```{r}
election_result <- case_when(
  taco_share < 0.5 ~ "Sandwich Won",
  taco_share > 0.5 ~ "Taco Won",
  .default = "tie"
)

print(election_result)
```


# Simulation

So far, we have merely one observation.  What if we wanted to address broader questions like

* How often would taco win in this scenario?
* What is the variance (or standard deviation) for the `taco_share`?

## for loops

A common programming tool is the **for loop**. We tend to use letters $i$, $j$, and $k$ historically as *counter* variables.

```{r}
N <- 7 #number of iterations
```

```{r}
for(i in 1:N){
  print(i)
}
```

```{r}
for(i in 1:N){
  print(i^2)
}
```

```{r}
for(i in 1:N){
  print(LETTERS[1:i])
}
```


## Election Simulation

```{r}
N <- 1337 #number of simulations

# pre-allocate space for storing results
taco_share_vec <- rep(NA, N)

for(i in 1:N){
  df_election <- df_election |>
  rowwise() |>
    mutate(picks = sample(c("Taco", "Sandwich"), 
                          size = 1,
                          prob = c(taco_prop, sandwich_prop)))
  df_election <- df_election |>
    mutate(picks_bool = ifelse(picks == "Taco", 1, 0))
  
  taco_share_vec[i] <- sum(df_election$delegates * df_election$picks_bool) / sum(df_election$delegates)
}

df_simulation <- data.frame(iter = 1:N, taco_share_vec)
```

::: {.callout-note collapse="true"}
## On the computer processing of simulations

If your computer is older

* took a while to draw maps
* took a while to produce network visuals

you may reduce the number of iterations from 1337 to 201 (for example).
:::


## Visualize the Simulation

Now, `taco_share_vec` is itself a numerical variable, so we can visualize its distribution with a histogram.

```{r}
df_simulation |>
  ggplot(aes(x = taco_share_vec)) +
  geom_histogram(bins = 20, color = princeton_black, fill = princeton_orange) +
  geom_vline(xintercept = 0.5, color = "#2A668F", 
             linewidth = 3, linetype = 3) +
  labs(title = "Taco versus Sandwich!",
       subtitle = "Simulated delegation voting of the residential colleges",
       caption = "SML 201",
       x = "taco vote share") +
  theme_minimal()
```

## Simulation Statistics

To wrap up this example,

* "Taco" had this vote share on average:

```{r}
mean(df_simulation$taco_share_vec)
```

To compute how often "Taco" would win probabilistically, we could

* count the iterations where `taco_share_vec > 0.50`
* divide by the number of iterations

```{r}
mean(df_simulation$taco_share_vec > 0.50)
```

Preview: the **standard error** is the standard error of a sampling distribution.

```{r}
sd(df_simulation$taco_share_vec)
```










# Quo Vadimus?

:::: {.columns}

::: {.column width="45%"}

:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
### Exam 1 Statistics
:::

::::


# Footnotes

::: {.callout-note collapse="true"}
## (optional) Additional Resources

* The [Doge of Venice](https://en.wikipedia.org/wiki/Doge_of_Venice)
* [Skewness](https://en.wikipedia.org/wiki/Skewness)

:::

::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


::: {.callout-note collapse="true"}
## Example Callout Block

`note`, `tip`, `warning`, `caution`, or `important`
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::