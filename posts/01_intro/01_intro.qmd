---
title: "1: Introduction"
author: "Derek Sollberger"
date: "2026-01-27"
format:
  html:
    toc: true
---


# 1: Introduction

## Learning Objectives

:::: {.columns}

::: {.column width="60%"}
* **Goal**: Introduce data science

* **Objective**: Explore a data set with bar graphs and facets
:::

::: {.column width="40%"}
![Image credit: Steven Geringer](data_science_venn_diagram.png)
:::

::::

## Packages

```{r}
#| message: false
#| warning: false
library("ggtext")
library("gt")
library("gtExtras")
library("sf")
library("tidytext")
library("tidyverse")

precept_df <- readr::read_csv("precept_workload.csv")
topics_df <- readr::read_csv("SML201_lecture_schedule.csv")
```


# Case Study: Grant Witness

I wanted to explore the data sets assembled by [Grant Witness](https://grant-witness.us/) (Noam Ross, et al).  This data is about terminations of research grants in the USA in the year 2025.

The data can be downloaded as 3 CSV files

1. `epa_terminations.csv`
2. `nih_terminations.csv`
3. `nsf_terminations.csv`

which refer to the EPA (Environmental Protection Agency), NIH (National Institutes of Health), and NSF (National Science Foundation) respectively.

```{r}
#| message: false
#| warning: false

banned_words <- readLines("data/banned_words.txt")
EPA_raw <- readr::read_csv("data/epa_terminations.csv")
NIH_raw <- readr::read_csv("data/nih_terminations.csv")
NSF_raw <- readr::read_csv("data/nsf_terminations.csv")
states_shp <- readr::read_rds("data/us_states_shp.rds")
stop_words <- tidytext::get_stopwords()
```

## Data Wrangling

::::: {.panel-tabset}

### EPA

```{r}
colnames(EPA_raw)
```

### NIH

```{r}
colnames(NIH_raw)
```

### NSF

```{r}
colnames(NSF_raw)
```

### Banned

[https://grantwritingandfunding.com/banned-and-trigger-words-in-federal-grant-writing-in-the-trump-administration-2-0/](https://grantwritingandfunding.com/banned-and-trigger-words-in-federal-grant-writing-in-the-trump-administration-2-0/)

```{r}
banned_words_df <- as.data.frame(banned_words)
banned_words_df <- banned_words_df |>
  mutate(banned_words = stringr::str_trim(banned_words),
         n_char = nchar(banned_words)) |>
  filter(n_char > 0) |>
  mutate(banned_words = stringr::str_to_lower(banned_words))

banned_words <- banned_words_df |>
  pull(banned_words)
```

```{r}
print(banned_words_df$banned_words)
```

:::::

```{r}
intersect(colnames(NIH_raw), colnames(NSF_raw))
```

For now, I am going to focus on the NIH and NSF data since their tables are more similar.  It appears that the column names are not uniform, so let's search for columns of interest.

::: {.callout-note collapse="true"}
## Subset

I then looked at the spreadsheets directly.

```{r}
intersect_columns <- intersect(colnames(NIH_raw), colnames(NSF_raw))

df_NIH <- NIH_raw |>
  select(all_of(intersect_columns), abstract_text, total_award, dept_type)

df_NSF <- NSF_raw |>
  select(all_of(intersect_columns), abstract, nsf_total_budget, nsf_program_name)

common_columns <- c("status", "termination_date", "reinstatement_ind", "project_title", "org_name", "org_state", "org_city", "usaspending_url", "record_sha1", "abstract", "budget", "subdivsion")
colnames(df_NIH) <- common_columns
colnames(df_NSF) <- common_columns

df_NIH <- df_NIH |> mutate(agency = "NIH")
df_NSF <- df_NSF |> mutate(agency = "NSF")

df <- rbind(df_NIH, df_NSF) |>
  mutate(org_name = stringr::str_to_title(org_name))
```

:::




# Princeton Impact

My audience will want to know about the grants that directly relate to Princeton University.  Here, I simply look at the `org_name` variable (i.e. this approach may miss grants with collaborators across multiple universities).

## Table

::::: {.panel-tabset}

### table

```{r}
#| echo: false
#| eval: true

df_Princeton <- df |>
  filter(stringr::str_detect(org_name, "Princeton")) |>
  tidyr::fill(termination_date, .direction = "down")

df_Princeton |>
  select(agency, org_city, termination_date, budget, project_title) |>
  arrange(termination_date) |>
  gt() |>
  cols_align(align = "center") |>
  fmt_currency(columns = "budget", currency = "USD") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Princeton University",
    subtitle = "NIH and NSF Grants"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "#E77500"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_city")
  )
```

### gt code

```{r}
#| echo: true
#| eval: false

df_Princeton <- df |>
  filter(stringr::str_detect(org_name, "Princeton")) |>
  tidyr::fill(termination_date, .direction = "down")

df_Princeton |>
  select(agency, org_city, termination_date, budget, project_title) |>
  arrange(termination_date) |>
  gt() |>
  cols_align(align = "center") |>
  fmt_currency(columns = "budget", currency = "USD") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Princeton University",
    subtitle = "NIH and NSF Grants"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "#E77500"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_city")
  )
```

:::::




# Presenter

* Spring 2026
* Tuesdays and Thursdays

    - 1040 AM to 12 noon: Architecture Building 101
    - 120 PM to 240 PM: Friend 006

* Lecturer: Derek

    - I go by "Derek" or "teacher"

::: {.callout-tip collapse="true"}
## Course Description

Introduction to Data Science provides a practical introduction to the burgeoning field of data science. The course introduces students to the essential tools for conducting data-driven research, including the fundamentals of programming techniques and the essentials of statistics. Students will work with real-world datasets from various domains; write computer code to manipulate, explore, and analyze data; use basic techniques from statistics and machine learning to analyze data; learn to draw conclusions using sound statistical reasoning; and produce scientific reports. No prior knowledge of programming or statistics is required.
:::

## Lecturer

![](Lecturer_Derek.png)


## Current Research in Pedagogy

:::: {.columns}

::: {.column width="50%"}
![](MBVP SABER poster.png)
:::

::: {.column width="50%"}
- active learning
- computer programming
- flipped classrooms
:::

::::

## Identity Statement

:::: {.columns}

::: {.column width="75%"}
- Originally from Los Angeles
- Math: easier to understand through graphs
- Computer Programming: years of experience with R, Python, MATLAB, PHP, HTML, etc.
- Learning: drawn to puzzles and manageable tasks
- Personality: shy, introvert
:::

::: {.column width="25%"}
![](math-zach-galifianakis.gif)
:::

::::

## Icebreaker

* name
* major (and minors or certificates if applicable)
* unusual goal

    - (please pick a goal other than "get good grades")
    - whatever time frame makes sense
    
::: {.callout-tip collapse="true"}
### Derek's Example

"Hi.  My name is Derek, and I majored in applied mathematics.  My unusual goal is that I am trying to learn a bit of the Polish language.
:::

::: {.callout-warning}
# DCP1
:::


# Assessment

::: {.callout-note collapse="true"}

## Precepts

* 10 percent of semester grade
* weekly programming problem sets
* assessment: either

    * ask precept instructor to check your work for completion, XOR
    * turn in work in Canvas (not both)

* students are encouraged to work in pairs

:::

::: {.callout-note collapse="true"}

## Reading

* 4 percent of semester grade
* short reading tasks, cognitive activities

:::

::: {.callout-important collapse="true"}

## Projects

* 24 percent of semester grade

    1. (4%) exploratory data analyses, due February 24
    3. (8%) regression modeling, due April 7
    4. (12%) inference and machine learning, due May 11

* Students may work in groups of 1, 2, or 3 people

:::

::: {.callout-important collapse="true"}

## Exams

* 50 percent of semester grade

    * Exam 1 (20%): October 10
    * Exam 2 (30%): December 5

* content:

    * multiple-choice questions (similar to study materials)
    * open-ended tasks (similar to precepts and projects)

:::

::: {.callout-tip collapse="true"}

## Logistics

* 2 percent of semester grade
* short surveys, group formation, Derek's research, etc.

:::


# Reading List

## Textbooks

:::: {.columns}

::: {.column width="30%"}
![R for Data Science](R_for_DS_book_cover.png)
:::

::: {.column width="40%"}
This course will loosely follow 

* *R for Data Science* by Hadley Wickham, Mine Cetinkaya-Rundel, and Garrett Grolemund ([online textbook](https://r4ds.hadley.nz/))
* *Statistical Inference via Data Science* by Chester Ismay and Albert Y Kim ([online textbook](https://moderndive.com/))
:::

::: {.column width="30%"}
![Modern Dive](Modern_Dive_book_cover.png)
:::

::::

## Additional Reading

The following list of books is optional for student studies, but the instructor may use some materials to add depth and interest to the course.

::: {.callout-tip collapse="true"}

## Additional Reading

* *The Seven Pillars of Statistical Wisdom* by Stephen M Stigler provides a wonderful overview of the history of statistics and the field's major developments.
* *Statistical Rethinking* by Richard McElreath is the premier body of work in the field of Bayesian analysis.  This resource is great for people who want to build a strong foundation in philosophy and theory in this branch of mathematics.
* *Teaching Statistics* by Andrew Gelman and Deborah Nolan features a variety of classroom activities that engage audiences at prestigious universities into learning statistical concepts.
* *Bernoulli's Fallacy* by Aubrey Clayton is a scathing review of the history of statistics and posits that the foundations of the field are flawed.

:::


# Other Affected Universities

Here, we perform some **segmentation** and **pivoting** to find the top 10 organizations that were affected by the terminated grants (for both NIH and NSF grants)

## NIH

::::: {.panel-tabset}

### table

```{r}
#| echo: false
#| eval: true
df |>
  filter(agency == "NIH") |>
  group_by(org_name) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  select(agency, org_name, num_grants) |>
  distinct() |>
  slice_max(n = 10, order_by = num_grants) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Universities",
    subtitle = "NIH Grants, top 10 organizations affected"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_name")
  )
```

### gt table

```{r}
#| echo: true
#| eval: false
df |>
  filter(agency == "NIH") |>
  group_by(org_name) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  select(agency, org_name, num_grants) |>
  distinct() |>
  slice_max(n = 10, order_by = num_grants) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Universities",
    subtitle = "NIH Grants, top 10 organizations affected"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_name")
  )
```

:::::


## NSF

::::: {.panel-tabset}

### table

```{r}
#| echo: false
#| eval: true
df |>
  filter(agency == "NSF") |>
  group_by(org_name) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  select(agency, org_name, num_grants) |>
  distinct() |>
  slice_max(n = 10, order_by = num_grants) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Universities",
    subtitle = "NSF Grants, top 10 organizations affected"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "cadetblue1"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_name")
  )
```

### gt code

```{r}
#| echo: true
#| eval: false
df |>
  filter(agency == "NSF") |>
  group_by(org_name) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  select(agency, org_name, num_grants) |>
  distinct() |>
  slice_max(n = 10, order_by = num_grants) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated Grants at Universities",
    subtitle = "NSF Grants, top 10 organizations affected"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "cadetblue1"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "org_name")
  )
```

:::::


# Geospatial

::::: {.panel-tabset}

## joins

For science communication ("sci comm"), we now **join** tabular and spatial data in hopes of producing geometry maps to explore the information.

## R

```{r}
df_state_group <- df |>
  group_by(agency, org_state) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  select(agency, org_state, num_grants) |>
  distinct()

df_state_group$num_grants <- as.numeric(df_state_group$num_grants)

shp_and_df <- states_shp |>
  left_join(df_state_group, by = join_by(STUSPS == org_state))
```

## NIH

```{r}
#| echo: false
#| eval: true
shp_and_df |>
  filter(agency == "NIH") |>
  ggplot() +
  geom_sf(aes(fill = log(num_grants))) +
  labs(title = "Terminated Grants at Universities",
       subtitle = "NIH Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

## R

```{r}
#| echo: true
#| eval: false
shp_and_df |>
  filter(agency == "NIH") |>
  ggplot() +
  geom_sf(aes(fill = log(num_grants))) +
  labs(title = "Terminated Grants at Universities",
       subtitle = "NIH Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

## NSF

```{r}
#| echo: false
#| eval: true
shp_and_df |>
  filter(agency == "NSF") |>
  ggplot() +
  geom_sf(aes(fill = log(num_grants))) +
  labs(title = "Terminated Grants at Universities",
       subtitle = "NSF Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

## R

```{r}
#| echo: true
#| eval: false
shp_and_df |>
  filter(agency == "NSF") |>
  ggplot() +
  geom_sf(aes(fill = log(num_grants))) +
  labs(title = "Terminated Grants at Universities",
       subtitle = "NSF Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

:::::


# Words

## Titles

::::: {.panel-tabset}

### NIH

```{r}
#| echo: false
#| eval: true
NIH_title_words <- df |>
  filter(agency == "NIH") |>
  select(project_title) |>
  tidytext::unnest_tokens(word, project_title) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NIH_title_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NIH_title_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### code

```{r}
#| echo: true
#| eval: false
NIH_title_words <- df |>
  filter(agency == "NIH") |>
  select(project_title) |>
  tidytext::unnest_tokens(word, project_title) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NIH_title_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NIH_title_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### NSF

```{r}
#| echo: false
#| eval: true
NSF_title_words <- df |>
  filter(agency == "NSF") |>
  select(project_title) |>
  tidytext::unnest_tokens(word, project_title) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NSF_title_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NSF_title_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### code

```{r}
#| echo: true
#| eval: false
NSF_title_words <- df |>
  filter(agency == "NSF") |>
  select(project_title) |>
  tidytext::unnest_tokens(word, project_title) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NSF_title_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NSF_title_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Titles"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

:::::



## Abstracts

::::: {.panel-tabset}

### NIH

```{r}
#| echo: false
#| eval: true
NIH_abstract_words <- df |>
  filter(agency == "NIH") |>
  select(abstract) |>
  tidytext::unnest_tokens(word, abstract) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NIH_abstract_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NIH_abstract_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### code

```{r}
#| echo: true
#| eval: false
NIH_abstract_words <- df |>
  filter(agency == "NIH") |>
  select(abstract) |>
  tidytext::unnest_tokens(word, abstract) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NIH_abstract_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NIH_abstract_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NIH Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### NSF

```{r}
#| echo: false
#| eval: true
NSF_abstract_words <- df |>
  filter(agency == "NSF") |>
  select(abstract) |>
  tidytext::unnest_tokens(word, abstract) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NSF_abstract_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NSF_abstract_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

### code

```{r}
#| echo: true
#| eval: false
NSF_abstract_words <- df |>
  filter(agency == "NSF") |>
  select(abstract) |>
  tidytext::unnest_tokens(word, abstract) |>
  count(word) |>
  anti_join(stop_words, by = "word")

tab1 <- NSF_abstract_words |>
  arrange(desc(n)) |>
  slice(1:10) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

tab2 <- NSF_abstract_words |>
  arrange(desc(n)) |>
  slice(11:20) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness") |>
  tab_header(
    title = "Terminated NSF Grants",
    subtitle = "Most Frequent Words in Abstracts"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(cell_fill(color = "springgreen"),
                 cell_text(color = "#121212",
                           weight = "bold")),
    locations = cells_body(columns = "word")
  )

list(tab1, tab2) |> 
  gtExtras::gt_two_column_layout()
```

:::::





## Word Clouds

::::: {.panel-tabset}

### tools

While there are programmatic ways to make word clouds, I like the functionality of the [WordClouds.com](https://www.wordclouds.com/) website. To use that third-party software, make a CSV file whose columns are: `weight`, `word`, `color`, `url`.

### NIH

![NIH Abstracts](nih_wordcloud.png)

### code

```{r}
NIH_wordcloud_df <- NIH_abstract_words |>
  mutate(weight = n, .before = "word") |>
  select(weight, word) |>
  arrange(desc(weight)) |>
  slice(1:100) |>
  mutate(color = ifelse(word %in% banned_words, "#ff0000", ""),
         url = "")
readr::write_csv(NIH_wordcloud_df, "NIH_for_wordcloud.csv")
```

### NSF

![NSF Abstracts](nsf_wordcloud.png)

### code

```{r}
NSF_wordcloud_df <- NSF_abstract_words |>
  mutate(weight = n, .before = "word") |>
  select(weight, word) |>
  arrange(desc(weight)) |>
  slice(1:100) |>
  mutate(color = ifelse(word %in% banned_words, "#ff0000", ""),
         url = "")
readr::write_csv(NSF_wordcloud_df, "NSF_for_wordcloud.csv")
```



:::::








# Administrative

::: {.callout-warning collapse="true"}

## Prerequisites

* Minimal prerequisites:

    * computer skills: organizing files, file types
    * math: algebraic inequalities, familiarity with calculus, Boolean logic

:::

::: {.callout-note collapse="true"}

## Course Learning Outcomes

By the end of this course, students will be able to:

1. Implement data science and statistical concepts and methods to data sets and real-world scenarios
2. Utilize software to load files, perform data wrangling, and produce visualizations
3. Compute results from data analyses and express the findings to academic and scientific communication audiences
4. Discuss ethical and societal impact of data science projects and equitable practices

:::

::: {.callout-note collapse="true"}

## Lecture Sessions

Please keep extra noise to a minimum.  Cell phones may be used as long as they are on silent or vibrate.  Please also review the Cooperative Classroom statement below.

:::

::: {.callout-note collapse="true"}

## Precepts

Precepts will be held for 80 minutes per week.  Students will develop problem-solving skills through collaborative work on the computer programming  while also working toward the projects.

:::

::: {.callout-note collapse="true"}

## Computers

Use of a laptop computer is highly recommended for this course, and students are asked to *bring their laptop computer to every lecture* and precept session.

* More information about computer needs can be found at <https://princeton.service-now.com/service?id=kb_article&sys_id=KB0013768>
* While Chromebooks (or other systems that discourage installation of software) can access cloud software, intensive calculations in this course may merit the use of a personal computer and downloaded software rather than server access.

:::

::: {.callout-tip collapse="true"}

## Special Accommodations

Students must register with the Office of Disability Services (ODS) (ods@princeton.edu; 258-8840) for disability verification and determination of eligibility for reasonable academic accommodations. Requests for academic accommodations for this course need to be made at the beginning of the semester, or as soon as possible for newly approved students, and again at least two weeks in advance of any needed accommodations in order to make arrangements to implement the accommodations. Please make an appointment to meet with me in order to maintain confidentiality in addressing your needs. No accommodations will be given without authorization from ODS, or without advance notice.

:::

::: {.callout-important collapse="true"}

## Academic Integrity Policy 

You are allowed to read text books and resources online. You may not ask other individuals questions (e.g., you may not ask questions on Stack Exchange or R help discussion groups). In accordance with the honor code, you must cite all sources of external information used in your work. This can be a book or a web site. Part of being a successful data scientist is having the ability to leverage existing information and techniques, so it is okay to do so in this course as long as you cite the reference.  University policies can be reviewed at <https://ua.princeton.edu/policies-resources/undergraduate-honor-system>

:::


# Data-Driven Course

## Audience

During the Fall 2024 semester, the `Demographics Survey` yielded the following information about majors and minors.

```{r}
#| message: false
#| warning: false
#| echo: false
#| eval: true
df_major <- readr::read_csv("majors_minors_Fall_2024.csv")
```

```{r}
#| echo: false
#| eval: true
df_minor <- data.frame(c(df_major$minor1, df_major$minor2))
colnames(df_minor) <- "minor"
df_minor <- df_minor |> filter(!is.na(minor))
```


::::: {.panel-tabset}

## majors

```{r}
#| echo: false
#| eval: true

df_major |>
  ggplot(aes(y = fct_rev(fct_infreq(major)))) +
  geom_bar(color = "#000000", fill = "#EE7F2D", stat = "count") +
  labs(title = "Student Majors for SML 201",
       subtitle = "Fall 2024 semester",
       caption = "SML 201",
       x = "count", y = "") +
  theme_minimal()
```


## minors

```{r}
#| echo: false
#| eval: true

df_minor |>
  group_by(minor) |>
  mutate(n = n()) |>
  ungroup() |>
  filter(n > 1) |>
  ggplot(aes(y = fct_rev(fct_infreq(minor)))) +
  geom_bar(color = "#000000", fill = "#EE7F2D", stat = "count") +
  labs(title = "Student Minors for SML 201",
       subtitle = "Fall 2024 semester",
       caption = "SML 201\n
       subgroups with n > 1",
       x = "count", y = "") +
  theme_minimal()
```

## R code

```{r}
#| echo: true
#| eval: false

df_major <- readr::read_csv("majors_minors_Fall_2024.csv")

df_minor <- data.frame(c(df_major$minor1, df_major$minor2))
colnames(df_minor) <- "minor"
df_minor <- df_minor |> filter(!is.na(minor))

df_major |>
  ggplot(aes(y = fct_rev(fct_infreq(major)))) +
  geom_bar(color = "#000000", fill = "#EE7F2D", stat = "count") +
  labs(title = "Student Majors for SML 201",
       subtitle = "Fall 2024 semester",
       caption = "SML 201",
       x = "count", y = "") +
  theme_minimal()

df_minor |>
  group_by(minor) |>
  mutate(n = n()) |>
  ungroup() |>
  filter(n > 1) |>
  ggplot(aes(y = fct_rev(fct_infreq(minor)))) +
  geom_bar(color = "#000000", fill = "#EE7F2D", stat = "count") +
  labs(title = "Student Minors for SML 201",
       subtitle = "Fall 2024 semester",
       caption = "SML 201\n
       subgroups with n > 1",
       x = "count", y = "") +
  theme_minimal()
```


:::::


## Workload

As part of an exit-survey, I asked students how long (in minutes) they spent on the "shortest" and "longest" precept assignments.

::::: {.panel-tabset}

### summary

```{r}
summary(precept_df$short)
```

```{r}
summary(precept_df$long)
```

### density

```{r}
#| echo: false
#| eval: true
precept_long <- precept_df |>
  pivot_longer(cols = c("short", "long"), names_to = "contrast", values_to = "time")

title_string <- "Time Spent on <span style = 'color:#0000FF'>short</span> and<br><span style = 'color:#FF0000'>long</span> precept assignments"

precept_long |>
  ggplot() +
  geom_density(aes(x = time, fill = contrast),
               alpha = 0.75) +
  labs(title = title_string,
       subtitle = "Fall 2024",
       caption = "SML 201",
       x = "time (minutes)") +
  scale_fill_manual(values = c("red", "blue")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_markdown(face = "bold", size = 24),
        plot.subtitle = element_markdown(size = 16))
```

### R code

```{r}
#| echo: true
#| eval: false
precept_long <- precept_df |>
  pivot_longer(cols = c("short", "long"), names_to = "contrast", values_to = "time")

title_string <- "Time Spent on <span style = 'color:#0000FF'>short</span> and<br><span style = 'color:#FF0000'>long</span> precept assignments"

precept_long |>
  ggplot() +
  geom_density(aes(x = time, fill = contrast),
               alpha = 0.75) +
  labs(title = title_string,
       subtitle = "Fall 2024",
       caption = "SML 201",
       x = "time (minutes)") +
  scale_fill_manual(values = c("red", "blue")) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_markdown(face = "bold", size = 24),
        plot.subtitle = element_markdown(size = 16))
```

:::::





::: {.callout-warning collapse="true"}
# DCP2

![incomplete example](DCP0126_image.png)

* [data source](https://ec.europa.eu/eurostat/databrowser/view/edat_aes_l21/default/table?lang=en&category=educ.educ_lang.educ_lang_00.edat_aes_l2)
* [better example](https://github.com/nrennie/misc/blob/main/R/eurostat_languages_chart.R) by Nicola Rennie
    
    * [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7413969351520980992/)

:::


# Learning Environment

## Cooperative Classroom

Learning in a cooperative environment should be stimulating, demanding, and fair.  Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations.  Below are my expectations for students in this class.  This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words.  If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.

1.	Students are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.
2.	When working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others.  Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.
3.	Students should explore data, make observations, and develop inferences as part of a group.  If you use material from published sources, you must provide appropriate attribution.

<!---
(Students will be asked to acknowledge this document in an online form.)
--->

:::: {.columns}

::: {.column width="50%"}


This document has been adapted from
*Scientific Teaching*
by Jo Handelsman, Sarah Miller, and Christine Pfund
:::

::: {.column width="50%"}
![Scientific Teaching](Scientific_Teaching.png)
:::

::::

## Pep Talk

Learning R can be difficult at first---it is like learning a new language, just like Spanish, French, or
Chinese. Hadley Wickham---the chief data scientist at RStudio and the author of some amazing R packages you will be using like `ggplot2`---made this wise observation:

::: {.callout-tip collapse="true"}

## Wisdom from Hadley Wickham

It's easy when you start out programming to get really frustrated and think, “Oh it's me, I'm really stupid,” or, “I'm not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It's just a natural part of programming. So, it happens to everyone and gets less and less over time. Don't blame yourself. Just take a break, do something fun, and then come back and try again later.

:::

If you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions ... e-mail [Derek], etc.  I promise you can do this.

---Andrew Heiss, Georgia State University   

## Inclusion Statement

I value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment).


## Learner Profiles

:::: {.panel-tabset}

## Pedagogy

Sharing an overview of the types of students that might be taking this course.

## 1

:::: {.columns}

::: {.column width="45%"}
### Spike

![Spike](LP_Spike.png)
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* Senior
* History
* Did not like computer programming in the past, but is willing to learn now
:::

::::

## 2

:::: {.columns}

::: {.column width="45%"}
### Jet

![Jet](LP_Jet.png)	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* Junior
* Psychology
* Took AP Statistics years ago, and wants more complex case studies
:::

::::

## 3

:::: {.columns}

::: {.column width="45%"}
### Faye

![Faye](LP_Faye.png)		
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* Sophomore
* Anthropology
* Wants to add "data science" to CV before applying to internships
:::

::::

## 4

:::: {.columns}

::: {.column width="45%"}
### Ed

![Ed](LP_Ed.png)		
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* Computer Science
* ORFE
* Has a lot of experience programming in Python, but is wondering why this class is taught in R 
:::

::::

::::


# Languages

## Why not Spreadsheets?

::::: {.panel-tabset}

### engineering

:::: {.columns}

::: {.column width="45%"}
* need expansive storage
* need control over data types
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Covid memories](UK_Covid.png)

* image source: [The Guardian](https://www.theguardian.com/politics/2020/oct/05/how-excel-may-have-caused-loss-of-16000-covid-tests-in-england)
:::

::::

### reproducibility

:::: {.columns}

::: {.column width="45%"}
"**Reproducibility** refers to the ability of a researcher to duplicate the results of a prior study using the same materials and procedures as were used by the original investigator. So in an attempt to reproduce a published statistical analysis, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis to determine whether they yield the same results." --- [Harvard Data Management](https://datamanagement.hms.harvard.edu/collect-analyze/reproducibility)
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![reproducible code](reproducible_code.png)

* image source: [Netherlands eScience Center](https://blog.esciencecenter.nl/)
:::

::::

:::::

## Why R?

:::: {.columns}

::: {.column width="45%"}
![R](R_logo.png)	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* matches data science concepts well
* language made for statistics and probability calculations
* software compatibility
* easier to learn
* easier to teach
* gaining popularity in areas such as consulting, finance, epidemiology, genomics, pharmaceuticals, etc.
:::

::::

## R vs Python

:::: {.panel-tabset}

## table

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false

languages_df <- data.frame(
  R = c("Data Science", "Dashboards", "Interactvity", "Visualization", "Debugging"),
  Python = c("Machine Learning", "Software Development", "Object-Oriented Programming", "Big Data", "Faster")
)

languages_df |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "source: Derek's opinion") |>
  tab_header(
    title = "Data Science Programming Languages",
    subtitle = "Which one is better?"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#ffc100")
    ),
    locations = cells_body(columns = R)
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#d0cef3")
    ),
    locations = cells_body(columns = Python)
  )
```

## gt code

```{r}
#| echo: true
#| eval: false
#| message: false
#| warning: false

languages_df <- data.frame(
  R = c("Data Science", "Dashboards", "Interactvity", "Visualization", "Debugging"),
  Python = c("Machine Learning", "Software Development", "Object-Oriented Programming", "Big Data", "Faster")
)

languages_df |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "source: Derek's opinion") |>
  tab_header(
    title = "Data Science Programming Languages",
    subtitle = "Which one is better?"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#ffc100")
    ),
    locations = cells_body(columns = R)
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#d0cef3")
    ),
    locations = cells_body(columns = Python)
  )
```

::::


# Topics

:::: {.panel-tabset}

## table

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false

topics_df |>
  select(1:8) |>
  filter(!is.na(Week)) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Spring 2026") |>
  tab_header(
    title = "SML 201",
    subtitle = "Lecture Topics"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#ffc100")
    ),
    locations = cells_body(columns = Topic)
  )
```

## gt code

```{r}
#| echo: true
#| eval: false
#| message: false
#| warning: false

topics_df |>
  select(1:8) |>
  filter(!is.na(Week)) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Spring 2026") |>
  tab_header(
    title = "SML 201",
    subtitle = "Lecture Topics"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "#ffc100")
    ),
    locations = cells_body(columns = Topic)
  )
```

::::


::: {.callout-warning}
# DCP3
:::

::: {.callout-note collapse="true"}
## Changes 

Between the Fall 2024 semesters and the Spring 2026 semester, Derek made adjustments to SML 201, including

* removed "Networks" (too niche and provincial)
* restoring "ANOVA" (classical statistics concept)
* higher emphasis on exams; lower emphasis on projects
* adding DCPs and Slido for interactivity
* removed before-lecture quizzes (too many deadlines)

    * moving to Practice Quizzes
    * worth zero percent of semester grade (to remove deadlines)
* adding data ethics and/or history to each session (CLO4)

:::


# Ethics: PII

**Personally identifiable information** (PII) could be used to specifically identify an individual.

![PII](PII.png)

* image source: [UpGuard](https://www.upguard.com/blog/personally-identifiable-information-pii)

::: {.callout-note}

## PII in SML 201

Beyond your name and e-mail address (used for in-class communication), you are not obligated to release your personally identifiable information in this course.

:::


# Reinstatement


## Conditional Statements

* If a grant was restored, as seen in the `reinstatement_ind` column, set `restated` to TRUE
* If a grant was not restored, as seen in the `reinstatement_ind` column, set `restated` to FALSE
* `R`: `mutate(reinstated = ifelse(is.na(reinstatement_ind), FALSE, TRUE))`

::::: {.panel-tabset}

### table

```{r}
#| echo: false
#| eval: true

df_NIH |>
  select(org_state, reinstatement_ind) |>
  filter(!is.na(org_state)) |>
  slice(1:10) |>
  mutate(reinstated = ifelse(is.na(reinstatement_ind), FALSE, TRUE)) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness, sample of grants") |>
  tab_header(
    title = "Reinstated NIH Grants",
    subtitle = "Tracking Missing Values"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "cyan")
    ),
    locations = cells_body(columns = c(reinstatement_ind, reinstated),
                           rows = reinstated == FALSE)
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "darkorange")
    ),
    locations = cells_body(columns = c(reinstatement_ind, reinstated),
                           rows = reinstated == TRUE)
  )
```


### R code

```{r}
#| echo: true
#| eval: false

df_NIH |>
  select(org_state, reinstatement_ind) |>
  filter(!is.na(org_state)) |>
  slice(1:10) |>
  mutate(reinstated = ifelse(is.na(reinstatement_ind), FALSE, TRUE)) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Grant Witness, sample of grants") |>
  tab_header(
    title = "Reinstated NIH Grants",
    subtitle = "Tracking Missing Values"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "cyan")
    ),
    locations = cells_body(columns = c(reinstatement_ind, reinstated),
                           rows = reinstated == FALSE)
  ) |>
  tab_style(
    style = list(
      cell_fill(color = "darkorange")
    ),
    locations = cells_body(columns = c(reinstatement_ind, reinstated),
                           rows = reinstated == TRUE)
  )
```

:::::




## Proportion

::::: {.panel-tabset}

### Concept

Finally, I am curious if some states performed better than others in getting those research grants reinstated.  We will seek out the proportion of grants that were reinstated for each state.

### R code

```{r}
df_state_group <- df |>
  group_by(agency, org_state) |>
  mutate(num_grants = n()) |>
  ungroup() |>
  mutate(reinstated = ifelse(is.na(reinstatement_ind), FALSE, TRUE)) |>
  group_by(agency, org_state) |>
  mutate(num_reinstated = sum(reinstated)) |>
  ungroup() |>
  mutate(prop_reinstated = num_reinstated / num_grants) |>
  select(agency, org_state, prop_reinstated) |>
  distinct()

shp_and_df <- states_shp |>
  left_join(df_state_group, by = join_by(STUSPS == org_state))
```

### NIH

```{r}
#| echo: false
#| eval: true
shp_and_df |>
  filter(agency == "NIH") |>
  ggplot() +
  geom_sf(aes(fill = prop_reinstated)) +
  labs(title = "Reinstated Grants at Universities",
       subtitle = "NIH Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

### R code

```{r}
#| echo: true
#| eval: false
shp_and_df |>
  filter(agency == "NIH") |>
  ggplot() +
  geom_sf(aes(fill = prop_reinstated)) +
  labs(title = "Reinstated Grants at Universities",
       subtitle = "NIH Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

### NSF

```{r}
#| echo: false
#| eval: true
shp_and_df |>
  filter(agency == "NSF") |>
  ggplot() +
  geom_sf(aes(fill = prop_reinstated)) +
  labs(title = "Reinstated Grants at Universities",
       subtitle = "NSF Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

### R code

```{r}
#| echo: true
#| eval: false
shp_and_df |>
  filter(agency == "NSF") |>
  ggplot() +
  geom_sf(aes(fill = prop_reinstated)) +
  labs(title = "Reinstated Grants at Universities",
       subtitle = "NSF Grants",
       caption = "Source: Grant Witness") +
  scale_fill_gradient(low = "red", high = "blue") +
  theme_minimal()
```

:::::









# Projects

::::: {.panel-tabset}

## Splash

We will have hands-on coding experience here in SML 201.

Here are the projects being drafted for this semester.

## Birds

:::: {.columns}

::: {.column width="45%"}
### Ornithology

Explore a taxonomic data set

* concepts: exploratory data analyses, sample statistics
* areas: biology, ecology

Created by

* Professor Çağan Şekercioğlu
* University of Utah


:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

![Red-cheeked Cordonbleu](Red-cheeked-Cordonbleu_feature.png)

* image source: [Çağan Şekercioğlu](https://www.biology.utah.edu/news/dataset-tracks-ecological-traits-for-11k-birds/)
:::

::::

## QMOF

:::: {.columns}

::: {.column width="45%"}
### Quantum Metal–Organic Framework

The Quantum Metal–Organic Framework (QMOF) database contains quantum-chemical properties for over 14,000 experimental MOF crystal structures, computed using periodic density functional theory calculations.

* concepts: linear regression modeling
* areas: chemical engineering

Created by

* Professor Andrew Rosen
* Princeton University

:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![QMOF](qmof.png)

* image source: [Computational Chemical Sciences (CCS) Initiative](https://ccs-psi.org/node/70)

:::

::::

## Pitching

:::: {.columns}

::: {.column width="45%"}
### OpenBiomechanics

[The OpenBiomechanics Project](https://www.openbiomechanics.org/) is "The open source initiative for anonymized, elite-level athletic motion capture data"

* concepts: hypothesis testing, machine learning
* areas: physics, biophysics, physiology, kinesiology

Created by: [Driveline Baseball](https://www.drivelinebaseball.com/)
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![vectors](Driveline_bio_mechanics.png)

* image source: [Driveline Baseball](https://www.drivelinebaseball.com/2018/12/improving-durability-pitcher-using-biomechanics-lab/)
:::

::::

:::::


# Quo Vadimus?

:::: {.columns}

::: {.column width="45%"}
* Please read the weekly announcement in Canvas
* Due this Friday:

    * Software Installation
    * Precept 1
    * CLO Assessment
    * Demographics Survey
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* Project 1:

    * assigned: Feb 9
    * due: Feb 24
    
* Exam 1: Mar 5

::: {.callout-tip}

## Sign-In

If you're not enrolled yet, please sign-in (paper at the front of class)

:::
    
:::

::::


# Footnotes

::: {.callout-note collapse="true"}

## (optional) Additional Resources and References

:::

::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::