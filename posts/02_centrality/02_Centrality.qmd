---
title: "2: Centrality"
author: "Derek Sollberger"
date: "2026-11-29"
# format:
#   revealjs:
#     scrollable: true
format:
  html:
    toc: true
---

```{r}
#| echo: false
#| message: false
#| warning: false
library("gt")
library("tidyverse")
library("zoo")

some_data <- c(32, 45, 16, 78, 39)
olympic_df1 <- readr::read_csv("olympic_data.csv")
olympic_df2 <- readr::read_csv("olympic_data2.csv")
tickets_df <- readr::read_csv("tickets_days.csv")

flint_mdeq <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-11-04/flint_mdeq.csv')
flint_vt <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-11-04/flint_vt.csv')
```

# SML 201

## Start

:::: {.columns}

::: {.column width="45%"}
* **Goal**: Summarize data by centrality

* **Objective**: Compute means and medians
:::

::: {.column width="10%"}

:::

::: {.column width="45%"}
![The limit does not exist!](median_girls_meme.png)
:::

::::

::: {.callout-tip}
## Advice

* create a folder on your computer desktop called "SML 201"

    * later: place all code scripts and data sets in this folder
    
* To create a new Quarto document, open RStudio and then

    * `File` --> `New File` --> `Quarto Document ...`
    * save the file into your `SML 201` folder
    
* To run a line of code, the keyboard short cut is

    * Windows: CTRL + ENTER
    * Mac: CMD + ENTER
:::


# Apertif: Astronomy Tables

:::: {.columns}

::: {.column width="30%"}
![astronomy table](astronomical_table.png)	
:::

::: {.column width="10%"}
	
:::

::: {.column width="60%"}
* 1580: Uranienborg, observatory in Denmark
* 1592: Tycho Brahe publishes *Thousand Star Catalog*
* 1627: Kepler's Laws of Planetary Motion
:::

::::


# Mean

::: {.callout-note}
## Definition

For a list of data

$$\{a_{1}, a_{2}, ..., a_{n}\}$$

the **mean** or **average** of the data is defined as

$$\bar{x} = \displaystyle\frac{1}{n}\sum_{i = 1}^{n} a_{i}$$
where "x bar" denotes a **sample mean**
:::



## In R

Run each of these lines of code, and describe the code

```{r}
#| echo: true
#| eval: false
some_data <- c(32, 45, 16, 78, 39)
sum(some_data)
length(some_data)
sum(some_data) / length(some_data)
mean(some_data)
```

## Missing Data

Run each of these lines of code, and describe the code

```{r}
#| echo: true
#| eval: false
some_data <- c(32, 45, 16, 78, NA, 39)
sum(some_data)
length(some_data)
sum(some_data) / length(some_data)
mean(some_data)
mean(some_data, na.rm = TRUE)
```


::: {.callout-warning}
# DCP1
:::


# Case Study: Weights of Olympians

## Loading the Data

I have supplied a couple of data sets to a GitHub repository to ease the loading of data for classroom work.

```{r}
#| echo: true
#| eval: false
olympic_df1 <- readr::read_csv("https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv")
olympic_df2 <- readr::read_csv("https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv")
```

## Summary Statistics

Run each of these lines of code, and describe the code

```{r}
#| echo: true
#| eval: false
mean(olympic_df1$weight)
mean(olympic_df1$weight, na.rm = TRUE)
```

::: {.callout-tip collapse="true"}
## The fix

```{r}
olympic_df1$weight[olympic_df1$weight <= 0] <- NA
olympic_df2$weight[olympic_df2$weight <= 0] <- NA
```

:::


# Case Study: Ages of Olympians

## Filter

For this demonstration, let us focus on the athletes from Turkey.

```{r}
Turkey_df1 <- olympic_df1 |>
  filter(country_code == "TUR")
```


## Dotplot

Early in an introductory statistics course, a **dotplot** is useful for visualizing *integer* data.

```{r}
#| warning: false
mean_1 <- mean(Turkey_df1$age, na.rm = TRUE)

Turkey_df1 |>
  ggplot(aes(x = age)) +
  geom_dotplot() +
  geom_vline(xintercept = mean_1, color = "blue", linewidth = 3) +
  labs(title = "Ages of Turkish Athletics",
       subtitle = "mean in blue",
       caption = "SML 201")
```


## The Outlier

:::: {.columns}

::: {.column width="55%"}
![Yusuf Dikec](Yusuf_Dikec.png)

* image source: News 18
:::

::: {.column width="5%"}
	
:::

::: {.column width="40%"}
* Yusuf Dikec
* Turkish sharpshooter

    * silver medalist (2024 Olympics)
    * 10m air pistol mixed team

* Age: 51
:::

::::

## Filtered Again

```{r}
Turkey_df2 <- olympic_df2 |>
  filter(country_code == "TUR")
```

## Dotplot Revisited

Early in an introductory statistics course, a **dotplot** is useful for visualizing *integer* data.

```{r}
#| warning: false
mean_1 <- mean(Turkey_df1$age, na.rm = TRUE)
mean_2 <- mean(Turkey_df2$age, na.rm = TRUE)

Turkey_df2 |>
  ggplot(aes(x = age)) +
  geom_dotplot() +
  geom_vline(xintercept = mean_1, color = "blue", linewidth = 3) +
  geom_vline(xintercept = mean_2, color = "blue", linewidth = 3) +
  labs(title = "Ages of Turkish Athletics",
       subtitle = "mean in blue",
       caption = "SML 201")
```


# Median

Run each of these lines of code, and describe the code

```{r}
#| echo: true
#| eval: false
some_data <- c(32, 45, 16, 78, 39)
sort(some_data)
median(some_data)

some_data2 <- c(32, 45, 16, 78, 39, 5)
sort(some_data2)
median(some_data2)
```

::: {.callout-note}
## Definition

For a *sorted* list of data

$$\{a_{(1)}, a_{(2)}, ..., a_{(n)}\}$$

the **median** is the value in the middle of the list (splits list into 50 percentile halves).

* If there are an even amount of elements in the data, then the **median** is the *average* of the middle two values.
:::

## Medians

```{r}
#| warning: false
median_1 <- median(Turkey_df1$age, na.rm = TRUE)
median_2 <- median(Turkey_df2$age, na.rm = TRUE)

Turkey_df2 |>
  ggplot(aes(x = age)) +
  geom_dotplot() +
  geom_vline(xintercept = median_1, color = "red", linewidth = 3) +
  geom_vline(xintercept = median_2, color = "red", linewidth = 3) +
  labs(title = "Ages of Turkish Athletics",
       subtitle = "median in red",
       caption = "SML 201")
```


# Observed Differences

As a preview of concepts that we will need later (for hypothesis testing), we can practice computing a **difference in means** and a **difference in medians**

```{r}
#| eval: false
mean_1 #without outlier
mean_2 #with outlier
```


:::: {.panel-tabset}

## Difference in Means

:::: {.columns}

::: {.column width="45%"}
```{r}
mean_1 - mean_2
```	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
```{r}
abs(mean_1 - mean_2)
```
:::

::::


## Difference in Medians

:::: {.columns}

::: {.column width="45%"}
```{r}
median_1 - median_2
```
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
```{r}
abs(median_1 - median_2)
```
:::

::::



## Punchline

![Invincible](median_robust.png)

* The median is *robust* against outliers!
* image source: [Know Your Meme](https://knowyourmeme.com/memes/look-what-they-need-to-mimic-a-fraction-of-our-power)

::::



# Reporting

:::: {.panel-tabset}

## Why the mean?

Later, we use the mean for:

* normal distributions ("bell curves")
* linear regression goes through center of mass
* estimators and other statistical theory

## Which do we use?

:::: {.columns}

::: {.column width="60%"}
### When feasible, compute and report both the mean and median.	
:::

::: {.column width="10%"}
	
:::

::: {.column width="30%"}
![Why not both?](why_not_both.png)

* image source: [Know Your Meme](https://knowyourmeme.com/memes/why-not-both-why-dont-we-have-both)
:::

::::

::::


::: {.callout-warning}
# DCP2
:::


# Side Quest: Median Stack

:::: {.panel-tabset}

## Computer Vision

![RGB matrices](RBG_matrices.png)

* image credit: Ben Mauss

## Outlier Pixels

![Salt and pepper noise](salt_and_pepper_noise.png)

## Align Matrices

![take many still photos](many_shots.png)

## Median Stack Filter

![apply a median!](median_stack_result.png)

* source: [making people disappear from a photo](https://photofocus.com/software/photoshop-magic-making-people-disappear-from-a-scene/)

::::



# Mode

::: {.callout-warning}
## No mode function in R?

It appears that `R` doesn't have a built-in function to compute a statistical mode.

Instead, we will later use `tidyverse` techniques to compute mode(s) of data.
:::


# Segmentation

```{r}
set.seed(201)
segmented_data <- olympic_df2 |>
  select(country_code, gender, height, age) |>
  filter(country_code %in% c("CAN", "MEX", "USA")) |>
  group_by(country_code) |>
  mutate(xbar = mean(age, na.rm = TRUE)) |>
  sample_n(3) |>
  ungroup()
```


## Data types

In `R`, we use the `str` command to look at the *structure* of a data frame.

```{r}
str(segmented_data, give.attr = FALSE)
```

In this example,

* `country_code` and `gender` may be treated as *categorical data*
* `height` and `age` may be treated as *numerical data*


## Process

**Segmentation** is a **group by** operation followed by an **aggregation**:

* mean
* median
* mode
* minimum
* maximum

::::: {.panel-tabset}

### group by

```{r}
#| echo: false
#| eval: true

segmented_data |>
  select(country_code, age) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#D80621")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "CAN")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#006341")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "MEX")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#0A3161")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "USA")
  )
```

### gt

```{r}
#| echo: true
#| eval: false

segmented_data |>
  select(country_code, age) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#D80621")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "CAN")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#006341")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "MEX")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#0A3161")),
    locations = cells_body(columns = country_code,
                           rows = country_code == "USA")
  )
```

### mutate

```{r}
#| echo: false
#| eval: true

segmented_data |>
  select(country_code, age) |>
  mutate(xbar = NA) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "#121212"),
      cell_fill(color = "#E77500")),
    locations = cells_body(columns = xbar)
  )
```

### gt

```{r}
#| echo: true
#| eval: false

segmented_data |>
  select(country_code, age) |>
  mutate(xbar = NA) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "#121212"),
      cell_fill(color = "#E77500")),
    locations = cells_body(columns = xbar)
  )
```

### aggregation

```{r}
#| echo: false
#| eval: true

segmented_data |>
  select(country_code, age, xbar) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#D80621")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "CAN")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#006341")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "MEX")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#0A3161")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "USA")
  )
```

### gt

```{r}
#| echo: true
#| eval: false

segmented_data |>
  select(country_code, age, xbar) |>
  gt() |>
  cols_align(align = "center") |>
  tab_footnote(footnote = "Source: Kaggle, Petro Ivaniuk") |>
  tab_header(
    title = "Segmenting Data",
    subtitle = "(3 observations per group shown)"
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#D80621")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "CAN")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#006341")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "MEX")
  ) |>
  tab_style(
    style = list(
      cell_text(color = "white", weight = "bold"),
      cell_fill(color = "#0A3161")),
    locations = cells_body(columns = xbar,
                           rows = country_code == "USA")
  )
```

:::::


::: {.callout-warning}
# DCP3
:::


# Data History: Flint Water Quality

:::: {.columns}

::: {.column width="45%"}
* "exploring lead levels in water samples collected in Flint, Michigan in 2015"
* "samples collected by the Michigan Department of Environment (MDEQ) and data from a citizen science project coordinated by Prof Marc Edwards and colleagues at Virginia Tech"
* data hosted at [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-11-04/readme.md), curated by Jen Richmond
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Marc Edwards and LeeAnne Walters, pictured during a House Oversight and Government Reform Committee hearing](m_sign_14_2_16_gra-3.png)

* as described in *Significance* magazine, [Volume 14, Issue 2, April 2017](https://academic.oup.com/jrssig/article/14/2/16/7029247?login=false)
:::

::::

## Summary statistics

```{r}
mu1_mdeq <- mean(flint_mdeq$lead, na.rm = TRUE)
mu2_mdeq <- mean(flint_mdeq$lead2, na.rm = TRUE)
mu_vt <- mean(flint_vt$lead, na.rm = TRUE)

top10_1_mdeq <- quantile(flint_mdeq$lead, 0.90, na.rm = TRUE)
top10_2_mdeq <- quantile(flint_mdeq$lead2, 0.90, na.rm = TRUE)
top10_vt <- quantile(flint_vt$lead, 0.90, na.rm = TRUE)
```

### All MDEQ Samples

```{r}
summary(flint_mdeq$lead)
```

### Outliers Removed

```{r}
summary(flint_mdeq$lead2)
```

### Independent Test

```{r}
summary(flint_vt$lead)
```

## Histograms

:::: {.panel-tabset}

### All MDEQ Samples

```{r}
flint_mdeq |>
  ggplot() +
  geom_histogram(aes(x = lead),
                 binwidth = 5, color = "black", fill = "gray75") +
  geom_vline(xintercept = mu1_mdeq, color = "blue", 
             linetype = 2, linewidth = 2) +
  geom_vline(xintercept = top10_1_mdeq, color = "red", 
             linetype = 2, linewidth = 2) +
  labs(title = "Flint Water Samples in 2015",
       subtitle = "MDEQ measurements (average in blue, top 10 percentile in red)",
       caption = "Source: Jen Richmond",
       x = "lead (ppb)", y = "number of samples") +
  theme_minimal()
```

### Outliers Removed

```{r}
flint_mdeq |>
  ggplot() +
  geom_histogram(aes(x = lead2),
                 binwidth = 5, color = "black", fill = "gray75") +
  geom_vline(xintercept = mu1_mdeq, color = "blue", 
             linetype = 2, linewidth = 2) +
  geom_vline(xintercept = top10_2_mdeq, color = "red", 
             linetype = 2, linewidth = 2) +
  labs(title = "Flint Water Samples in 2015",
       subtitle = "MDEQ measurements, two samples missing (average in blue, top 10 percentile in red)",
       caption = "Source: Jen Richmond",
       x = "lead (ppb)", y = "number of samples") +
  theme_minimal()
```

### Independent Test

```{r}
flint_vt |>
  ggplot() +
  geom_histogram(aes(x = lead),
                 binwidth = 5, color = "black", fill = "gray75") +
  geom_vline(xintercept = mu1_mdeq, color = "blue", 
             linetype = 2, linewidth = 2) +
  geom_vline(xintercept = top10_vt, color = "red", 
             linetype = 2, linewidth = 2) +
  labs(title = "Flint Water Samples in 2015",
       subtitle = "VT measurements (average in blue, top 10 percentile in red)",
       caption = "Source: Jen Richmond",
       x = "lead (ppb)", y = "number of samples") +
  theme_minimal()
```

::::




## Diagnoses

"the Lead and Copper Rule (LCR) of 1991 is 15 parts per billion (ppb). If this is exceeded in more than 10% of homes tested (or if the 90th percentile value of the total sample is above 15 ppb), action is required." --- [Significance, Vol 14, Issue 2](https://academic.oup.com/jrssig/article/14/2/16/7029247?login=false)

### All MDEQ Samples

```{r}
ifelse(quantile(flint_mdeq$lead, 0.90, na.rm = TRUE) > 15,
       "action required", "safe water")
```

### Outliers Removed

```{r}
ifelse(quantile(flint_mdeq$lead2, 0.90, na.rm = TRUE) > 15,
       "action required", "safe water")
```

### Independent Test

```{r}
ifelse(quantile(flint_vt$lead, 0.90, na.rm = TRUE) > 15,
       "action required", "safe water")
```

# Coda

::: {.callout-note}

## Do we remove outliers?

* We should not automatically remove outliers
* Deciding on removing outliers is very context dependent.

:::

# Quo Vadimus?

:::: {.columns}

::: {.column width="45%"}
* Please read the weekly announcement in Canvas
* Due this Friday:

    * Software Installation
    * Precept 1
    * CLO Assessment
    * Demographics Survey
    
* Project 1:

    * assigned: Feb 9
    * due: Feb 24
    
* Exam 1: Mar 5
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![](statistics_rhyme.png)
:::

::::


# Footnotes

::: {.callout-note collapse="true"}
## (optional) How the data set was altered

I altered the following `olympics_data.csv` to make classroom demonstrations.

```{r}
#| echo: true
#| eval: false

Q <- readr::read_csv("athletes.csv")
Q$weight[Q$weight <=0] <- -99 #imitate old-fashioned missing value recording
Q$age <- lubridate::year("2024-07-26") - lubridate::year(Q$birth_date)
W <- Q |> dplyr::filter(age <= 30)
readr::write_csv(Q, "olympic_data2.csv")
readr::write_csv(W, "olympic_data.csv")
```

:::

::: {.callout-note collapse="true"}

## (optional) Additional Resources

* great explanation of a [moving average](https://www.ablebits.com/office-addins-blog/moving-average-excel/)

:::

## Application (optional): Rolling Mean

:::: {.panel-tabset}

### Data 

:::: {.columns}

::: {.column width="45%"}
* source: [TidyTuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-12-03) (2019-12-03)

* [Open Data Philly](https://opendataphilly.org/datasets/parking-violations/)

    * filtered to year 2017 data that had latitude/longitude	
    
* objective: summarize trends in ticketing
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Philadelphia Parking Authority](PPA.png)

* image source: Matt Rourke/AP Photo
:::

::::

### Wrangling

```{r}
#| echo: true
#| eval: false

# i.e. started with a very large data set
# and needed to pare it down
tickets_raw <- readr::read_csv("tickets.csv")
tickets_days <- tickets_raw |>
  separate(issue_datetime, sep = " ",
           into = c("date", "time")) |>
  group_by(date) |>
  count(date) |>
  ungroup() |>
  select(date, n)
readr::write_csv(tickets_days, "tickets_days.csv")

tickets_df <- readr::read_csv("tickets_days.csv")
```


::::

### Time Series

:::: {.panel-tabset}

### Viz

```{r}
#| echo: false
#| eval: true

tickets_df |>
  ggplot(aes(x = date, y = n)) +
  geom_line() +
  labs(title = "Parking Tickets in Philadelphia",
       subtitle = "Street Sweeping Violations (2017)",
       caption = "Source: Open Data Philly",
       y = "number of tickets") +
  theme_minimal()
```

### Code

```{r}
#| echo: true
#| eval: false

tickets_df |>
  ggplot(aes(x = date, y = n)) +
  geom_line() +
  labs(title = "Parking Tickets in Philadelphia",
       subtitle = "Street Sweeping Violations (2017)",
       caption = "Source: Open Data Philly",
       y = "number of tickets") +
  theme_minimal()
```

::::

### Moving Average

:::: {.panel-tabset}

### Concept

A **rolling mean** or **moving average** compues the mean across a group of $L$ (lag) consecutive data points in a time series and slides the "window".

### 3

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 3, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 3 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 5

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 5, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 35 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 7

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 7, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 7 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 9

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 9, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 9 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 11

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 11, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 11 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### Code

```{r}
#| echo: true
#| eval: false
#| warning: false

tickets_df |>
  mutate(roll_mean = zoo::rollapply(
    n, 3, mean, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_mean),
            color = "blue") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling mean in blue (n = 3 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

::::

### Rolling Median

:::: {.panel-tabset}

### 3

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 3, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 3 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 5

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 5, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 5 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 7

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 7, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 7 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 9

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 9, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 9 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### 11

```{r}
#| echo: false
#| eval: true
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 11, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 11 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

### Code

```{r}
#| echo: true
#| eval: false
#| warning: false

tickets_df |>
  mutate(roll_median = zoo::rollapply(
    n, 3, median, align = 'left', fill = NA
  )) |>
    ggplot() +
    geom_point(aes(x = date, y = n),
               color = "black") +
  geom_line(aes(x = date, y = roll_median),
            color = "red") +
    labs(title = "Parking Tickets in Philadelphia",
         subtitle = "Rolling median in red (n = 3 day window)",
         caption = "Source: Open Data Philly",
         y = "number of tickets") +
    theme_minimal()
```

::::

::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::