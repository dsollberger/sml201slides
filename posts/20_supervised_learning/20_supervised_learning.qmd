---
title: "20: Supervised Learning"
author: "Derek Sollberger"

date: "2024-11-19"
format:
  html:
    toc: true
    theme: cerulean
---

# SML 201

## Start

::: {.callout-note collapse="true"}
## Libraries and Loading the Data

```{r}
#| message: false
#| warning: false

library("corrplot")
library("tidyclust")
library("tidymodels")
library("tidyverse")

# school colors
princeton_orange <- "#E77500"
princeton_black  <- "#121212"

# data set: GPT detectors
office_raw <- readr::read_csv('office_sentiment.csv')
# office_raw <- readr::read_csv("https://raw.githubusercontent.com/dsollberger/sml201slides/main/data/office_sentiment.csv")
```

:::

:::: {.columns}

::: {.column width="50%"}
* **Goal**: Explore topics in supervised learning


:::

::: {.column width="10%"}

:::

::: {.column width="40%"}
* **Objectives**: 

- `tidymodels`
- ridge regression
- LASSO regression
:::

::::


# Case Study: Sentiment in The Office

The data set this week come from the `schrute` package, and it features the scripts from the popular TV show *The Office*.  I have augmented the data with sentiment analyses scores from three algorithms

1. `syuzhet`
2. `sentimentr`
3. `sentimentAnalysis`

Each row of the data frame is a spoken line of dialogue.  From there, the data has the following variables:

* `index`: to easily refer to a particular row in the data
* `season`: The Office ran for 9 seasons
* `episode`: the episode number within a season
* `episode_name`
* `director`
* `writer`
* `character`: the fictional character of the TV show
* `text`: the spoken text in the line of dialogue
* `text_w_direction`: ... includes stage direction
* `imdb_rating`: Internet Movie Database rating for the episode (from 0 to 10, which 10 being the highest)
* `total_votes`: number of IMdB users that voted on that episode
* `air_date`
* `sentimentAnalysis_score`
* `sentimentr_score`
* `syuzhet_score`

::: {.callout-note}
## Research Question

In this session, we will define **cringe** as the standard deviation of a sentiment analysis score. Are the `imdb_rating` values explained by the *cringe* of the episodes?
:::

## Filtering

```{r}
office_df <- office_raw |>
  select(imdb_rating,
         season, episode, total_votes,
         sentimentAnalysis_score, sentimentr_score, syuzhet_score) |>
  rename(ep_in_season = episode,
         sent1 = syuzhet_score,
         sent2 = sentimentr_score,
         sent3 = sentimentAnalysis_score)
```

## Derived Variables

```{r}
office_df <- office_df |>
  group_by(season, ep_in_season) |>
  mutate(sent1_mean = mean(sent1, na.rm = TRUE),
         sent2_mean = mean(sent2, na.rm = TRUE),
         sent3_mean = mean(sent3, na.rm = TRUE),
         sent1_dev = sd(sent1, na.rm = TRUE),
         sent2_dev = sd(sent2, na.rm = TRUE),
         sent3_dev = sd(sent3, na.rm = TRUE)) |>
  ungroup() |>
  select(imdb_rating,
         sent1_mean, sent2_mean, sent3_mean,
         sent1_dev, sent2_dev, sent3_dev,
         season, ep_in_season, total_votes) |>
  distinct() |>
  mutate(episode_num = 1:n())
```

## Correlation Plot

```{r}
office_df |>
  cor(use = "pairwise.complete.obs") |>
  corrplot(method = "number",
           order = "FPC",
           type = "upper")
```


# Linear Regression

* model equation:

$$\hat{y} = \beta_{0} + \sum_{j=1}^{k} \beta_{j}X_{j}$$
* loss function:

$$L(\vec{\beta}) = \text{argmin}_{\vec{\beta}} \sum_{i=1}^{N} \left(y_{i} - \beta_{0} - \sum_{j=1}^{k} \beta_{j}x_{ij}\right)$$

```{r}
lin_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(imdb_rating ~ ., data = office_df)
```

```{r}
tidy(lin_fit)
```

$$\text{RSME} = \sqrt{\frac{\sum_{i=1}^{n}(y_{i} - \hat{y})^{2}}{n-k-1}}$$

```{r}
predictions <- predict(lin_fit, 
                       new_data = office_df |>
                         select(-imdb_rating))
true_values <- office_df |> select(imdb_rating)
n <- office_df |> drop_na(imdb_rating) |> nrow()
k <- ncol(office_df) - 1
RMSE <- sqrt((1/(n-k-1))*sum((true_values - predictions)^2))
print(RMSE)
```


::: {.callout-warning}
## Size of regression coefficients?

Do the size of the regression coefficients ($\beta_{i}$) matter?  Are the sizes of the regression coefficients related to the units of the measurements?
:::


# Ridge Regression

* loss function:

$$L(\vec{\beta}, \lambda) = \text{argmin}_{\vec{\beta}} \left[\sum_{i=1}^{N} \left(y_{i} - \beta_{0} - \sum_{j=1}^{k} \beta_{j}x_{ij}\right) + \lambda\sum_{j=i}^{k}\beta_{j}^{2}\right]$$

```{r}
ridge_fit <- linear_reg(mixture = 0, penalty = 0) |>
  set_engine("glmnet") |>
  fit(imdb_rating ~ ., data = office_df)
```

## Penalties

```{r}
tidy(ridge_fit, penalty = 0)
```

```{r}
tidy(ridge_fit, penalty = 201)
```

```{r}
ridge_fit |> autoplot()
```

## Predictions

```{r}
predict(ridge_fit,
        new_data = office_df |> select(-imdb_rating),
        penalty = 0) |>
  head()
```

```{r}
predict(ridge_fit,
        new_data = office_df |> select(-imdb_rating),
        penalty = 201) |>
  head()
```

## Lambda Grid

```{r}
lambda_vals <- 10^seq(-3,3, length.out = 10)
format(lambda_vals, scientific=FALSE)
lambda_grid <- grid_regular(penalty(range = c(-3, 3)),
                            levels = 50)
```

### Data Split

```{r}
office_split <- initial_split(office_df, strata = "imdb_rating")
office_train <- training(office_split)
office_test  <- testing(office_split)
office_fold  <- vfold_cv(office_train, v = 10)
```

### Preprocessing

```{r}
ridge_recipe <- recipe(formula = imdb_rating ~ ., 
                       data = office_train) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())
```

### Specification

```{r}
ridge_spec <- linear_reg(mixture = 0, penalty = tune()) |>
  set_engine("glmnet")
```

### Workflow

```{r}
ridge_workflow <- workflow() |>
  add_recipe(ridge_recipe) |>
  add_model(ridge_spec)
```

### Tuning

```{r}
#| warning: false
tune_results <- tune_grid(
  ridge_workflow,
  resamples = office_fold,
  grid = lambda_grid
)
```
```{r}
tune_results |> autoplot()
```

```{r}
tune_results |> collect_metrics() |> head()
```

```{r}
# tune_results |>
#   collect_metrics() |>
#   filter(.metric == "rmse") |>
#   filter(mean == min(mean))
```

## Predictions Refined

```{r}
# best_lambda <- tune_results |>
#   collect_metrics() |>
#   filter(.metric == "rmse") |>
#   filter(mean == min(mean)) |>
#   distinct() |>
#   pull(penalty)

best_lambda <- select_best(tune_results, metric = "rmse") |>
  pull(penalty)

predict(ridge_fit,
        new_data = office_df |> select(-imdb_rating),
        penalty = best_lambda) |>
  head()
```


# LASSO Regression

* **L**east **A**bsolute **S**hrinkage and **S**election **O**perator regression
* loss function:

$$L(\vec{\beta}, \lambda) = \text{argmin}_{\vec{\beta}} \left[\sum_{i=1}^{N} \left(y_{i} - \beta_{0} - \sum_{j=1}^{k} \beta_{j}x_{ij}\right) + \lambda\sum_{j=i}^{k}|\beta_{j}|\right]$$
```{r}
lasso_fit <- linear_reg(mixture = 1, penalty = 0) |>
  set_engine("glmnet") |>
  fit(imdb_rating ~ ., data = office_df)
```

```{r}
lasso_fit |> autoplot()
```

## Coefficients

```{r}
tidy(lasso_fit, penalty = 1e-2)
```

```{r}
tidy(lasso_fit, penalty = 1e-1)
```

## Lambda Grid
### Preprocessing

```{r}
lasso_recipe <- recipe(formula = imdb_rating ~ ., 
                       data = office_train) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize()
```

### Specification

```{r}
lasso_spec <- linear_reg(mixture = 1, penalty = tune()) |>
  set_engine("glmnet")
```

### Workflow

```{r}
lasso_workflow <- workflow() |>
  add_recipe(lasso_recipe) |>
  add_model(lasso_spec)
```

### Tuning

```{r}
#| warning: false

lambda_grid <- grid_regular(penalty(range = c(-2, -1)),
                            levels = 25)

tune_results <- tune_grid(
  lasso_workflow,
  resamples = office_fold,
  grid = lambda_grid
)
```

```{r}
tune_results |> autoplot()
```

## Explanatory Variables

```{r}
tune_results |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  filter(mean == min(mean))
```


```{r}
best_lambda <- select_best(tune_results, metric = "rmse") |>
  pull(penalty)

tidy(lasso_fit, penalty = best_lambda)
```


# Principal Components Regression

::: {.callout-tip collapse="true"}
## PCA

**Principal Component Analysis** (PCA) is a popular algorithm for *dimensionality reduction*.
:::

## Preprocessing

```{r}
pca_recipe <- 
  recipe(formula = imdb_rating ~ ., data = office_train) |> 
  step_normalize(all_predictors()) |>
  step_pca(all_predictors(), threshold = tune())
```

## Specification

```{r}
lm_spec <- 
  linear_reg() |>
  set_engine("lm")
```

## Workflow

```{r}
pca_workflow <- 
  workflow() |>
  add_recipe(pca_recipe) |>
  add_model(lm_spec)
```

## Tuning

```{r}
#| warning: false

lambda_grid <- grid_regular(threshold(),
                            levels = 20)

tune_results <- tune_grid(
  pca_workflow,
  resamples = office_fold,
  grid = lambda_grid
)
```

```{r}
tune_results |> autoplot()
```

```{r}
best_threshold <- select_best(tune_results, metric = "rmse")
pca_refined <- finalize_workflow(pca_workflow, best_threshold)
pca_fit <- fit(pca_refined, data = office_train)
```

## Visualization

```{r}
flat_data <- pca_recipe <- 
  recipe(formula = imdb_rating ~ ., data = office_train) |> 
  step_normalize(all_predictors()) |>
  step_pca(all_predictors()) |> 
  prep() |>
  juice() |>
  select(imdb_rating, PC1, PC2)
```

```{r}
kmeans_fit <- k_means(num_clusters = 5) |>
  set_engine("stats") |>
  fit(imdb_rating ~ PC1 + PC2, data = flat_data)
```

```{r}
flat_data |>
  mutate(cluster_num = extract_cluster_assignment(kmeans_fit) |>
           pull()) |>
  ggplot(aes(x = PC1, y = PC2, color = cluster_num)) +
  geom_point() +
  labs(title = "The Office",
       subtitle = "inputs projected onto first two principal components",
       caption = "Source: Schrute package",
       x = "principal component 1", y = "principal component 2") +
  theme_minimal()
```


# Precept 10

:::: {.columns}

::: {.column width="45%"}
* MLB players from 1986
* explanatory variables: offense stats for hitters
* predict 1987 salaries
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
![Meet the Mets!](Mets_1986.png)
:::

::::


# Quo Vadimus?

:::: {.columns}

::: {.column width="40%"}
* Precept 10
* Project 3 (Due Nov 20)
* CLO Assessment
* Exam 2 (December 5)
:::

::: {.column width="10%"}
	
:::

::: {.column width="50%"}
![Ted Lasso](Ted_Lasso.png)

* TODO: watch *Ted Lasso* to generate nerdy jokes

:::

::::


# Footnotes

::: {.callout-note collapse="true"}
## (optional) Additional Resources

* [ISLR tidymodels labs](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/) by Emil Hvitfeldt

:::

::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


::: {.callout-note collapse="true"}
## Example Callout Block

`note`, `tip`, `warning`, `caution`, or `important`
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::