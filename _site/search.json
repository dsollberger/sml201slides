[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SML 201 (Fall 2024)",
    "section": "",
    "text": "10: Modeling Categorical Variables\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n8: Multiple Linear Regression\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n8: Linear Regression\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n7: Correlation\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n6: Geospatial\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n5: Networks\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n4: Categories\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n3: Variance\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n2: Centrality\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n1: Introductions\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html",
    "href": "posts/01_introduction/01_introduction.html",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce data science\nObjective: Explore a data set with bar graphs and facets\n\n\n\n\n\nImage credit: Steven Geringer"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#start",
    "href": "posts/01_introduction/01_introduction.html#start",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce data science\nObjective: Explore a data set with bar graphs and facets\n\n\n\n\n\nImage credit: Steven Geringer"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#sml-201-introduction-to-data-science",
    "href": "posts/01_introduction/01_introduction.html#sml-201-introduction-to-data-science",
    "title": "1: Introductions",
    "section": "",
    "text": "Fall 2024\nTuesdays and Thursdays\n\n11 AM to 1220 PM: Lewis Library 120\n130 PM to 250 PM: Lewis Library 120\n\nLecturer: Derek\n\nI go by “Derek” or “teacher”\n\n\n\n\n\n\n\n\nCourse Description\n\n\n\n\n\nIntroduction to Data Science provides a practical introduction to the burgeoning field of data science. The course introduces students to the essential tools for conducting data-driven research, including the fundamentals of programming techniques and the essentials of statistics. Students will work with real-world datasets from various domains; write computer code to manipulate, explore, and analyze data; use basic techniques from statistics and machine learning to analyze data; learn to draw conclusions using sound statistical reasoning; and produce scientific reports. No prior knowledge of programming or statistics is required."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#lecturer",
    "href": "posts/01_introduction/01_introduction.html#lecturer",
    "title": "1: Introductions",
    "section": "Lecturer",
    "text": "Lecturer"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "href": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "title": "1: Introductions",
    "section": "Current Research in Pedagogy",
    "text": "Current Research in Pedagogy\n\n\n\n\n\nactive learning\ncomputer programming\nflipped classrooms"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#identity-statement",
    "href": "posts/01_introduction/01_introduction.html#identity-statement",
    "title": "1: Introductions",
    "section": "Identity Statement",
    "text": "Identity Statement\n\n\n\nOriginally from Los Angeles\nMath: easier to understand through graphs\nComputer Programming: years of experience with R, Python, MATLAB, PHP, HTML, etc.\nLearning: drawn to puzzles and manageable tasks\nPersonality: shy, introvert"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#textbooks",
    "href": "posts/01_introduction/01_introduction.html#textbooks",
    "title": "1: Introductions",
    "section": "Textbooks",
    "text": "Textbooks\n\n\n\n\n\nR for Data Science\n\n\n\nThis course will loosely follow\n\nR for Data Science by Hadley Wickham, Mine Cetinkaya-Rundel, and Garrett Grolemund (online textbook)\nStatistical Inference via Data Science by Chester Ismay and Albert Y Kim (online textbook)\n\n\n\n\n\nModern Dive"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#additional-reading",
    "href": "posts/01_introduction/01_introduction.html#additional-reading",
    "title": "1: Introductions",
    "section": "Additional Reading",
    "text": "Additional Reading\nThe following list of books is optional for student studies, but the instructor may use some materials to add depth and interest to the course.\n\n\n\n\n\n\nAdditional Reading\n\n\n\n\n\n\nThe Seven Pillars of Statistical Wisdom by Stephen M Stigler provides a wonderful overview of the history of statistics and the field’s major developments.\nStatistical Rethinking by Richard McElreath is the premier body of work in the field of Bayesian analysis. This resource is great for people who want to build a strong foundation in philosophy and theory in this branch of mathematics.\nTeaching Statistics by Andrew Gelman and Deborah Nolan features a variety of classroom activities that engage audiences at prestigious universities into learning statistical concepts.\nBernoulli’s Fallacy by Aubrey Clayton is a scathing review of the history of statistics and posits that the foundations of the field are flawed."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "href": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "title": "1: Introductions",
    "section": "Cooperative Classroom",
    "text": "Cooperative Classroom\nLearning in a cooperative environment should be stimulating, demanding, and fair. Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations. Below are my expectations for students in this class. This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words. If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.\n\nStudents are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.\nWhen working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others. Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.\nStudents should explore data, make observations, and develop inferences as part of a group. If you use material from published sources, you must provide appropriate attribution.\n\n\n\n(Students will be asked to acknowledge this document in an online form.)\nThis document has been adapted from Scientific Teaching by Jo Handelsman, Sarah Miller, and Christine Pfund\n\n\n\n\nScientific Teaching"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#pep-talk",
    "href": "posts/01_introduction/01_introduction.html#pep-talk",
    "title": "1: Introductions",
    "section": "Pep Talk",
    "text": "Pep Talk\nLearning R can be difficult at first—it is like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you will be using like ggplot2—made this wise observation:\n\n\n\n\n\n\nWisdom from Hadley Wickham\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nIf you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions … e-mail [Derek], etc. I promise you can do this.\n—Andrew Heiss, Georgia State University"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "href": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "title": "1: Introductions",
    "section": "Inclusion Statement",
    "text": "Inclusion Statement\nI value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment)."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#concern-for-bee-populations",
    "href": "posts/01_introduction/01_introduction.html#concern-for-bee-populations",
    "title": "1: Introductions",
    "section": "Concern for Bee Populations",
    "text": "Concern for Bee Populations\n\n\n\n\n\nTime\n\n\n\n\n\n\n\n\nABC"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#finding-data",
    "href": "posts/01_introduction/01_introduction.html#finding-data",
    "title": "1: Introductions",
    "section": "Finding Data",
    "text": "Finding Data\n\nUS Dept of Agriculture\nNational Agricultural Statistics Service\n\n\nLoading DataR Code\n\n\n\n\n# A tibble: 4 × 7\n  Program  Year   Value `Geo Level` State    Commodity `Data Item`              \n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                    \n1 SURVEY   2015 2849500 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n2 SURVEY   2016 2801470 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n3 SURVEY   2017 2694150 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n4 SURVEY   2018 2665880 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n\n\n\n\n\nbee_df &lt;- readr::read_csv(\"bee_population.csv\")\nhead(bee_df)"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#presenting-narrative",
    "href": "posts/01_introduction/01_introduction.html#presenting-narrative",
    "title": "1: Introductions",
    "section": "Presenting Narrative",
    "text": "Presenting Narrative"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#why-r",
    "href": "posts/01_introduction/01_introduction.html#why-r",
    "title": "1: Introductions",
    "section": "Why R?",
    "text": "Why R?\n\n\n\n\n\nR\n\n\n\n\n\n\nmatches data science concepts well\nlanguage made for statistics and probability calculations\nsoftware compatibility\neasier to learn\neasier to teach\ngaining popularity in areas such as consulting, finance, epidemiology, genomics, pharmaceuticals, etc."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#r-vs-python",
    "href": "posts/01_introduction/01_introduction.html#r-vs-python",
    "title": "1: Introductions",
    "section": "R vs Python",
    "text": "R vs Python\n\ntablegt code\n\n\n\n\n\n\n\n\n\n\nData Science Programming Languages\n\n\nWhich one is better?\n\n\nR\nPython\n\n\n\n\nData Science\nMachine Learning\n\n\nDashboards\nSoftware Development\n\n\nInteractvity\nObject-Oriented Programming\n\n\nVisualization\nBig Data\n\n\nDebugging\nFaster\n\n\n\nsource: Derek's opinion\n\n\n\n\n\n\n\n\n\n\n\nlanguages_df &lt;- data.frame(\n  R = c(\"Data Science\", \"Dashboards\", \"Interactvity\", \"Visualization\", \"Debugging\"),\n  Python = c(\"Machine Learning\", \"Software Development\", \"Object-Oriented Programming\", \"Big Data\", \"Faster\")\n)\n\nlanguages_df |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"source: Derek's opinion\") |&gt;\n  tab_header(\n    title = \"Data Science Programming Languages\",\n    subtitle = \"Which one is better?\"\n  ) |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = \"#ffc100\")\n    ),\n    locations = cells_body(columns = R)\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = \"#d0cef3\")\n    ),\n    locations = cells_body(columns = Python)\n  )"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#critique",
    "href": "posts/01_introduction/01_introduction.html#critique",
    "title": "1: Introductions",
    "section": "Critique",
    "text": "Critique\n\n\nCritique this graph. What comments do you have about it?"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#continuing-the-narrative",
    "href": "posts/01_introduction/01_introduction.html#continuing-the-narrative",
    "title": "1: Introductions",
    "section": "Continuing the Narrative",
    "text": "Continuing the Narrative\n\nMore DataCodeFacetsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbee_totals_df |&gt;\n  mutate(num_colonies = Value / 1e6) |&gt;\n  ggplot(aes(x = factor(Year), y = num_colonies)) +\n  geom_bar(color = \"#121212\", fill = \"#E77500\",\n           stat = \"identity\") +\n  labs(title = \"US Bee Population\",\n       subtitle = \"Survey of bee colonies\",\n       caption = \"source: USDA NASS\",\n       x = \"year\",\n       y = \"bee colonies (in millions)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbee_states_df |&gt;\n  # filter(Year &gt;= 2015 & Year &lt;= 2018) |&gt;\n  filter(State %in% c(\"NEW JERSEY\", \"CALIFORNIA\")) |&gt;\n  ggplot(aes(x = factor(Year), y = Value)) +\n  facet_wrap(vars(State), ncol = 1, scales = \"free_y\") +\n  geom_bar(color = \"#121212\", fill = \"#E77500\",\n           stat = \"identity\") +\n  labs(title = \"US Bee Population\",\n       subtitle = \"Selection of States\",\n       caption = \"source: USDA NASS\",\n       x = \"year\",\n       y = \"bee colonies\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#epilogue",
    "href": "posts/01_introduction/01_introduction.html#epilogue",
    "title": "1: Introductions",
    "section": "Epilogue",
    "text": "Epilogue\n * inspiration: Wait, does America suddenly have a record number of bees? by Andrew Van Dam"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html",
    "href": "posts/02_centrality/02_Centrality.html",
    "title": "2: Centrality",
    "section": "",
    "text": "Goal: Summarize data by centrality\nObjective: Compute mean, median, and mode\n\n\n\n\n\n\n\nThe limit does not exist!\n\n\n\n\n\n\n\n\ncreate a folder on your computer desktop called “SML 201”\n\nlater: place all code scripts and data sets in this folder\n\nopen RStudio and create a new Quarto document\n\nFile –&gt; New File –&gt; Quarto Document ...\nsave the file into your SML 201 folder\n\nTo run a line of code, the keyboard short cut is\n\nWindows: CTRL + ENTER\nMac: CMD + ENTER"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#start",
    "href": "posts/02_centrality/02_Centrality.html#start",
    "title": "2: Centrality",
    "section": "",
    "text": "Goal: Summarize data by centrality\nObjective: Compute mean, median, and mode\n\n\n\n\n\n\n\nThe limit does not exist!"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#advice",
    "href": "posts/02_centrality/02_Centrality.html#advice",
    "title": "2: Centrality",
    "section": "",
    "text": "create a folder on your computer desktop called “SML 201”\n\nlater: place all code scripts and data sets in this folder\n\nopen RStudio and create a new Quarto document\n\nFile –&gt; New File –&gt; Quarto Document ...\nsave the file into your SML 201 folder\n\nTo run a line of code, the keyboard short cut is\n\nWindows: CTRL + ENTER\nMac: CMD + ENTER"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#definition",
    "href": "posts/02_centrality/02_Centrality.html#definition",
    "title": "2: Centrality",
    "section": "Definition",
    "text": "Definition\nFor a list of data\n\\[\\{a_{1}, a_{2}, ..., a_{n}\\}\\]\nthe mean or average of the data is defined as\n\\[\\bar{x} = \\displaystyle\\frac{1}{n}\\sum_{i = 1}^{n} a_{i}\\] where “x bar” denotes a sample mean"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#in-r",
    "href": "posts/02_centrality/02_Centrality.html#in-r",
    "title": "2: Centrality",
    "section": "In R",
    "text": "In R\nRun each of these lines of code, and describe the code\n\nsome_data &lt;- c(32, 45, 16, 78, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#missing-data",
    "href": "posts/02_centrality/02_Centrality.html#missing-data",
    "title": "2: Centrality",
    "section": "Missing Data",
    "text": "Missing Data\nRun each of these lines of code, and describe the code\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)\nmean(some_data, na.rm = TRUE)"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#loading-the-data",
    "href": "posts/02_centrality/02_Centrality.html#loading-the-data",
    "title": "2: Centrality",
    "section": "Loading the Data",
    "text": "Loading the Data\nI have supplied a couple of data sets to a GitHub repository to ease the loading of data for classroom work.\n\nolympic_df1 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv\")\nolympic_df2 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#summary-statistics",
    "href": "posts/02_centrality/02_Centrality.html#summary-statistics",
    "title": "2: Centrality",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nRun each of these lines of code, and describe the code\n\nmean(olympic_df1$weight)\nmean(olympic_df1$weight, na.rm = TRUE)\n\n\n\n\n\n\n\nThe fix\n\n\n\n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#filter",
    "href": "posts/02_centrality/02_Centrality.html#filter",
    "title": "2: Centrality",
    "section": "Filter",
    "text": "Filter\nFor this demonstration, let us focus on the athletes from Turkey.\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#dotplot",
    "href": "posts/02_centrality/02_Centrality.html#dotplot",
    "title": "2: Centrality",
    "section": "Dotplot",
    "text": "Dotplot\nEarly in an introductory statistics course, a dotplot is useful for visualizing integer data.\n\nmean_1 &lt;- mean(Turkey_df1$age, na.rm = TRUE)\n\nTurkey_df1 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#the-outlier",
    "href": "posts/02_centrality/02_Centrality.html#the-outlier",
    "title": "2: Centrality",
    "section": "The Outlier",
    "text": "The Outlier\n\n\n\n\n\nYusuf Dikec\n\n\n\nimage source: News 18\n\n\n\n\n\nYusuf Dikec\nTurkish sharpshooter\n\nsilver medalist (2024 Olympics)\n10m air pistol mixed team\n\nAge: 51"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#filtered-again",
    "href": "posts/02_centrality/02_Centrality.html#filtered-again",
    "title": "2: Centrality",
    "section": "Filtered Again",
    "text": "Filtered Again\n\nTurkey_df2 &lt;- olympic_df2 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#dotplot-revisited",
    "href": "posts/02_centrality/02_Centrality.html#dotplot-revisited",
    "title": "2: Centrality",
    "section": "Dotplot Revisited",
    "text": "Dotplot Revisited\nEarly in an introductory statistics course, a dotplot is useful for visualizing integer data.\n\nmean_1 &lt;- mean(Turkey_df1$age, na.rm = TRUE)\nmean_2 &lt;- mean(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  geom_vline(xintercept = mean_2, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#medians",
    "href": "posts/02_centrality/02_Centrality.html#medians",
    "title": "2: Centrality",
    "section": "Medians",
    "text": "Medians\n\nmedian_1 &lt;- median(Turkey_df1$age, na.rm = TRUE)\nmedian_2 &lt;- median(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = median_1, color = \"red\", linewidth = 3) +\n  geom_vline(xintercept = median_2, color = \"red\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"median in red\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#difference-in-means",
    "href": "posts/02_centrality/02_Centrality.html#difference-in-means",
    "title": "2: Centrality",
    "section": "Difference in Means",
    "text": "Difference in Means\n\nmean_1 - mean_2\n\n[1] -1.92449\n\nabs(mean_1 - mean_2)\n\n[1] 1.92449"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#difference-in-medians",
    "href": "posts/02_centrality/02_Centrality.html#difference-in-medians",
    "title": "2: Centrality",
    "section": "Difference in Medians",
    "text": "Difference in Medians\n\nmedian_1 - median_2\n\n[1] 0\n\nabs(median_1 - median_2)\n\n[1] 0"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#punchline",
    "href": "posts/02_centrality/02_Centrality.html#punchline",
    "title": "2: Centrality",
    "section": "Punchline",
    "text": "Punchline\n\n\n\nInvincible\n\n\n\nThe median is robust against outliers!\nimage source: Know Your Meme"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#why-the-mean",
    "href": "posts/02_centrality/02_Centrality.html#why-the-mean",
    "title": "2: Centrality",
    "section": "Why the mean?",
    "text": "Why the mean?\nLater, we use the mean for:\n\nnormal distributions (“bell curves”)\nlinear regression goes through center of mass\nestimators and other statistical theory"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#which-do-we-use",
    "href": "posts/02_centrality/02_Centrality.html#which-do-we-use",
    "title": "2: Centrality",
    "section": "Which do we use?",
    "text": "Which do we use?\n\n\n\nWhen feasible, compute and report both the mean and median.\n\n\n\n\n\n\n\nWhy not both?\n\n\n\nimage source: Know Your Meme"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#time-series",
    "href": "posts/02_centrality/02_Centrality.html#time-series",
    "title": "2: Centrality",
    "section": "Time Series",
    "text": "Time Series\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  ggplot(aes(x = date, y = n)) +\n  geom_line() +\n  labs(title = \"Parking Tickets in Philadelphia\",\n       subtitle = \"Street Sweeping Violations (2017)\",\n       caption = \"Source: Open Data Philly\",\n       y = \"number of tickets\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#moving-average",
    "href": "posts/02_centrality/02_Centrality.html#moving-average",
    "title": "2: Centrality",
    "section": "Moving Average",
    "text": "Moving Average\n\nConcept357911Code\n\n\nA rolling mean or moving average compues the mean across a group of \\(L\\) (lag) consecutive data points in a time series and slides the “window”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  mutate(roll_mean = zoo::rollapply(\n    n, 3, mean, align = 'left', fill = NA\n  )) |&gt;\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_mean),\n            color = \"blue\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling mean in blue (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#rolling-median",
    "href": "posts/02_centrality/02_Centrality.html#rolling-median",
    "title": "2: Centrality",
    "section": "Rolling Median",
    "text": "Rolling Median\n\n357911Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  mutate(roll_median = zoo::rollapply(\n    n, 3, median, align = 'left', fill = NA\n  )) |&gt;\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_median),\n            color = \"red\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling median in red (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html",
    "href": "posts/03_variance/03_Variance.html",
    "title": "3: Variance",
    "section": "",
    "text": "Goal: Introduce the concept of variance\nObjective: Compute range, variance, and standard deviation\n\n\n\n\n\n\n\nSpread!"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#start",
    "href": "posts/03_variance/03_Variance.html#start",
    "title": "3: Variance",
    "section": "",
    "text": "Goal: Introduce the concept of variance\nObjective: Compute range, variance, and standard deviation\n\n\n\n\n\n\n\nSpread!"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#centrality",
    "href": "posts/03_variance/03_Variance.html#centrality",
    "title": "3: Variance",
    "section": "Centrality",
    "text": "Centrality\nRecall that we can compute means and medians.\n\nmean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#visualization",
    "href": "posts/03_variance/03_Variance.html#visualization",
    "title": "3: Variance",
    "section": "Visualization",
    "text": "Visualization\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimple_df &lt;- data.frame(A,B)\ntitle_string &lt;- \"Compare and Contrast: &lt;span style='color:blue'&gt;Set A&lt;/span&gt; versus &lt;span style='color:red'&gt;Set B&lt;/span&gt;\"\n\nsimple_df |&gt;\n  ggplot() +\n  geom_point(aes(x = A, y = 1), color = \"blue\", size = 10) +\n  geom_point(aes(x = B, y = 2), color = \"red\", size = 10) +\n  labs(title = title_string,\n       subtitle = \"What is alike?  What is different?\",\n       caption = \"SML 201\",\n       x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),\n        plot.title = element_markdown(face = \"bold\", hjust = 0.5,size = 20),\n        plot.subtitle = element_markdown(hjust = 0.5,size = 15)) +\n  ylim(0,3)"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#aside-range",
    "href": "posts/03_variance/03_Variance.html#aside-range",
    "title": "3: Variance",
    "section": "Aside: Range",
    "text": "Aside: Range\nTo describe variance, an early draft was the range\n\\[\\text{range}(x) = \\text{max}(x) - \\text{min}(x)\\]\n\nhighly affected by outliers\nuses only two data points\n\n\n# range in R computes min and max values\nrange(A)\n\n[1] -3  3\n\nrange(B)\n\n[1] -9  9\n\n# range in statistics\ndiff(range(A))\n\n[1] 6\n\ndiff(range(B))\n\n[1] 18"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#sample-mean",
    "href": "posts/03_variance/03_Variance.html#sample-mean",
    "title": "3: Variance",
    "section": "Sample Mean",
    "text": "Sample Mean\nRecall that we compute the sample mean of the data as\n\\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}\\]\n\nH &lt;- c(75,76,63,62,58)\nxbar &lt;- mean(H)"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#deviations",
    "href": "posts/03_variance/03_Variance.html#deviations",
    "title": "3: Variance",
    "section": "Deviations",
    "text": "Deviations\nNext, we can compute deviations from the mean\n\ndeviations &lt;- H - xbar\ndeviations\n\n[1]  8.2  9.2 -3.8 -4.8 -8.8"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#squared-deviations",
    "href": "posts/03_variance/03_Variance.html#squared-deviations",
    "title": "3: Variance",
    "section": "Squared Deviations",
    "text": "Squared Deviations\nWe don’t need negative signs in this calculations. One way around this is to square the deviations.\n\nsq_deviations &lt;- deviations^2\nsq_deviations\n\n[1] 67.24 84.64 14.44 23.04 77.44"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#tabulation",
    "href": "posts/03_variance/03_Variance.html#tabulation",
    "title": "3: Variance",
    "section": "Tabulation",
    "text": "Tabulation\nSo far we have\n\nTableCode\n\n\n\n\n\n\n\n\n\n\nNathan's Hot Dog Eating Contest\n\n\nRecent winning amounts\n\n\nhot_dogs\nxbar\ndeviations\nsq_deviations\n\n\n\n\n75\n66.8\n8.2\n67.24\n\n\n76\n66.8\n9.2\n84.64\n\n\n63\n66.8\n-3.8\n14.44\n\n\n62\n66.8\n-4.8\n23.04\n\n\n58\n66.8\n-8.8\n77.44\n\n\n\nMen's competition\n\n\n\n\n\n\n\n\n\n\n\nhot_dog_data &lt;- data.frame(hot_dogs = c(75,76,63,62,58))\nhot_dog_data |&gt;\n  mutate(xbar = mean(hot_dogs, na.rm = TRUE),\n         deviations = hot_dogs - xbar,\n         sq_deviations = deviations^2) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"Men's competition\") |&gt;\n  tab_header(\n    title = \"Nathan's Hot Dog Eating Contest\",\n    subtitle = \"Recent winning amounts\") |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  )"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#summarizing",
    "href": "posts/03_variance/03_Variance.html#summarizing",
    "title": "3: Variance",
    "section": "Summarizing",
    "text": "Summarizing\nLike before, we want to summarize a list of numbers.\n\\[s^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2} = \\frac{266.8}{4} = 66.7\\]\nAt this point, the calculation has produced a sample variance\n\nWhy “n-1”? See later session about “Estimators”\nBut what are the units?"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#dimensional-analysis",
    "href": "posts/03_variance/03_Variance.html#dimensional-analysis",
    "title": "3: Variance",
    "section": "Dimensional Analysis",
    "text": "Dimensional Analysis\n\nTableCodeWhat?\n\n\n\n\n\n\n\n\n\n\nNathan's Hot Dog Eating Contest\n\n\nRecent winning amounts\n\n\nhot_dogs\nxbar\ndeviations\nsq_deviations\n\n\n\n\n75\n66.8\n8.2\n67.24 (hot dogs)^2\n\n\n76\n66.8\n9.2\n84.64 (hot dogs)^2\n\n\n63\n66.8\n-3.8\n14.44 (hot dogs)^2\n\n\n62\n66.8\n-4.8\n23.04 (hot dogs)^2\n\n\n58\n66.8\n-8.8\n77.44 (hot dogs)^2\n\n\n\nMen's competition\n\n\n\n\n\n\n\n\n\n\n\nhot_dog_data &lt;- data.frame(hot_dogs = c(75,76,63,62,58))\nhot_dog_data |&gt;\n  mutate(xbar = mean(hot_dogs, na.rm = TRUE),\n         deviations = hot_dogs - xbar,\n         sq_deviations = paste(round(deviations^2,2), \n                               \"(hot dogs)^2\")) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"Men's competition\") |&gt;\n  tab_header(\n    title = \"Nathan's Hot Dog Eating Contest\",\n    subtitle = \"Recent winning amounts\") |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = cell_text(color = \"red\"),\n    locations = cells_body(columns = sq_deviations)\n  )\n\n\n\nThe sample variance is\n\\[s^{2} = 66.7 \\,(\\text{hot dogs})^{2}\\]\n\n\n\nsquare hot dogs?\n\n\n\nimage created with Canva AI"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#rectify",
    "href": "posts/03_variance/03_Variance.html#rectify",
    "title": "3: Variance",
    "section": "Rectify",
    "text": "Rectify\nIf we need to use these results in subsequent calculations, we can fix the units by taking the square root of the sample variance. This yields the sample standard deviation\n\\[s = \\sqrt{66.7} \\approx 8.1670 \\text{ hot dogs}\\]"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#sse",
    "href": "posts/03_variance/03_Variance.html#sse",
    "title": "3: Variance",
    "section": "SSE",
    "text": "SSE\nFor the sum of squared errors, what value of \\(c\\) will minimize the error?\n\\[\\text{SSE} = \\sum_{i=1}^{n} (x_{i} - c)^{2}, \\quad H = \\{75,76,63,62,58\\}\\]\n\ncvals &lt;- seq(58, 76)\nSSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SSE[i] &lt;- sum((H - cvals[i])^{2})\n}\nmin(SSE)\n\n[1] 267\n\ncvals[which.min(SSE)]\n\n[1] 67\n\n\n\ncvals &lt;- seq(58, 76, by = 0.1)\nSSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SSE[i] &lt;- sum((H - cvals[i])^{2})\n}\nmin(SSE)\n\n[1] 266.8\n\ncvals[which.min(SSE)]\n\n[1] 66.8\n\nmean(H)\n\n[1] 66.8\n\n\nClaim: The sample mean minimizes the sum of squared errors.\n\n\n\n\n\n\n(optional) Calculus proof\n\n\n\n\n\nFor a non-constant data set \\(\\{x_{i}\\}_{i=1}^{n}\\), and for the sum of squared errors\n\\[S(c) = \\sum_{i=1}^{n} (x_{i} - c)^{2}\\]\nwe can set the derivative equal to zero\n\\[\\begin{array}{rcl}\n  0 & = & \\frac{dS}{dc} \\\\\n  0 & = & \\frac{d}{dc} \\sum_{i=1}^{n} (x_{i} - c)^{2} \\\\\n  0 & = & \\sum_{i=1}^{n} \\frac{d}{dc} (x_{i} - c)^{2} \\\\\n  0 & = & \\sum_{i=1}^{n} 2(x_{i} - c) \\\\\n  0 & = &  2\\sum_{i=1}^{n} x_{i} - 2nc \\\\\n  0 & = &  \\sum_{i=1}^{n} x_{i} - nc \\\\\n  nc & = &  \\sum_{i=1}^{n} x_{i} \\\\\n  c & = & \\frac{1}{n}\\sum_{i=1}^{n} x_{i} \\\\\n\\end{array}\\]\nWe recognize that the right-hand side is the sample mean. Since the function was a concave up parabola, we know that this critical point is a global minimum."
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#absolute-value",
    "href": "posts/03_variance/03_Variance.html#absolute-value",
    "title": "3: Variance",
    "section": "Absolute Value",
    "text": "Absolute Value\nWhat if we had used the absolute value instead? We can use a similar argument on the sum of absolute errors.\n\ncvals &lt;- seq(58, 76, by = 0.1)\nSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SE[i] &lt;- sum(abs(H - cvals[i]))\n}\nmin(SE)\n\n[1] 31\n\ncvals[which.min(SE)]\n\n[1] 63\n\nmedian(H)\n\n[1] 63\n\n\nClaim: The sample median minimizes the sum of absolute errors.\n\\[SE(c) = \\sum_{i=1}^{n} |x_{i} - c|\\]\n\n\n\n\n\n\n(optional) Outline of proof\n\n\n\n\n\n\nargue that the summation is smallest when one of terms is zero\ninterpolate for the case when the number of observations is even"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#data-dow-jones-industrial-average",
    "href": "posts/03_variance/03_Variance.html#data-dow-jones-industrial-average",
    "title": "3: Variance",
    "section": "Data: Dow Jones Industrial Average",
    "text": "Data: Dow Jones Industrial Average\n\n\n\n30 popular stocks\nYear to date\n\nJan 2, 2024\nSept 6, 2024\n\nsource: Yahoo Finance\n\n\n\n\n\ndow_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/03_variance/DOW30.csv\")"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#exploration",
    "href": "posts/03_variance/03_Variance.html#exploration",
    "title": "3: Variance",
    "section": "Exploration",
    "text": "Exploration\n\nhead(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 AAPL   2024-01-02       187.       188.      184.        186. 82488700\n2 AAPL   2024-01-03       184.       186.      183.        184. 58414500\n3 AAPL   2024-01-04       182.       183.      181.        182. 71983600\n4 AAPL   2024-01-05       182.       183.      180.        181. 62303300\n5 AAPL   2024-01-08       182.       186.      182.        186. 59144500\n6 AAPL   2024-01-09       184.       185.      183.        185. 42841800\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\nstr(dow_df, give.attr = FALSE)\n\nspc_tbl_ [5,160 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ticker                : chr [1:5160] \"AAPL\" \"AAPL\" \"AAPL\" \"AAPL\" ...\n $ ref_date              : Date[1:5160], format: \"2024-01-02\" \"2024-01-03\" ...\n $ price_open            : num [1:5160] 187 184 182 182 182 ...\n $ price_high            : num [1:5160] 188 186 183 183 186 ...\n $ price_low             : num [1:5160] 184 183 181 180 182 ...\n $ price_close           : num [1:5160] 186 184 182 181 186 ...\n $ volume                : num [1:5160] 82488700 58414500 71983600 62303300 59144500 ...\n $ price_adjusted        : num [1:5160] 185 184 181 180 185 ...\n $ ret_adjusted_prices   : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ ret_closing_prices    : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ cumret_adjusted_prices: num [1:5160] 1 0.993 0.98 0.976 1 ...\n\n\n\ncolnames(dow_df)\n\n [1] \"ticker\"                 \"ref_date\"               \"price_open\"            \n [4] \"price_high\"             \"price_low\"              \"price_close\"           \n [7] \"volume\"                 \"price_adjusted\"         \"ret_adjusted_prices\"   \n[10] \"ret_closing_prices\"     \"cumret_adjusted_prices\""
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#which-stocks",
    "href": "posts/03_variance/03_Variance.html#which-stocks",
    "title": "3: Variance",
    "section": "Which Stocks?",
    "text": "Which Stocks?\nThe table command tallys the observations in a categorical variable.\n\ntable(dow_df$ticker)\n\n\nAAPL AMGN AMZN  AXP   BA  CAT  CRM CSCO  CVX  DIS  DOW   GS   HD  HON  IBM INTC \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172  172  172 \n JNJ  JPM   KO  MCD  MMM  MRK MSFT  NKE   PG  TRV  UNH    V   VZ  WMT \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#histograms",
    "href": "posts/03_variance/03_Variance.html#histograms",
    "title": "3: Variance",
    "section": "Histograms",
    "text": "Histograms\n\ndow_df |&gt;\n  filter(ticker == \"VZ\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Verizon stock\",\n       subtitle = \"2024 YTD\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndow_df |&gt;\n  filter(ticker == \"GS\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Goldman Sachs stock\",\n       subtitle = \"2024 YTD\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#application-1",
    "href": "posts/03_variance/03_Variance.html#application-1",
    "title": "3: Variance",
    "section": "Application 1",
    "text": "Application 1\nWhich stocks have had the highest average price_close this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(avg_price = mean(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, avg_price) |&gt;\n  distinct() |&gt;\n  arrange(desc(avg_price))\n\n# A tibble: 30 × 2\n   ticker avg_price\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 UNH         516.\n 2 GS          435.\n 3 MSFT        417.\n 4 HD          354.\n 5 CAT         335.\n 6 AMGN        302.\n 7 MCD         275.\n 8 V           273.\n 9 CRM         271.\n10 AXP         227.\n# ℹ 20 more rows\n\n\n\nUnited Health\nGoldman Sachs\nMicrosoft\nHome Depot\nCaterpillar"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#volatility",
    "href": "posts/03_variance/03_Variance.html#volatility",
    "title": "3: Variance",
    "section": "Volatility",
    "text": "Volatility\nWhich stocks have been the most volatile this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, volatility) |&gt;\n  distinct() |&gt;\n  arrange(desc(volatility))\n\n# A tibble: 30 × 2\n   ticker volatility\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 GS           43.5\n 2 UNH          37.5\n 3 CRM          22.2\n 4 CAT          21.9\n 5 AMGN         21.3\n 6 AAPL         20.8\n 7 MSFT         19.5\n 8 AXP          18.9\n 9 BA           17.5\n10 MMM          16.2\n# ℹ 20 more rows\n\n\n\nGoldman Sachs\nUnited Health\nSalesforce\nCaterpillar\nAmgen\n\nWhich stocks have been the most volatile this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, volatility) |&gt;\n  distinct() |&gt;\n  arrange(volatility)\n\n# A tibble: 30 × 2\n   ticker volatility\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 VZ          0.973\n 2 CSCO        1.73 \n 3 DOW         2.29 \n 4 KO          3.58 \n 5 MRK         5.56 \n 6 PG          6.23 \n 7 JNJ         6.23 \n 8 CVX         6.24 \n 9 WMT         6.47 \n10 HON         6.56 \n# ℹ 20 more rows\n\n\n\nVerizon\nCisco\nDow Inc\nCoca-Cola\nMerck"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#coefficient-of-variation",
    "href": "posts/03_variance/03_Variance.html#coefficient-of-variation",
    "title": "3: Variance",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\nWouldn’t the most expensive stocks naturally vary more?\n\\[\\text{CoV} = \\frac{s}{\\bar{x}}\\]\n\n\\(\\bar{x}\\): sample mean\n\\(s\\): sample standard deviation\n\nWhich stocks have the highest coefficients of variation this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(avg_price = mean(price_close, na.rm = TRUE)) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, avg_price, volatility) |&gt;\n  distinct() |&gt;\n  mutate(coef_var = volatility / avg_price) |&gt;\n  arrange(desc(coef_var))\n\n# A tibble: 30 × 4\n   ticker avg_price volatility coef_var\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 INTC        35.1       8.58   0.244 \n 2 MMM         98.2      16.2    0.165 \n 3 NKE         91.6      10.6    0.115 \n 4 AAPL       195.       20.8    0.106 \n 5 WMT         63.3       6.47   0.102 \n 6 GS         435.       43.5    0.100 \n 7 DIS        102.        9.92   0.0971\n 8 BA         187.       17.5    0.0934\n 9 AXP        227.       18.9    0.0833\n10 CRM        271.       22.2    0.0819\n# ℹ 20 more rows\n\n\n\nIntel\n3M\nNike\nApple\nWalmart"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#z-scores-1",
    "href": "posts/03_variance/03_Variance.html#z-scores-1",
    "title": "3: Variance",
    "section": "Z-scores",
    "text": "Z-scores\nSometimes, we want to rescale numerical columns to be able to compare them together.\n\nsummary(dow_df$price_close)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.89   96.86  181.35  198.37  271.92  604.18 \n\n\n\ndow_df &lt;- dow_df |&gt;\n  mutate(price_scaled = scale(price_close)) #z-scores\n\n\nsummary(dow_df$price_scaled)\n\n       V1         \n Min.   :-1.4525  \n 1st Qu.:-0.8215  \n Median :-0.1377  \n Mean   : 0.0000  \n 3rd Qu.: 0.5953  \n Max.   : 3.2842"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#line-plots",
    "href": "posts/03_variance/03_Variance.html#line-plots",
    "title": "3: Variance",
    "section": "Line Plots",
    "text": "Line Plots\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle_string &lt;- \"&lt;span style='color:blue'&gt;Verizon&lt;/span&gt; and &lt;span style='color:red'&gt;Goldman Sachs&lt;/span&gt;\"\nsubtitle_string &lt;- \"2024 stock prices\"\n\ndow_df |&gt;\n  ggplot() +\n  geom_line(aes(x = ref_date, y = price_close),\n            color = \"blue\", linewidth = 2,\n            data = dow_df |&gt; filter(ticker == \"VZ\")) +\n  geom_line(aes(x = ref_date, y = price_close),\n            color = \"red\", linewidth = 3,\n            data = dow_df |&gt; filter(ticker == \"GS\")) +\n  labs(title = title_string,\n       subtitle = subtitle_string,\n       caption = \"SML 201\",\n       x = \"date\", y = \"closing price\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", hjust = 0.5,size = 25),\n        plot.subtitle = element_markdown(hjust = 0.5,size = 20))"
  },
  {
    "objectID": "posts/04_categories/04_categories.html",
    "href": "posts/04_categories/04_categories.html",
    "title": "4: Categories",
    "section": "",
    "text": "Goal: Explore data wrangling with categorical variables\nObjective: Compute counts, make bar graphs, and discuss data\n\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#start",
    "href": "posts/04_categories/04_categories.html#start",
    "title": "4: Categories",
    "section": "",
    "text": "Goal: Explore data wrangling with categorical variables\nObjective: Compute counts, make bar graphs, and discuss data\n\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#data",
    "href": "posts/04_categories/04_categories.html#data",
    "title": "4: Categories",
    "section": "Data",
    "text": "Data\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#queries",
    "href": "posts/04_categories/04_categories.html#queries",
    "title": "4: Categories",
    "section": "Queries",
    "text": "Queries\n\n\nFor the Demographics Survey, here are the variable names that represent the responses to the survey questions.\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-ocean-or-snow",
    "href": "posts/04_categories/04_categories.html#example-ocean-or-snow",
    "title": "4: Categories",
    "section": "Example: Ocean or Snow?",
    "text": "Example: Ocean or Snow?\n\ndemo_df |&gt;\n  filter(!is.na(oceanSnow)) |&gt;\n  ggplot(aes(x = oceanSnow)) +\n  geom_bar(aes(fill = oceanSnow),\n           color = \"black\",\n           stat = \"count\")"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-campus-safety",
    "href": "posts/04_categories/04_categories.html#example-campus-safety",
    "title": "4: Categories",
    "section": "Example: Campus Safety",
    "text": "Example: Campus Safety\nOn a scale from 0 to 100—with 0 = very anxious and 100 = comfortable—how safe do you feel on campus?\n\nsummary(demo_df$safety)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2.00   80.00   90.00   87.16   97.25  100.00       5 \n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = safety)) +\n  geom_histogram(binwidth = 5)\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = safety, group = gender)) +\n  geom_density(aes(fill = gender),\n               alpha = 0.5)\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = gender, y = safety)) +\n  geom_boxplot()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-flossing",
    "href": "posts/04_categories/04_categories.html#example-flossing",
    "title": "4: Categories",
    "section": "Example: Flossing",
    "text": "Example: Flossing\n\nsummary(demo_df$flossing)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   2.000   5.000   5.224   7.000  14.000      10"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-football",
    "href": "posts/04_categories/04_categories.html#example-football",
    "title": "4: Categories",
    "section": "Example: Football",
    "text": "Example: Football\n\ndemo_df |&gt;\n  select(football) |&gt;\n  separate_longer_delim(football, delim = \",\") |&gt;\n  count(football) |&gt;\n  arrange(desc(n))\n\n# A tibble: 29 × 2\n   football                 n\n   &lt;chr&gt;                &lt;int&gt;\n 1 &lt;NA&gt;                    40\n 2 New York Giants         14\n 3 Philadelphia Eagles     13\n 4 San Francisco 49ers     11\n 5 Dallas Cowboys           7\n 6 Buffalo Bills            6\n 7 Houston Texas            6\n 8 New England Patriots     6\n 9 Arizona Cardinals        5\n10 New York Jets            5\n# ℹ 19 more rows\n\n\n\ndemo_df |&gt;\n  select(baseball) |&gt;\n  separate_longer_delim(baseball, delim = \",\") |&gt;\n  count(baseball) |&gt;\n  arrange(desc(n))\n\n# A tibble: 28 × 2\n   baseball                  n\n   &lt;chr&gt;                 &lt;int&gt;\n 1 &lt;NA&gt;                     49\n 2 New York Yankees         16\n 3 Boston Red Sox           11\n 4 New York Mets            11\n 5 Philadelphia Phillies    11\n 6 Los Angeles Dodgers       8\n 7 Arizona Diamondbacks      4\n 8 Houston Astros            4\n 9 Miami Marlins             4\n10 San Franciso Giants       4\n# ℹ 18 more rows"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-sleep",
    "href": "posts/04_categories/04_categories.html#example-sleep",
    "title": "4: Categories",
    "section": "Example: Sleep",
    "text": "Example: Sleep"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-residential-colleges",
    "href": "posts/04_categories/04_categories.html#example-residential-colleges",
    "title": "4: Categories",
    "section": "Example: Residential Colleges",
    "text": "Example: Residential Colleges"
  },
  {
    "objectID": "posts/05_networks/05_networks.html",
    "href": "posts/05_networks/05_networks.html",
    "title": "5: Networks",
    "section": "",
    "text": "Goal: Visualize network data\nObjective: Arrange paired data into nodes and edges\n\n\n\n\n\n\n\nnetwork terminology\n\n\n\nimage source: MRI Questions\n\n\n\n\n\n\nMoving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#start",
    "href": "posts/05_networks/05_networks.html#start",
    "title": "5: Networks",
    "section": "",
    "text": "Goal: Visualize network data\nObjective: Arrange paired data into nodes and edges\n\n\n\n\n\n\n\nnetwork terminology\n\n\n\nimage source: MRI Questions"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#rbind",
    "href": "posts/05_networks/05_networks.html#rbind",
    "title": "5: Networks",
    "section": "rbind",
    "text": "rbind\n\ndf1 &lt;- music_df |&gt;\n  select(artist1, song1) |&gt;\n  set_names(c(\"artist\", \"song\"))\ndf2 &lt;- music_df |&gt;\n  select(artist2, song2) |&gt;\n  set_names(c(\"artist\", \"song\"))\n\nmusic_long &lt;- df1 |&gt;\n  rbind(df2) |&gt;\n  separate_longer_delim(artist, delim = \", \") |&gt;\n  filter(!is.na(artist)) |&gt;\n  filter(!is.na(song))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#top_n",
    "href": "posts/05_networks/05_networks.html#top_n",
    "title": "5: Networks",
    "section": "top_n",
    "text": "top_n\nWho are the top 5 most frequent artists in the data set?\n\nmusic_long |&gt;\n  count(artist) |&gt;\n  arrange(desc(n)) |&gt;\n  top_n(5, wt = n)\n\n# A tibble: 6 × 2\n  artist                n\n  &lt;chr&gt;             &lt;int&gt;\n1 Taylor Swift         10\n2 Sabrina Carpenter     9\n3 SZA                   7\n4 Daya                  6\n5 Bruno Mars            4\n6 Lauv                  4\n\n\n\ntop_artists &lt;- music_long |&gt;\n  count(artist) |&gt;\n  arrange(desc(n)) |&gt;\n  top_n(5, wt = n) |&gt;\n  pull(artist)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble",
    "href": "posts/05_networks/05_networks.html#node-tibble",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(id = music_long$artist,\n                  label = music_long$artist,\n                  color = \"green\",\n                  shape = \"circle\")\nnode_tbl &lt;- node_tbl |&gt;\n  bind_rows(\n    tibble(id = music_long$song,\n           label = music_long$song,\n           color = \"yellow\",\n           shape = \"circle\")\n  ) |&gt;\n  distinct()"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble",
    "href": "posts/05_networks/05_networks.html#edge-tibble",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from = music_long$artist,\n  to = music_long$song,\n  arrow = \"to\") #directed network"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Song Playlist Network\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#filtered-plot",
    "href": "posts/05_networks/05_networks.html#filtered-plot",
    "title": "5: Networks",
    "section": "Filtered Plot",
    "text": "Filtered Plot\n\nmusic_top &lt;- music_long |&gt;\n  filter(artist %in% top_artists)\n\nnode_tbl &lt;- tibble(id = music_top$artist,\n                  label = music_top$artist,\n                  color = \"green\",\n                  shape = \"circle\")\nnode_tbl &lt;- node_tbl |&gt;\n  bind_rows(\n    tibble(id = music_top$song,\n           label = music_top$song,\n           color = \"yellow\",\n           shape = \"circle\")\n  ) |&gt;\n  distinct()\n\nedge_tbl &lt;- tibble(\n  from = music_top$artist,\n  to = music_top$song)\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Song Playlist Network\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#other-music",
    "href": "posts/05_networks/05_networks.html#other-music",
    "title": "5: Networks",
    "section": "Other Music",
    "text": "Other Music\nWe can negate the %in% to create a complement set of lessor known songs. We can also use the sample function to display a small number of those songs.\n\nmusic_long |&gt;\n  filter(!(artist %in% top_artists)) |&gt;\n  sample_n(10)\n\n# A tibble: 10 × 2\n   artist           song         \n   &lt;chr&gt;            &lt;chr&gt;        \n 1 NewJeans         Right Now    \n 2 Slow Pulp        High         \n 3 Lisa Loeb        Fools Like Me\n 4 Charlie xcx      365          \n 5 The Beatles      Let It Be    \n 6 Yuuri            Dried Flower \n 7 New Jeans        OMG          \n 8 Childish Gambino Riot         \n 9 Harry Styles     Keep Driving \n10 Frank Ocean      Pink + White"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble-1",
    "href": "posts/05_networks/05_networks.html#node-tibble-1",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(id = majors_df$major,\n                  label = majors_df$major,\n                  color = \"#E77500\",\n                  shape = \"circle\") |&gt;\n  bind_rows(\n    tibble(id = majors_df$minor1,\n           label = majors_df$minor1,\n           color = \"#121212\",\n           opacity = 0.5,\n           shape = \"circle\")\n  ) |&gt; \n  bind_rows(\n    tibble(id = majors_df$minor2,\n           label = majors_df$minor2,\n           color = \"#121212\",\n           opacity = 0.5,\n           shape = \"circle\")\n  ) |&gt; \n  distinct(id, .keep_all = TRUE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble-1",
    "href": "posts/05_networks/05_networks.html#edge-tibble-1",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from = majors_df$major,\n  to = majors_df$minor1,\n  color = \"#333333\") |&gt;\n  bind_rows(\n    tibble(from = majors_df$major,\n           to = majors_df$minor2,\n           color = \"#333333\")\n  ) |&gt;\n  filter(!is.na(to))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot-1",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot-1",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Majors and Minors at Princeton\\nAmong SML 201 Students\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble-2",
    "href": "posts/05_networks/05_networks.html#node-tibble-2",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(\n  id = classes_df$class1,\n  label = classes_df$class1) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class2,\n    label = classes_df$class2\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class3,\n    label = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class4,\n    label = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class5,\n    label = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class6,\n    label = classes_df$class6\n  )) |&gt;\n  distinct() |&gt;\n  filter(!is.na(id)) |&gt;\n  filter(id != \"SML 201\") |&gt;\n  separate(id, into = c(\"dept\", \"num\"), \n           sep = \" \", remove = FALSE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble-2",
    "href": "posts/05_networks/05_networks.html#edge-tibble-2",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from   = classes_df$class1,\n  to     = classes_df$class2\n) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class4,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class4,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class5,\n    to   = classes_df$class6\n  )) |&gt;\n  distinct() |&gt;\n  filter(!is.na(to)) |&gt;\n  filter(from != \"SML 201\") |&gt;\n  separate(from, into = c(\"dept_from\", \"num_from\"), \n           sep = \" \", remove = FALSE) |&gt;\n  separate(to, into = c(\"dept_to\", \"num_to\"), \n           sep = \" \", remove = FALSE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot-2",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot-2",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Current Classes\",\n           submain = \"Among SML 201 Students\") |&gt;\n  visPhysics(maxVelocity = 5,\n             stabilization = list(iterations = 5))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#highlighted-plot",
    "href": "posts/05_networks/05_networks.html#highlighted-plot",
    "title": "5: Networks",
    "section": "Highlighted Plot",
    "text": "Highlighted Plot\n\ndept_abbrev = \"MOL\"\n\nnode_tbl &lt;- node_tbl |&gt;\n  mutate(color = ifelse(dept == dept_abbrev,\n                        \"#E77500\", \"#DDDDDD\"),\n         opacity = ifelse(dept == dept_abbrev,\n                        1.0, 0.5))\nedge_tbl &lt;- edge_tbl |&gt;\n  mutate(color = ifelse(dept_from == dept_abbrev | dept_to == dept_abbrev,\n                        \"#E77500\", \"#DDDDDD\"))\n\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Classes Connected to MOL BIO\",\n           submain = \"Among SML 201 Students\") |&gt;\n  visPhysics(maxVelocity = 5,\n             stabilization = list(iterations = 5))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#template-files",
    "href": "posts/05_networks/05_networks.html#template-files",
    "title": "5: Networks",
    "section": "",
    "text": "Moving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "lecture_code/session4notes_L02.html",
    "href": "lecture_code/session4notes_L02.html",
    "title": "session 4 notes",
    "section": "",
    "text": "library(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")\n\nRows: 133 Columns: 84\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (38): timestamp, currentCourse, statsBefore, classStanding, major, resid...\ndbl (46): numCourses, GPA, hoursStudying, age, height, shoeSize, weight, cal...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session4notes_L02.html#filtering",
    "href": "lecture_code/session4notes_L02.html#filtering",
    "title": "session 4 notes",
    "section": "Filtering",
    "text": "Filtering\n\ndf2 &lt;- select(demo_df, residentialCollege, languages)\n\ndf3 &lt;- filter(df2, residentialCollege == \"Mathey\")\n\n# sample means\nxbar &lt;- mean(df3$languages, na.rm = TRUE)\nxbar\n\n[1] 2.092308\n\ndf4 &lt;- filter(df2, residentialCollege == \"Forbes\")\nxbar &lt;- mean(df4$languages, na.rm = TRUE)\nxbar\n\n[1] 2.552941\n\n\n\nkey observation: the sample mean can change based on the sampling\n\n\ndf_grouped &lt;- group_by(df2, residentialCollege)\nsummarize(df_grouped,\n          xbar = mean(languages, na.rm = TRUE))\n\n# A tibble: 8 × 2\n  residentialCollege   xbar\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Butler               2.05\n2 Forbes               2.55\n3 Mathey               2.09\n4 New College West     2.53\n5 Rockefeller          2.37\n6 Whitman              2.32\n7 Yeh College          2.29\n8 &lt;NA&gt;               NaN   \n\n\n\nall_means &lt;- summarize(df_grouped,\n          xbar = mean(languages, na.rm = TRUE))\n\n# variables go inside aesthetics\nggplot(all_means, aes(x = residentialCollege, y = xbar)) +\n  \n  # when we want to plot the numbers directly, use \"identity\"\n  geom_bar(color = \"red\", fill = \"green\",stat = \"identity\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`)."
  },
  {
    "objectID": "lecture_code/session4notes_L02.html#more-examples",
    "href": "lecture_code/session4notes_L02.html#more-examples",
    "title": "session 4 notes",
    "section": "More Examples",
    "text": "More Examples\nWhat time do you go to sleep?\n\ntable(demo_df$sleepTime)\n\n\n       1 AM       10 PM       11 PM 12 midnight        2 AM        3 AM \n         33           6          19          52          15           6 \n\n\n\nsummary(demo_df$flossing)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   2.000   5.000   5.224   7.000  14.000      10 \n\n\n\nsummary(demo_df$attractiveness)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   50.00   65.00   63.18   79.00  100.00      16 \n\n\n\nsummary(demo_df$intelligence)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   60.00   70.00   67.52   83.00  100.00      12 \n\n\n\nsummary(demo_df$showers)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2.00    7.00    7.00    7.55    8.00   16.00       4 \n\n\n\ntable(demo_df$drugUse)\n\n\n No Yes \n 99  32 \n\n\n\ntable(demo_df$pancakesWaffles)\n\n\nPancakes  Waffles \n      59       69 \n\n\n\nsummary(demo_df$SAT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0    1500    1540    1617    1560   15560      24 \n\ndemo_df$SAT[demo_df$SAT &gt; 1600] &lt;- NA\ndemo_df$SAT[demo_df$SAT &lt; 400] &lt;- NA\n\nsummary(demo_df$SAT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1100    1500    1540    1516    1560    1600      27"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html",
    "href": "lecture_code/session3notes_L02.html",
    "title": "session 3 notes",
    "section": "",
    "text": "A &lt;- seq(-3,3)\nB &lt;- seq(-9, 9, by = 3)\nA\n\n[1] -3 -2 -1  0  1  2  3\n\nB\n\n[1] -9 -6 -3  0  3  6  9\n\n\n\n\n\nmean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0\n\n\n\n\n\n\nvar(A)\n\n[1] 4.666667\n\nvar(B)\n\n[1] 42\n\n\nThe variance of set B is larger than the variance of set A.\n\n\n\n\nsd(A)\n\n[1] 2.160247\n\nsd(B)\n\n[1] 6.480741\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#centrality",
    "href": "lecture_code/session3notes_L02.html#centrality",
    "title": "session 3 notes",
    "section": "",
    "text": "mean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#variance",
    "href": "lecture_code/session3notes_L02.html#variance",
    "title": "session 3 notes",
    "section": "",
    "text": "var(A)\n\n[1] 4.666667\n\nvar(B)\n\n[1] 42\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#standard-deviation",
    "href": "lecture_code/session3notes_L02.html#standard-deviation",
    "title": "session 3 notes",
    "section": "",
    "text": "sd(A)\n\n[1] 2.160247\n\nsd(B)\n\n[1] 6.480741\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#exploration",
    "href": "lecture_code/session3notes_L02.html#exploration",
    "title": "session 3 notes",
    "section": "exploration",
    "text": "exploration\n\nhead(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 AAPL   2024-01-02       187.       188.      184.        186. 82488700\n2 AAPL   2024-01-03       184.       186.      183.        184. 58414500\n3 AAPL   2024-01-04       182.       183.      181.        182. 71983600\n4 AAPL   2024-01-05       182.       183.      180.        181. 62303300\n5 AAPL   2024-01-08       182.       186.      182.        186. 59144500\n6 AAPL   2024-01-09       184.       185.      183.        185. 42841800\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\ntail(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 WMT    2024-08-29       76.0       76.5      75.7        76.4 11856800\n2 WMT    2024-08-30       76.4       77.5      76.2        77.2 23230000\n3 WMT    2024-09-03       77.3       77.8      76.8        77.2 22666100\n4 WMT    2024-09-04       77.3       77.5      76.7        77.2 18442800\n5 WMT    2024-09-05       77.2       77.4      76.4        77.0 13082900\n6 WMT    2024-09-06       76.9       77.3      76.3        76.6 14545900\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\nstr(dow_df, give.attr = FALSE)\n\nspc_tbl_ [5,160 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ticker                : chr [1:5160] \"AAPL\" \"AAPL\" \"AAPL\" \"AAPL\" ...\n $ ref_date              : Date[1:5160], format: \"2024-01-02\" \"2024-01-03\" ...\n $ price_open            : num [1:5160] 187 184 182 182 182 ...\n $ price_high            : num [1:5160] 188 186 183 183 186 ...\n $ price_low             : num [1:5160] 184 183 181 180 182 ...\n $ price_close           : num [1:5160] 186 184 182 181 186 ...\n $ volume                : num [1:5160] 82488700 58414500 71983600 62303300 59144500 ...\n $ price_adjusted        : num [1:5160] 185 184 181 180 185 ...\n $ ret_adjusted_prices   : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ ret_closing_prices    : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ cumret_adjusted_prices: num [1:5160] 1 0.993 0.98 0.976 1 ...\n\n\n\ncolnames(dow_df)\n\n [1] \"ticker\"                 \"ref_date\"               \"price_open\"            \n [4] \"price_high\"             \"price_low\"              \"price_close\"           \n [7] \"volume\"                 \"price_adjusted\"         \"ret_adjusted_prices\"   \n[10] \"ret_closing_prices\"     \"cumret_adjusted_prices\""
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#which-stocks",
    "href": "lecture_code/session3notes_L02.html#which-stocks",
    "title": "session 3 notes",
    "section": "Which stocks?",
    "text": "Which stocks?\ntable tallies the amounts in a categorical variable\n\ntable(dow_df$ticker)\n\n\nAAPL AMGN AMZN  AXP   BA  CAT  CRM CSCO  CVX  DIS  DOW   GS   HD  HON  IBM INTC \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172  172  172 \n JNJ  JPM   KO  MCD  MMM  MRK MSFT  NKE   PG  TRV  UNH    V   VZ  WMT \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#histograms",
    "href": "lecture_code/session3notes_L02.html#histograms",
    "title": "session 3 notes",
    "section": "Histograms",
    "text": "Histograms\nA histogram shows us the distribution of a numerical variable.\n\ndow_df |&gt;\n  filter(ticker == \"VZ\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Verison Stock\",\n       subtitle = \"2024 prices\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndow_df |&gt;\n  filter(ticker == \"GS\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Goldman Sachs Stock\",\n       subtitle = \"2024 prices\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#z-scores-1",
    "href": "lecture_code/session3notes_L02.html#z-scores-1",
    "title": "session 3 notes",
    "section": "Z-scores",
    "text": "Z-scores\nSometimes we want to rescale numerical columns to be able to compare them together.\n\nsummary(dow_df$price_close)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.89   96.86  181.35  198.37  271.92  604.18 \n\n\n\ndow_df &lt;- dow_df |&gt;\n  #mutate attachs a new column\n  mutate(price_scaled = scale(price_close))\n\n\nsummary(dow_df$price_scaled)\n\n       V1         \n Min.   :-1.4525  \n 1st Qu.:-0.8215  \n Median :-0.1377  \n Mean   : 0.0000  \n 3rd Qu.: 0.5953  \n Max.   : 3.2842"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html",
    "href": "lecture_code/session2notes_L01.html",
    "title": "session 2 notes",
    "section": "",
    "text": "add up the values\ndivide by amount of values\n\n“c” means “concatenate” (or “combine”)\nto run one line of code: CTRL + ENTER\n\n# create some data\nsome_data &lt;- c(32, 45, 16, 78, 39)\n\nsum(some_data)\n\n[1] 210\n\nlength(some_data)\n\n[1] 5\n\nsum(some_data) / length(some_data)\n\n[1] 42\n\nmean(some_data)\n\n[1] 42\n\n\n\n\nNA for non-applicable, or “missing data”\nBy default, R stops upon missing\n\nwant to avoid the missing data\n\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\n\nmean(some_data)\n\n[1] NA\n\nmean(some_data, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#missing-data",
    "href": "lecture_code/session2notes_L01.html#missing-data",
    "title": "session 2 notes",
    "section": "",
    "text": "NA for non-applicable, or “missing data”\nBy default, R stops upon missing\n\nwant to avoid the missing data\n\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\n\nmean(some_data)\n\n[1] NA\n\nmean(some_data, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#explore-the-data",
    "href": "lecture_code/session2notes_L01.html#explore-the-data",
    "title": "session 2 notes",
    "section": "explore the data",
    "text": "explore the data\n\nhead(olympic_df1)\n\n# A tibble: 6 × 36\n     code name         name_short name_tv gender `function` country_code country\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n1 1532873 AMOYAN Malk… AMOYAN M   Malkha… Male   Athlete    ARM          Armenia\n2 1532874 GALSTYAN Sl… GALSTYAN S Slavik… Male   Athlete    ARM          Armenia\n3 1532944 HARUTYUNYAN… HARUTYUNY… Arsen … Male   Athlete    ARM          Armenia\n4 1532945 TEVANYAN Va… TEVANYAN V Vazgen… Male   Athlete    ARM          Armenia\n5 1533136 BASS BITTAY… BASS BITT… Gina M… Female Athlete    GAM          Gambia \n6 1533176 CAMARA Ebra… CAMARA E   Ebrahi… Male   Athlete    GAM          Gambia \n# ℹ 28 more variables: country_full &lt;chr&gt;, nationality &lt;chr&gt;,\n#   nationality_full &lt;chr&gt;, nationality_code &lt;chr&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;,\n#   disciplines &lt;chr&gt;, events &lt;chr&gt;, birth_date &lt;date&gt;, birth_place &lt;chr&gt;,\n#   birth_country &lt;chr&gt;, residence_place &lt;chr&gt;, residence_country &lt;chr&gt;,\n#   nickname &lt;chr&gt;, hobbies &lt;chr&gt;, occupation &lt;chr&gt;, education &lt;chr&gt;,\n#   family &lt;chr&gt;, lang &lt;chr&gt;, coach &lt;chr&gt;, reason &lt;chr&gt;, hero &lt;chr&gt;,\n#   influence &lt;chr&gt;, philosophy &lt;chr&gt;, sporting_relatives &lt;chr&gt;, …\n\nstr(olympic_df1) #structure\n\nspc_tbl_ [8,687 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code              : num [1:8687] 1532873 1532874 1532944 1532945 1533136 ...\n $ name              : chr [1:8687] \"AMOYAN Malkhas\" \"GALSTYAN Slavik\" \"HARUTYUNYAN Arsen\" \"TEVANYAN Vazgen\" ...\n $ name_short        : chr [1:8687] \"AMOYAN M\" \"GALSTYAN S\" \"HARUTYUNYAN A\" \"TEVANYAN V\" ...\n $ name_tv           : chr [1:8687] \"Malkhas AMOYAN\" \"Slavik GALSTYAN\" \"Arsen HARUTYUNYAN\" \"Vazgen TEVANYAN\" ...\n $ gender            : chr [1:8687] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ function          : chr [1:8687] \"Athlete\" \"Athlete\" \"Athlete\" \"Athlete\" ...\n $ country_code      : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ country           : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ country_full      : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality       : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_full  : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_code  : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ height            : num [1:8687] 0 0 0 0 161 178 0 0 183 0 ...\n $ weight            : num [1:8687] -99 -99 -99 -99 -99 -99 -99 -99 -99 -99 ...\n $ disciplines       : chr [1:8687] \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" ...\n $ events            : chr [1:8687] \"[\\\"Men's Greco-Roman 77kg\\\"]\" \"[\\\"Men's Greco-Roman 67kg\\\"]\" \"[\\\"Men's Freestyle 57kg\\\"]\" \"[\\\"Men's Freestyle 65kg\\\"]\" ...\n $ birth_date        : Date[1:8687], format: \"1999-01-22\" \"1996-12-21\" ...\n $ birth_place       : chr [1:8687] \"YEREVAN\" NA \"MASIS\" \"POKR VEDI\" ...\n $ birth_country     : chr [1:8687] \"Armenia\" NA \"Armenia\" \"Armenia\" ...\n $ residence_place   : chr [1:8687] \"YEREVAN\" \"YEREVAN\" \"YEREVAN\" NA ...\n $ residence_country : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nickname          : chr [1:8687] NA NA NA NA ...\n $ hobbies           : chr [1:8687] NA NA NA NA ...\n $ occupation        : chr [1:8687] NA NA \"Athlete\" \"Athlete\" ...\n $ education         : chr [1:8687] NA NA \"Graduated with a Master's degree from the Armenian State Institute of Physical Culture and Sport (2023)\" \"Studied at the Armenian State Institute of Physical Culture and Sport (Yerevan, ARM)\" ...\n $ family            : chr [1:8687] NA NA \"Wife, Diana (married October 2022). Daughter, Marias (born 2023)\" \"Wife, Sona (married November 2023)\" ...\n $ lang              : chr [1:8687] \"Armenian\" \"Armenian\" \"Armenian\" \"Armenian, Russian\" ...\n $ coach             : chr [1:8687] NA \"Personal: Martin Alekhanyan (ARM).&lt;br&gt;National: Armen Babalaryan (ARM)\" \"National: Habetnak Kurghinyan\" \"National: Habetnak Kurghinyan (ARM)\" ...\n $ reason            : chr [1:8687] NA NA \"While doing karate he noticed wrestlers training and decided to give it a try. He also tried judo but his fathe\"| __truncated__ \"“My family did not like wrestling very much. At first I wanted to do boxing but my older friends advised me to \"| __truncated__ ...\n $ hero              : chr [1:8687] NA NA \"Wrestler Armen Nazaryan (ARM, BUL), two-time Olympic champion (1996, 2000) and 2004 bronze medallist. Eight-tim\"| __truncated__ NA ...\n $ influence         : chr [1:8687] NA NA NA NA ...\n $ philosophy        : chr [1:8687] \"\\\"To become a good athlete, you first have to be a good person.\\\" (ankakh.com, 6 Oct 2018)\" NA \"“Nothing is impossible, set goals in front of you, fight and achieve it.” (Instagram, 13 May 2023)\" NA ...\n $ sporting_relatives: chr [1:8687] \"Uncle, Roman Amoyan (wrestling), 2008 Olympic bronze medallist and two-time European champion in Greco-Roman\" NA NA NA ...\n $ ritual            : chr [1:8687] NA NA NA NA ...\n $ other_sports      : chr [1:8687] NA NA NA NA ...\n $ age               : num [1:8687] 25 28 25 25 29 28 30 27 27 17 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   name = col_character(),\n  ..   name_short = col_character(),\n  ..   name_tv = col_character(),\n  ..   gender = col_character(),\n  ..   `function` = col_character(),\n  ..   country_code = col_character(),\n  ..   country = col_character(),\n  ..   country_full = col_character(),\n  ..   nationality = col_character(),\n  ..   nationality_full = col_character(),\n  ..   nationality_code = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   disciplines = col_character(),\n  ..   events = col_character(),\n  ..   birth_date = col_date(format = \"\"),\n  ..   birth_place = col_character(),\n  ..   birth_country = col_character(),\n  ..   residence_place = col_character(),\n  ..   residence_country = col_character(),\n  ..   nickname = col_character(),\n  ..   hobbies = col_character(),\n  ..   occupation = col_character(),\n  ..   education = col_character(),\n  ..   family = col_character(),\n  ..   lang = col_character(),\n  ..   coach = col_character(),\n  ..   reason = col_character(),\n  ..   hero = col_character(),\n  ..   influence = col_character(),\n  ..   philosophy = col_character(),\n  ..   sporting_relatives = col_character(),\n  ..   ritual = col_character(),\n  ..   other_sports = col_character(),\n  ..   age = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ncolnames(olympic_df1)\n\n [1] \"code\"               \"name\"               \"name_short\"        \n [4] \"name_tv\"            \"gender\"             \"function\"          \n [7] \"country_code\"       \"country\"            \"country_full\"      \n[10] \"nationality\"        \"nationality_full\"   \"nationality_code\"  \n[13] \"height\"             \"weight\"             \"disciplines\"       \n[16] \"events\"             \"birth_date\"         \"birth_place\"       \n[19] \"birth_country\"      \"residence_place\"    \"residence_country\" \n[22] \"nickname\"           \"hobbies\"            \"occupation\"        \n[25] \"education\"          \"family\"             \"lang\"              \n[28] \"coach\"              \"reason\"             \"hero\"              \n[31] \"influence\"          \"philosophy\"         \"sporting_relatives\"\n[34] \"ritual\"             \"other_sports\"       \"age\"               \n\n\n\nmean(olympic_df1$weight)\n\n[1] NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] -93.50138\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  -99.0   -99.0   -99.0   -93.5   -99.0   113.0      11 \n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] 77.68889\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  51.00   67.00   76.50   77.69   88.00  113.00    8417"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#filter",
    "href": "lecture_code/session2notes_L01.html#filter",
    "title": "session 2 notes",
    "section": "Filter",
    "text": "Filter\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html",
    "href": "lecture_code/session2notes_L02.html",
    "title": "session 2 notes",
    "section": "",
    "text": "add up the numbers\ndivide by the amount of numbers\n\nto run a line of code: CTRL + ENTER\n“c” for concatenate (“combine”)\n\nsome_data &lt;- c(32, 45, 16, 78, 39)\nsum(some_data)\n\n[1] 210\n\nlength(some_data)\n\n[1] 5\n\nsum(some_data) / length(some_data)\n\n[1] 42\n\nmean(some_data)\n\n[1] 42\n\n\n\n\nNA for not applicable (“missing data”)\nR stops calculations upon missing data\n* want to avoid the missing data\n\nsome_data2 &lt;- c(32, 45, 16, 78, NA, 39) #another list\nmean(some_data2)\n\n[1] NA\n\nmean(some_data2, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#missing-data",
    "href": "lecture_code/session2notes_L02.html#missing-data",
    "title": "session 2 notes",
    "section": "",
    "text": "NA for not applicable (“missing data”)\nR stops calculations upon missing data\n* want to avoid the missing data\n\nsome_data2 &lt;- c(32, 45, 16, 78, NA, 39) #another list\nmean(some_data2)\n\n[1] NA\n\nmean(some_data2, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#load-data",
    "href": "lecture_code/session2notes_L02.html#load-data",
    "title": "session 2 notes",
    "section": "Load Data",
    "text": "Load Data\n\nolympic_df1 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv\")\n\nRows: 8687 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (31): name, name_short, name_tv, gender, function, country_code, countr...\ndbl   (4): code, height, weight, age\ndate  (1): birth_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nolympic_df2 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv\")\n\nRows: 11110 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (31): name, name_short, name_tv, gender, function, country_code, countr...\ndbl   (4): code, height, weight, age\ndate  (1): birth_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#explore-data",
    "href": "lecture_code/session2notes_L02.html#explore-data",
    "title": "session 2 notes",
    "section": "Explore Data",
    "text": "Explore Data\n\nhead(olympic_df1)\n\n# A tibble: 6 × 36\n     code name         name_short name_tv gender `function` country_code country\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n1 1532873 AMOYAN Malk… AMOYAN M   Malkha… Male   Athlete    ARM          Armenia\n2 1532874 GALSTYAN Sl… GALSTYAN S Slavik… Male   Athlete    ARM          Armenia\n3 1532944 HARUTYUNYAN… HARUTYUNY… Arsen … Male   Athlete    ARM          Armenia\n4 1532945 TEVANYAN Va… TEVANYAN V Vazgen… Male   Athlete    ARM          Armenia\n5 1533136 BASS BITTAY… BASS BITT… Gina M… Female Athlete    GAM          Gambia \n6 1533176 CAMARA Ebra… CAMARA E   Ebrahi… Male   Athlete    GAM          Gambia \n# ℹ 28 more variables: country_full &lt;chr&gt;, nationality &lt;chr&gt;,\n#   nationality_full &lt;chr&gt;, nationality_code &lt;chr&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;,\n#   disciplines &lt;chr&gt;, events &lt;chr&gt;, birth_date &lt;date&gt;, birth_place &lt;chr&gt;,\n#   birth_country &lt;chr&gt;, residence_place &lt;chr&gt;, residence_country &lt;chr&gt;,\n#   nickname &lt;chr&gt;, hobbies &lt;chr&gt;, occupation &lt;chr&gt;, education &lt;chr&gt;,\n#   family &lt;chr&gt;, lang &lt;chr&gt;, coach &lt;chr&gt;, reason &lt;chr&gt;, hero &lt;chr&gt;,\n#   influence &lt;chr&gt;, philosophy &lt;chr&gt;, sporting_relatives &lt;chr&gt;, …\n\nstr(olympic_df1) #structure\n\nspc_tbl_ [8,687 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code              : num [1:8687] 1532873 1532874 1532944 1532945 1533136 ...\n $ name              : chr [1:8687] \"AMOYAN Malkhas\" \"GALSTYAN Slavik\" \"HARUTYUNYAN Arsen\" \"TEVANYAN Vazgen\" ...\n $ name_short        : chr [1:8687] \"AMOYAN M\" \"GALSTYAN S\" \"HARUTYUNYAN A\" \"TEVANYAN V\" ...\n $ name_tv           : chr [1:8687] \"Malkhas AMOYAN\" \"Slavik GALSTYAN\" \"Arsen HARUTYUNYAN\" \"Vazgen TEVANYAN\" ...\n $ gender            : chr [1:8687] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ function          : chr [1:8687] \"Athlete\" \"Athlete\" \"Athlete\" \"Athlete\" ...\n $ country_code      : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ country           : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ country_full      : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality       : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_full  : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_code  : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ height            : num [1:8687] 0 0 0 0 161 178 0 0 183 0 ...\n $ weight            : num [1:8687] -99 -99 -99 -99 -99 -99 -99 -99 -99 -99 ...\n $ disciplines       : chr [1:8687] \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" ...\n $ events            : chr [1:8687] \"[\\\"Men's Greco-Roman 77kg\\\"]\" \"[\\\"Men's Greco-Roman 67kg\\\"]\" \"[\\\"Men's Freestyle 57kg\\\"]\" \"[\\\"Men's Freestyle 65kg\\\"]\" ...\n $ birth_date        : Date[1:8687], format: \"1999-01-22\" \"1996-12-21\" ...\n $ birth_place       : chr [1:8687] \"YEREVAN\" NA \"MASIS\" \"POKR VEDI\" ...\n $ birth_country     : chr [1:8687] \"Armenia\" NA \"Armenia\" \"Armenia\" ...\n $ residence_place   : chr [1:8687] \"YEREVAN\" \"YEREVAN\" \"YEREVAN\" NA ...\n $ residence_country : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nickname          : chr [1:8687] NA NA NA NA ...\n $ hobbies           : chr [1:8687] NA NA NA NA ...\n $ occupation        : chr [1:8687] NA NA \"Athlete\" \"Athlete\" ...\n $ education         : chr [1:8687] NA NA \"Graduated with a Master's degree from the Armenian State Institute of Physical Culture and Sport (2023)\" \"Studied at the Armenian State Institute of Physical Culture and Sport (Yerevan, ARM)\" ...\n $ family            : chr [1:8687] NA NA \"Wife, Diana (married October 2022). Daughter, Marias (born 2023)\" \"Wife, Sona (married November 2023)\" ...\n $ lang              : chr [1:8687] \"Armenian\" \"Armenian\" \"Armenian\" \"Armenian, Russian\" ...\n $ coach             : chr [1:8687] NA \"Personal: Martin Alekhanyan (ARM).&lt;br&gt;National: Armen Babalaryan (ARM)\" \"National: Habetnak Kurghinyan\" \"National: Habetnak Kurghinyan (ARM)\" ...\n $ reason            : chr [1:8687] NA NA \"While doing karate he noticed wrestlers training and decided to give it a try. He also tried judo but his fathe\"| __truncated__ \"“My family did not like wrestling very much. At first I wanted to do boxing but my older friends advised me to \"| __truncated__ ...\n $ hero              : chr [1:8687] NA NA \"Wrestler Armen Nazaryan (ARM, BUL), two-time Olympic champion (1996, 2000) and 2004 bronze medallist. Eight-tim\"| __truncated__ NA ...\n $ influence         : chr [1:8687] NA NA NA NA ...\n $ philosophy        : chr [1:8687] \"\\\"To become a good athlete, you first have to be a good person.\\\" (ankakh.com, 6 Oct 2018)\" NA \"“Nothing is impossible, set goals in front of you, fight and achieve it.” (Instagram, 13 May 2023)\" NA ...\n $ sporting_relatives: chr [1:8687] \"Uncle, Roman Amoyan (wrestling), 2008 Olympic bronze medallist and two-time European champion in Greco-Roman\" NA NA NA ...\n $ ritual            : chr [1:8687] NA NA NA NA ...\n $ other_sports      : chr [1:8687] NA NA NA NA ...\n $ age               : num [1:8687] 25 28 25 25 29 28 30 27 27 17 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   name = col_character(),\n  ..   name_short = col_character(),\n  ..   name_tv = col_character(),\n  ..   gender = col_character(),\n  ..   `function` = col_character(),\n  ..   country_code = col_character(),\n  ..   country = col_character(),\n  ..   country_full = col_character(),\n  ..   nationality = col_character(),\n  ..   nationality_full = col_character(),\n  ..   nationality_code = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   disciplines = col_character(),\n  ..   events = col_character(),\n  ..   birth_date = col_date(format = \"\"),\n  ..   birth_place = col_character(),\n  ..   birth_country = col_character(),\n  ..   residence_place = col_character(),\n  ..   residence_country = col_character(),\n  ..   nickname = col_character(),\n  ..   hobbies = col_character(),\n  ..   occupation = col_character(),\n  ..   education = col_character(),\n  ..   family = col_character(),\n  ..   lang = col_character(),\n  ..   coach = col_character(),\n  ..   reason = col_character(),\n  ..   hero = col_character(),\n  ..   influence = col_character(),\n  ..   philosophy = col_character(),\n  ..   sporting_relatives = col_character(),\n  ..   ritual = col_character(),\n  ..   other_sports = col_character(),\n  ..   age = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ncolnames(olympic_df1) #column names\n\n [1] \"code\"               \"name\"               \"name_short\"        \n [4] \"name_tv\"            \"gender\"             \"function\"          \n [7] \"country_code\"       \"country\"            \"country_full\"      \n[10] \"nationality\"        \"nationality_full\"   \"nationality_code\"  \n[13] \"height\"             \"weight\"             \"disciplines\"       \n[16] \"events\"             \"birth_date\"         \"birth_place\"       \n[19] \"birth_country\"      \"residence_place\"    \"residence_country\" \n[22] \"nickname\"           \"hobbies\"            \"occupation\"        \n[25] \"education\"          \"family\"             \"lang\"              \n[28] \"coach\"              \"reason\"             \"hero\"              \n[31] \"influence\"          \"philosophy\"         \"sporting_relatives\"\n[34] \"ritual\"             \"other_sports\"       \"age\"               \n\n\n\nmean(olympic_df1$weight)\n\n[1] NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] -93.50138\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  -99.0   -99.0   -99.0   -93.5   -99.0   113.0      11 \n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA\n\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] 77.68889\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  51.00   67.00   76.50   77.69   88.00  113.00    8417"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#filter",
    "href": "lecture_code/session2notes_L02.html#filter",
    "title": "session 2 notes",
    "section": "Filter",
    "text": "Filter\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "lecture_code/session4notes_L01.html",
    "href": "lecture_code/session4notes_L01.html",
    "title": "session 4 notes",
    "section": "",
    "text": "Loading a CSV file with the read_csv command.\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")\n\nRows: 133 Columns: 84\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (38): timestamp, currentCourse, statsBefore, classStanding, major, resid...\ndbl (46): numCourses, GPA, hoursStudying, age, height, shoeSize, weight, cal...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session4notes_L01.html#visualization",
    "href": "lecture_code/session4notes_L01.html#visualization",
    "title": "session 4 notes",
    "section": "Visualization",
    "text": "Visualization\n\ndemo_df |&gt;\n  ggplot(aes(x = fct_rev(fct_infreq(major)), fill = major)) +\n  coord_flip() +\n  geom_bar(stat = \"count\") +\n  labs(title = \"SML 201 students by major\",\n       subtitle = \"Fall 2024\",\n       y = \"number of students\",\n       x = \"\") +\n  theme_minimal() + #removes gray background\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html",
    "href": "posts/06_geospatial/06_geospatial.html",
    "title": "6: Geospatial",
    "section": "",
    "text": "Goal: Visualize geospatial data\nObjective: Merge shapefiles and data files\n\n\n\n\n\n\n\nNJ at a glance\n\n\n\nimage source: Totally Bamboo\n\n\n\n\n\n\nMoving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file\n\n\n\n\n\nnj_health &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_health.csv\")\nnj_pop    &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_pop.csv\")\nnj_shp    &lt;- readr::read_rds(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_shp.rds\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#start",
    "href": "posts/06_geospatial/06_geospatial.html#start",
    "title": "6: Geospatial",
    "section": "",
    "text": "Goal: Visualize geospatial data\nObjective: Merge shapefiles and data files\n\n\n\n\n\n\n\nNJ at a glance\n\n\n\nimage source: Totally Bamboo"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#template-files",
    "href": "posts/06_geospatial/06_geospatial.html#template-files",
    "title": "6: Geospatial",
    "section": "",
    "text": "Moving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#load-data",
    "href": "posts/06_geospatial/06_geospatial.html#load-data",
    "title": "6: Geospatial",
    "section": "",
    "text": "nj_health &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_health.csv\")\nnj_pop    &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_pop.csv\")\nnj_shp    &lt;- readr::read_rds(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_shp.rds\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#centroids",
    "href": "posts/06_geospatial/06_geospatial.html#centroids",
    "title": "6: Geospatial",
    "section": "Centroids",
    "text": "Centroids\n\n# Calculate the centroid of each hexagon to add the label\n# https://stackoverflow.com/questions/49343958/do-the-values-returned-by-rgeosgcentroid-and-sfst-centroid-differ\ncenters &lt;- data.frame(\n  st_coordinates(st_centroid(nj_shp$geometry)),\n  id=nj_shp$COUNTY)\n\nnj_counties &lt;- nj_shp |&gt;\n  left_join(centers, by = c(\"COUNTY\" = \"id\"))"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#text-for-labels",
    "href": "posts/06_geospatial/06_geospatial.html#text-for-labels",
    "title": "6: Geospatial",
    "section": "Text (for labels)",
    "text": "Text (for labels)\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_text(aes(x = X, y = Y, label = COUNTY)) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#labels",
    "href": "posts/06_geospatial/06_geospatial.html#labels",
    "title": "6: Geospatial",
    "section": "Labels",
    "text": "Labels\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_label(aes(x = X, y = Y, label = COUNTY)) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#subset",
    "href": "posts/06_geospatial/06_geospatial.html#subset",
    "title": "6: Geospatial",
    "section": "Subset",
    "text": "Subset\n\nnj_label_subset &lt;- nj_counties |&gt;\n  filter(COUNTY %in% c(\"MERCER\", \"SUSSEX\", \"SALEM\"))\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_label(aes(x = X, y = Y, label = COUNTY),\n             data = nj_label_subset,\n             size = 2) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#per-capita",
    "href": "posts/06_geospatial/06_geospatial.html#per-capita",
    "title": "6: Geospatial",
    "section": "Per Capita",
    "text": "Per Capita\n\nnj_df &lt;- nj_df |&gt;\n  left_join(nj_pop, by = c(\"COUNTY\" = \"county\"))\n\n\nnj_df &lt;- nj_df |&gt;\n  mutate(unemployed_per_cap = number_unemployed / population)\n\n\nnj_df |&gt;\n  ggplot() +\n  geom_sf(aes(fill = unemployed_per_cap)) +\n  labs(title = \"New Jersey Unemployment\",\n       subtitle = \"per capita\",\n       caption = \"SML 201\") +\n  scale_fill_distiller(palette = \"OrRd\",\n                       direction = 1) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html",
    "href": "posts/07_correlation/07_correlation.html",
    "title": "7: Correlation",
    "section": "",
    "text": "library(\"corrplot\")\nlibrary(\"gt\")\nlibrary(\"tidyverse\") #tools for data wrangling and visualization\n\ncorrelatedValues = function(x, r = 0.9){\n  r2 = r**2\n  ve = 1-r2\n  SD = sqrt(ve)\n  e  = rnorm(length(x), mean=0, sd=SD)\n  y  = r*x + e\n  return(y)\n}\njudging_categories &lt;- c(\"aroma\", \"flavor\", \"aftertaste\", \"acidity\", \"body\", \"balance\", \"uniformity\", \"clean_cup\", \"sweetness\")\n\nx1 = rnorm(100, mean = -6, sd = 1)\ny1 = correlatedValues(x1, r = 0.75) + 6\nx2 = rnorm(100, mean = -3, sd = 1)\ny2 = correlatedValues(x2, r = 0.75) + 3\nx3 = rnorm(100, mean = 0, sd = 1)\ny3 = correlatedValues(x3, r = 0.75)\nx4 = rnorm(100, mean = 3, sd = 1)\ny4 = correlatedValues(x4, r = 0.75) - 3\nx5 = rnorm(100, mean = 6, sd = 1)\ny5 = correlatedValues(x5, r = 0.75) - 6\n\ndf1 &lt;- data.frame(x1, y1, \"group 1\")\ndf2 &lt;- data.frame(x2, y2, \"group 2\")\ndf3 &lt;- data.frame(x3, y3, \"group 3\")\ndf4 &lt;- data.frame(x4, y4, \"group 4\")\ndf5 &lt;- data.frame(x5, y5, \"group 5\")\nnames(df1) &lt;- c(\"xdata\", \"ydata\", \"group\")\nnames(df2) &lt;- c(\"xdata\", \"ydata\", \"group\")\nnames(df3) &lt;- c(\"xdata\", \"ydata\", \"group\")\nnames(df4) &lt;- c(\"xdata\", \"ydata\", \"group\")\nnames(df5) &lt;- c(\"xdata\", \"ydata\", \"group\")\ndemo_df &lt;- rbind(df1, df2, df3, df4, df5)"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#start",
    "href": "posts/07_correlation/07_correlation.html#start",
    "title": "7: Correlation",
    "section": "Start",
    "text": "Start\n\n\n\nGoal: Explore covariance\nObjective: Compute interquartile ranges and correlations\n\n\n\n\n\n\n\ncorrelation\n\n\n\nimage source: XKCD"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#data",
    "href": "posts/07_correlation/07_correlation.html#data",
    "title": "7: Correlation",
    "section": "Data",
    "text": "Data\n\n\n\nCoffee Ratings\nsource: Coffee Quality Database\nhost: TidyTuesday — July 7, 2020\n\n\n\n\n\n# coffee_df &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')\ncoffee_df &lt;- readr::read_csv(\"coffee_ratings.csv\")"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#numerical-variables",
    "href": "posts/07_correlation/07_correlation.html#numerical-variables",
    "title": "7: Correlation",
    "section": "Numerical Variables",
    "text": "Numerical Variables\n\nstr(coffee_df, give.attr = FALSE)\n\nspc_tbl_ [1,339 × 43] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ total_cup_points     : num [1:1339] 90.6 89.9 89.8 89 88.8 ...\n $ species              : chr [1:1339] \"Arabica\" \"Arabica\" \"Arabica\" \"Arabica\" ...\n $ owner                : chr [1:1339] \"metad plc\" \"metad plc\" \"grounds for health admin\" \"yidnekachew dabessa\" ...\n $ country_of_origin    : chr [1:1339] \"Ethiopia\" \"Ethiopia\" \"Guatemala\" \"Ethiopia\" ...\n $ farm_name            : chr [1:1339] \"metad plc\" \"metad plc\" \"san marcos barrancas \\\"san cristobal cuch\" \"yidnekachew dabessa coffee plantation\" ...\n $ lot_number           : chr [1:1339] NA NA NA NA ...\n $ mill                 : chr [1:1339] \"metad plc\" \"metad plc\" NA \"wolensu\" ...\n $ ico_number           : chr [1:1339] \"2014/2015\" \"2014/2015\" NA NA ...\n $ company              : chr [1:1339] \"metad agricultural developmet plc\" \"metad agricultural developmet plc\" NA \"yidnekachew debessa coffee plantation\" ...\n $ altitude             : chr [1:1339] \"1950-2200\" \"1950-2200\" \"1600 - 1800 m\" \"1800-2200\" ...\n $ region               : chr [1:1339] \"guji-hambela\" \"guji-hambela\" NA \"oromia\" ...\n $ producer             : chr [1:1339] \"METAD PLC\" \"METAD PLC\" NA \"Yidnekachew Dabessa Coffee Plantation\" ...\n $ number_of_bags       : num [1:1339] 300 300 5 320 300 100 100 300 300 50 ...\n $ bag_weight           : chr [1:1339] \"60 kg\" \"60 kg\" \"1\" \"60 kg\" ...\n $ in_country_partner   : chr [1:1339] \"METAD Agricultural Development plc\" \"METAD Agricultural Development plc\" \"Specialty Coffee Association\" \"METAD Agricultural Development plc\" ...\n $ harvest_year         : chr [1:1339] \"2014\" \"2014\" NA \"2014\" ...\n $ grading_date         : chr [1:1339] \"April 4th, 2015\" \"April 4th, 2015\" \"May 31st, 2010\" \"March 26th, 2015\" ...\n $ owner_1              : chr [1:1339] \"metad plc\" \"metad plc\" \"Grounds for Health Admin\" \"Yidnekachew Dabessa\" ...\n $ variety              : chr [1:1339] NA \"Other\" \"Bourbon\" NA ...\n $ processing_method    : chr [1:1339] \"Washed / Wet\" \"Washed / Wet\" NA \"Natural / Dry\" ...\n $ aroma                : num [1:1339] 8.67 8.75 8.42 8.17 8.25 8.58 8.42 8.25 8.67 8.08 ...\n $ flavor               : num [1:1339] 8.83 8.67 8.5 8.58 8.5 8.42 8.5 8.33 8.67 8.58 ...\n $ aftertaste           : num [1:1339] 8.67 8.5 8.42 8.42 8.25 8.42 8.33 8.5 8.58 8.5 ...\n $ acidity              : num [1:1339] 8.75 8.58 8.42 8.42 8.5 8.5 8.5 8.42 8.42 8.5 ...\n $ body                 : num [1:1339] 8.5 8.42 8.33 8.5 8.42 8.25 8.25 8.33 8.33 7.67 ...\n $ balance              : num [1:1339] 8.42 8.42 8.42 8.25 8.33 8.33 8.25 8.5 8.42 8.42 ...\n $ uniformity           : num [1:1339] 10 10 10 10 10 10 10 10 9.33 10 ...\n $ clean_cup            : num [1:1339] 10 10 10 10 10 10 10 10 10 10 ...\n $ sweetness            : num [1:1339] 10 10 10 10 10 10 10 9.33 9.33 10 ...\n $ cupper_points        : num [1:1339] 8.75 8.58 9.25 8.67 8.58 8.33 8.5 9 8.67 8.5 ...\n $ moisture             : num [1:1339] 0.12 0.12 0 0.11 0.12 0.11 0.11 0.03 0.03 0.1 ...\n $ category_one_defects : num [1:1339] 0 0 0 0 0 0 0 0 0 0 ...\n $ quakers              : num [1:1339] 0 0 0 0 0 0 0 0 0 0 ...\n $ color                : chr [1:1339] \"Green\" \"Green\" NA \"Green\" ...\n $ category_two_defects : num [1:1339] 0 1 0 2 2 1 0 0 0 4 ...\n $ expiration           : chr [1:1339] \"April 3rd, 2016\" \"April 3rd, 2016\" \"May 31st, 2011\" \"March 25th, 2016\" ...\n $ certification_body   : chr [1:1339] \"METAD Agricultural Development plc\" \"METAD Agricultural Development plc\" \"Specialty Coffee Association\" \"METAD Agricultural Development plc\" ...\n $ certification_address: chr [1:1339] \"309fcf77415a3661ae83e027f7e5f05dad786e44\" \"309fcf77415a3661ae83e027f7e5f05dad786e44\" \"36d0d00a3724338ba7937c52a378d085f2172daa\" \"309fcf77415a3661ae83e027f7e5f05dad786e44\" ...\n $ certification_contact: chr [1:1339] \"19fef5a731de2db57d16da10287413f5f99bc2dd\" \"19fef5a731de2db57d16da10287413f5f99bc2dd\" \"0878a7d4b9d35ddbf0fe2ce69a2062cceb45a660\" \"19fef5a731de2db57d16da10287413f5f99bc2dd\" ...\n $ unit_of_measurement  : chr [1:1339] \"m\" \"m\" \"m\" \"m\" ...\n $ altitude_low_meters  : num [1:1339] 1950 1950 1600 1800 1950 ...\n $ altitude_high_meters : num [1:1339] 2200 2200 1800 2200 2200 NA NA 1700 1700 1850 ...\n $ altitude_mean_meters : num [1:1339] 2075 2075 1700 2000 2075 ...\n\n\nRecall that we can use summary on a numerical variable.\n\nsummary(coffee_df$total_cup_points)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   81.08   82.50   82.09   83.67   90.58 \n\n\nThe dplyr way to compute quantiles includes\n\ncoffee_df |&gt;\n  summarize(min = min(total_cup_points, na.rm = TRUE),\n            q25 = quantile(total_cup_points, 0.25, na.rm = TRUE),\n            q50 = quantile(total_cup_points, 0.50, na.rm = TRUE),\n            q75 = quantile(total_cup_points, 0.75, na.rm = TRUE),\n            max = max(total_cup_points, na.rm = TRUE))\n\n# A tibble: 1 × 5\n    min   q25   q50   q75   max\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0  81.1  82.5  83.7  90.6\n\n\nWe can verify that about 50% of the data are below the median value\n\nmean(coffee_df$total_cup_points &lt; \n       median(coffee_df$total_cup_points))\n\n[1] 0.4899178\n\n\nWe can verify that about 75% of the data are indeed below that value for the 0.75 quantile (i.e. 75th percentile.)\n\nmean(coffee_df$total_cup_points &lt; 83.67)\n\n[1] 0.7490665\n\n\nThe interquartile range is the 75th percentile minus the 25th percentile.\n\nsummary(coffee_df$total_cup_points)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   81.08   82.50   82.09   83.67   90.58 \n\n\n\nIQR(coffee_df$total_cup_points, na.rm = TRUE)\n\n[1] 2.59"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#categorical-group",
    "href": "posts/07_correlation/07_correlation.html#categorical-group",
    "title": "7: Correlation",
    "section": "Categorical Group",
    "text": "Categorical Group\nThe dplyr code is easily adaptable to grouped data.\n\ncoffee_df |&gt;\n  group_by(species) |&gt;\n  summarize(min = min(total_cup_points, na.rm = TRUE),\n            q25 = quantile(total_cup_points, 0.25, na.rm = TRUE),\n            q50 = quantile(total_cup_points, 0.50, na.rm = TRUE),\n            q75 = quantile(total_cup_points, 0.75, na.rm = TRUE),\n            max = max(total_cup_points, na.rm = TRUE))\n\n# A tibble: 2 × 6\n  species   min   q25   q50   q75   max\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Arabica   0    81.2  82.5  83.7  90.6\n2 Robusta  73.8  80.2  81.5  82.5  83.8"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#another-example",
    "href": "posts/07_correlation/07_correlation.html#another-example",
    "title": "7: Correlation",
    "section": "Another Example",
    "text": "Another Example\n\n12Boxplot\n\n\n\ncoffee_df |&gt;\n  filter(!is.na(processing_method)) |&gt;\n  group_by(processing_method) |&gt;\n  summarize(min = min(total_cup_points, na.rm = TRUE),\n            q25 = quantile(total_cup_points, 0.25, na.rm = TRUE),\n            q50 = quantile(total_cup_points, 0.50, na.rm = TRUE),\n            q75 = quantile(total_cup_points, 0.75, na.rm = TRUE),\n            max = max(total_cup_points, na.rm = TRUE))\n\n# A tibble: 5 × 6\n  processing_method           min   q25   q50   q75   max\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Natural / Dry              67.9  81.2  82.8  83.8  89  \n2 Other                      63.1  80.8  81.8  83.0  84.7\n3 Pulped natural / honey     80.1  82.0  82.7  83.2  86.6\n4 Semi-washed / Semi-pulped  78.8  81.5  82.5  83.6  86.1\n5 Washed / Wet               59.8  81    82.4  83.5  90.6\n\n\n\n\n\ncoffee_df |&gt;\n  filter(!is.na(processing_method)) |&gt;\n  group_by(processing_method) |&gt;\n  mutate(min_val = min(total_cup_points, na.rm = TRUE),\n         q25 = quantile(total_cup_points, 0.25, na.rm = TRUE),\n         q50 = quantile(total_cup_points, 0.50, na.rm = TRUE),\n         q75 = quantile(total_cup_points, 0.75, na.rm = TRUE),\n         max_val = max(total_cup_points, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(processing_method, min_val, q25, q50, q75, max_val) |&gt;\n  distinct() |&gt;\n  rev() |&gt; #reverse order of columns\n  t() |&gt;   #transpose (switch rows and columns)\n  data.frame() |&gt;\n  slice(1:5) |&gt;\n  set_names(c(\"washed\", \"natural\", \"pulped\", \"semi\", \"other\"))\n\n         washed natural  pulped    semi   other\nmax_val   90.58   89.00   86.58   86.08   84.67\nq75     83.5000 83.8300 83.2075 83.6425 82.9575\nq50      82.420  82.750  82.665  82.500  81.830\nq25     81.0000 81.2500 81.9550 81.5000 80.7925\nmin_val   59.83   67.92   80.08   78.75   63.08\n\n\n\n\n\ncoffee_df |&gt;\n  filter(!is.na(processing_method)) |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = processing_method, y = total_cup_points,\n                   color = processing_method)) +\n  labs(title = \"Coffee Ratings\",\n       subtitle = \"Are these quantities different?\",\n       caption = \"Source: Coffee Quality Database\",\n       x = \"\", y = \"total points\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45),\n        legend.position = \"none\")"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#covariance",
    "href": "posts/07_correlation/07_correlation.html#covariance",
    "title": "7: Correlation",
    "section": "Covariance",
    "text": "Covariance\n\nFormulaIntuitionCommentary\n\n\nFor data \\((X,Y)\\) listed as \\(n\\) data points \\((x_{i}, y_{i})\\), the covariance is defined as\n\\[\\begin{array}{rcl}\n  \\text{Cov}(X,Y) & = & \\frac{1}{2n^{2}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}(x_{i} - x_{j})(y_{i} - y_{j}) \\\\\n  ~ & = & \\text{E}[X] \\cdot \\text{E}[Y] - \\text{E}[XY] \\\\\n  \\end{array}\\]\n\n\n\n\n\nconstructive or destructive waves\n\n\n\nimage source: Fissics\n\n\n\n\nAre resultant numbers large or small?\nUnits? (e.g. “burger-fries”)"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#standardization",
    "href": "posts/07_correlation/07_correlation.html#standardization",
    "title": "7: Correlation",
    "section": "Standardization",
    "text": "Standardization\n\n\n\nz-score\n\\[\\begin{array}{ccc}\nz & = & \\frac{x - \\bar{x}}{s} \\\\\n~ & = & \\frac{\\text{deviation}}{\\text{standard deviation}} \\\\\n\\end{array}\\]\n\n\n\n\n\nCorrelation\n\\[\\begin{array}{ccc}\n  r & = & \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_{i} - \\bar{x})}\\sqrt{\\sum_{i=1}^{n} (y_{i} - \\bar{y})}} \\\\\n  ~ & = & \\frac{\\text{Cov}(X,Y)}{\\text{SD}(X) \\cdot \\text{SD}(Y)} \\\\\n  ~ & = & \\frac{1}{n-1}\\sum_{i=1}^{n}\\left(\\frac{x_{i}-\\bar{x}}{s_{x}}\\right)\\left(\\frac{y_{i}-\\bar{y}}{s_{y}}\\right) \\\\\n\\end{array}\\]\n\n\n\nClaim: The correlation coefficient \\(r\\) has a mathematical range in \\([-1,1]\\):\n\\[-1 \\leq r \\leq 1\\]\n\n\n\n\n\n\nProof\n\n\n\n\n\n[refer to a Calculus-based Probability course]"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#demonstration",
    "href": "posts/07_correlation/07_correlation.html#demonstration",
    "title": "7: Correlation",
    "section": "Demonstration",
    "text": "Demonstration\n\n12345"
  },
  {
    "objectID": "posts/07_correlation/07_correlation.html#examples",
    "href": "posts/07_correlation/07_correlation.html#examples",
    "title": "7: Correlation",
    "section": "Examples",
    "text": "Examples\nCompute the correlation between flavor and aftertaste\n\ncor(coffee_df$flavor, coffee_df$aftertaste)\n\n[1] 0.8956718\n\n\nCompute the correlation between uniformity and clean_cup\n\ncor(coffee_df$uniformity, coffee_df$clean_cup,\n    use = \"pairwise.complete.obs\")\n\n[1] 0.5262187\n\n\nCompute the correlation between aroma and sweetness\n\ncoffee_df |&gt;\n  summarize(r = cor(aroma, sweetness,\n                    use = \"pairwise.complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.253"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html",
    "href": "posts/08_linear_regression/08_linear_regression.html",
    "title": "8: Linear Regression",
    "section": "",
    "text": "library(\"gt\")        #great tables\nlibrary(\"HistData\")  #historical data sets\nlibrary(\"tidyverse\") #tools for data wrangling and visualization\n\nliquor_df &lt;- data.frame(\n  year = 2014:2022,\n  LLV = c(129, 54, 103, 50, 15, 10, 18, 49,57)\n)\nMM_df &lt;- data.frame(\n  S = c(0.08, 0.12, 0.54, 1.23, 1.82, 2.72, 4.94, 10.00),\n  v = c(0.15, 0.21, 0.7, 1.1, 1.3, 1.5, 1.7, 1.8)\n)"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#start",
    "href": "posts/08_linear_regression/08_linear_regression.html#start",
    "title": "8: Linear Regression",
    "section": "Start",
    "text": "Start\n\n\n\nGoal: Make predictions\nObjective: Perform linear regression and compute coefficients of determination\n\n\n\n\n\n\n\nlinear regression\n\n\n\nimage source: XKCD"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#linear-regression-in-r",
    "href": "posts/08_linear_regression/08_linear_regression.html#linear-regression-in-r",
    "title": "8: Linear Regression",
    "section": "Linear Regression in R",
    "text": "Linear Regression in R\n\nresponse variable (y): LLV\nexplanatory variable (x): year\n\n\nlin_fit &lt;- lm(LLV ~ year, data = liquor_df)\n\nIn a model equation, the tilde ~ is read as “explained by”. In this model, we can say that the response variable LLV is explained by the year."
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#prediction-in-r",
    "href": "posts/08_linear_regression/08_linear_regression.html#prediction-in-r",
    "title": "8: Linear Regression",
    "section": "Prediction in R",
    "text": "Prediction in R\nWe use the predict function where the input is a data frame. In this example, we are predicting the number of judicial referrals for liquor law violations in the year 2023.\n\nyhat &lt;- predict(lin_fit,\n                newdata = data.frame(year = 2023))"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#validation",
    "href": "posts/08_linear_regression/08_linear_regression.html#validation",
    "title": "8: Linear Regression",
    "section": "Validation",
    "text": "Validation\nIn this simple example, we know the true answer: there were 262 judicial referrals for liquor law violations in the year 2023\n\n# true value\ny &lt;- 262\n\n\n# absolute error\nabs(y - yhat)\n\n       1 \n250.8611 \n\n\n\n# relative error\nabs(y - yhat) / y\n\n        1 \n0.9574852 \n\n\nWhy was the prediction so inaccurate?"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#scatterplot",
    "href": "posts/08_linear_regression/08_linear_regression.html#scatterplot",
    "title": "8: Linear Regression",
    "section": "Scatterplot",
    "text": "Scatterplot\nIt is a good idea to look at the data (when practical).\n\nliquor_df |&gt;\n  ggplot() +\n  geom_point(aes(x = factor(year), y = LLV),\n             size = 4, color = \"black\") +\n  labs(title = \"Liquor Law Violations\",\n       subtitle = \"Princeton University, main campus\",\n       caption = \"SML 201\",\n       x = \"year\", y = \"judicial referrals\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#smooth",
    "href": "posts/08_linear_regression/08_linear_regression.html#smooth",
    "title": "8: Linear Regression",
    "section": "Smooth",
    "text": "Smooth\nOn the visual size, linear regression summarizes a scatterplot.\n\nliquor_df |&gt;\n  ggplot(aes(x = year, y = LLV)) +\n  geom_point(size = 4, color = \"black\") +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE,\n              color = \"blue\", linewidth = 2) +\n  labs(title = \"Liquor Law Violations\",\n       subtitle = \"Princeton University, main campus\",\n       caption = \"SML 201\",\n       x = \"year\", y = \"judicial referrals\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#centroid",
    "href": "posts/08_linear_regression/08_linear_regression.html#centroid",
    "title": "8: Linear Regression",
    "section": "Centroid",
    "text": "Centroid\nClaim: a linear regression model goes through the centroid\n\\[(\\bar{x}, \\bar{y})\\]\n\nxbar &lt;- mean(liquor_df$year)\nybar &lt;- mean(liquor_df$LLV)\n\nliquor_df |&gt;\n  ggplot(aes(x = year, y = LLV)) +\n  geom_point(size = 4, color = \"black\") +\n  geom_vline(xintercept = xbar, color = \"green\") +\n  geom_hline(yintercept = ybar, color = \"green\") +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE,\n              color = \"blue\", linewidth = 2) +\n  labs(title = \"Linear Regression\",\n       subtitle = \"A linear regression model goes through the centroid \",\n       caption = \"SML 201\",\n       x = \"year\", y = \"judicial referrals\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#vector-space",
    "href": "posts/08_linear_regression/08_linear_regression.html#vector-space",
    "title": "8: Linear Regression",
    "section": "Vector Space",
    "text": "Vector Space\nHow was the line drawn?\n\n\n\nWhere to draw the line?"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#linear-model",
    "href": "posts/08_linear_regression/08_linear_regression.html#linear-model",
    "title": "8: Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\n\\[\\hat{y} = a + bx\\]\n\n\\(\\hat{y}\\): predicted value\n\\(a\\): intercept\n\\(b\\): slope"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#residuals",
    "href": "posts/08_linear_regression/08_linear_regression.html#residuals",
    "title": "8: Linear Regression",
    "section": "Residuals",
    "text": "Residuals\nA residual is the difference between a predicted value and its true value.\n\nliquor_df &lt;- liquor_df |&gt;\n  mutate(predictions = predict(lin_fit,\n                               newdata = data.frame(year = liquor_df$year)),\n         residuals = predictions - LLV)\n\n\nliquor_df |&gt;\n  ggplot(aes(x = year, y = LLV)) +\n  geom_segment(aes(x = year, y = predictions, \n                   xend = year, yend = LLV), \n               color = \"purple\", linewidth = 3) +\n  geom_point(size = 4, color = \"black\") +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE,\n              color = \"blue\", linewidth = 2) +\n  geom_point(aes(x = year, y = predictions),\n             color = \"red\", size = 4) +\n  labs(title = \"Linear Regression\",\n       subtitle = \"black: true values\\nred: predictions\\npurple: residuals\",\n       caption = \"SML 201\",\n       x = \"year\", y = \"judicial referrals\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#corollary-residual-balance",
    "href": "posts/08_linear_regression/08_linear_regression.html#corollary-residual-balance",
    "title": "8: Linear Regression",
    "section": "Corollary: Residual Balance",
    "text": "Corollary: Residual Balance\nClaim: the average of the residuals is zero\n\nmean(liquor_df$residuals)\n\n[1] 1.616879e-12"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#method-of-least-squares",
    "href": "posts/08_linear_regression/08_linear_regression.html#method-of-least-squares",
    "title": "8: Linear Regression",
    "section": "Method of Least Squares",
    "text": "Method of Least Squares\nIdea: The best-fit line is where the sum-of-squared residuals is minimized.\n\\[E(a,b) = \\sum_{i=1}^{n} (y_{i} - a - bx_{i})^{2}\\]\nClaim: \\[a = \\frac{ (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }, \\quad b = \\frac{ n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }\\]\n\n\n\n\n\n\n(optional) Proof\n\n\n\n\n\nSearch for a critical point by setting the partial derivatives (along with the Chain Rule) equal to zero.\n\\[0 = \\frac{\\partial E}{\\partial a} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i}) = 2an + 2b\\sum_{i = 1}^{n}x_{i} - 2\\sum_{i = 1}^{n} y_{i}\\] \\[0 = \\frac{\\partial E}{\\partial b} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i})x_{i} = 2a\\sum_{i = 1}^{n}x_{i} + 2b\\sum_{i = 1}^{n}x_{i}^{2} - 2\\sum_{i = 1}^{n} x_{i}y_{i}\\]\nCreate a matrix system of equations.\n\\[\\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right]\n  =\n  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right]\n  \\]\nEmploy a matrix inverse.\n$$\n\\[\\begin{array}{rcl}\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = &\n  \\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]^{-1}\\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}} \\left[  \\begin{array}{cc}\n  \\sum_{i = 1}^{n}x_{i}^{2} & -\\sum_{i = 1}^{n}x_{i} \\\\\n  -\\sum_{i = 1}^{n}x_{i} & n \\\\\n  \\end{array}\\right]  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}}\n  \\left[  \\begin{array}{c}  (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) \\\\  n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) \\end{array}\\right] \\\\\n\\end{array}\\]\n$$"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#lm",
    "href": "posts/08_linear_regression/08_linear_regression.html#lm",
    "title": "8: Linear Regression",
    "section": "LM",
    "text": "LM\n\\[\\hat{y} = a + bx\\]\n\nlm(LLV ~ year, data = liquor_df)\n\n\nCall:\nlm(formula = LLV ~ year, data = liquor_df)\n\nCoefficients:\n(Intercept)         year  \n   17307.79        -8.55  \n\n\nFor every increase in year, the number of judicial referrals decreases by 8.55.\n\nPrediction\nPredict the number of judicial referrals for liquor law violations in the year 2023.\n\na &lt;- summary(lin_fit)$coefficients[1]\nb &lt;- summary(lin_fit)$coefficients[2]\n\na + b*(2023)\n\n[1] 11.13889\n\npredict(lin_fit, newdata = data.frame(year = 2023))\n\n       1 \n11.13889"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#definition",
    "href": "posts/08_linear_regression/08_linear_regression.html#definition",
    "title": "8: Linear Regression",
    "section": "Definition",
    "text": "Definition\nThe coefficient of determination is defined as\n\\[R^{2} = \\frac{\\text{explained variance}}{\\text{total variance}}\\]\nFor analysis of variance:\n\nexplained variation: \\(\\sum(\\hat{y} - \\bar{y})^{2}\\)\nunexplained variation: \\(\\sum(y - \\hat{y})^{2}\\)\ntotal variation = explained variation + unexplained variation \\[\\sum(y - \\bar{y})^{2} = \\sum(\\hat{y} - \\bar{y})^{2} + \\sum(y - \\hat{y})^{2}\\]"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#inference",
    "href": "posts/08_linear_regression/08_linear_regression.html#inference",
    "title": "8: Linear Regression",
    "section": "Inference",
    "text": "Inference\nWhy is that denoted “\\(R^2\\)”? For linear regression, the coefficient of determination is literally the square of the correlation coefficient (\\(r\\))\n\ncorrelation \\(-1 \\leq r \\leq 1\\) implies coefficient of determination \\[0 \\leq R^{2} \\leq 1\\]\nwant more “explained variation”, thus higher \\(R^{2}\\) means a better model"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#guidelines",
    "href": "posts/08_linear_regression/08_linear_regression.html#guidelines",
    "title": "8: Linear Regression",
    "section": "Guidelines",
    "text": "Guidelines\n\n\nIn this course, we will simply follow the Pearson suggestions for interpreting coefficient of determination values:\n\n\\(0 \\leq R^{2} &lt; 0.4\\): poor model\n\\(0.4 \\leq R^{2} &lt; 0.7\\): good model\n\\(0.7 \\leq R^{2} \\leq 1.0\\): great model\n\n\n\n\n\n\n\nKarl Pearson"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#model-statistics",
    "href": "posts/08_linear_regression/08_linear_regression.html#model-statistics",
    "title": "8: Linear Regression",
    "section": "Model Statistics",
    "text": "Model Statistics\nIn R, we can use summary to access model statistics.\n\nsummary(lin_fit)\n\n\nCall:\nlm(formula = LLV ~ year, data = liquor_df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-38.89 -25.54 -12.44  32.01  40.91 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 17307.789   9047.707   1.913   0.0973 .\nyear           -8.550      4.483  -1.907   0.0982 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 34.73 on 7 degrees of freedom\nMultiple R-squared:  0.3419,    Adjusted R-squared:  0.2479 \nF-statistic: 3.637 on 1 and 7 DF,  p-value: 0.09819\n\n\nHere in SML 201, we will use the “Adjusted R-squared” value that accounts for the number of predictor variables. Treat negative adjusted R-squared values simply as zero variation explained, and then look for the highest adjusted R-squared values.\n\nsummary(lin_fit)$adj.r.squared\n\n[1] 0.2478815"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#francis-galton",
    "href": "posts/08_linear_regression/08_linear_regression.html#francis-galton",
    "title": "8: Linear Regression",
    "section": "Francis Galton",
    "text": "Francis Galton\n\n\n\n\n\nSir Francis Galton\n\n\n\n\n\n\n1822 - 1911\ncousin of Charles Darwin\ncorrelation discovery\n\n1846: August Bravais\n1888: Francis Galton"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#do-tall-parents-have-tall-children",
    "href": "posts/08_linear_regression/08_linear_regression.html#do-tall-parents-have-tall-children",
    "title": "8: Linear Regression",
    "section": "Do tall parents have tall children?",
    "text": "Do tall parents have tall children?\nThe Galton data set in the HistData package has two variables\n\nparents’ height (see documentation for weighted formula)\nchild’s height\n\nfor about 200 families\n\nheredity_df &lt;- HistData::Galton"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#scatterplot-1",
    "href": "posts/08_linear_regression/08_linear_regression.html#scatterplot-1",
    "title": "8: Linear Regression",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nheredity_df |&gt;\n  ggplot(aes(x = parent, y = child)) +\n  geom_point() +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE) +\n  labs(title = \"Do tall parents have tall children?\",\n       subtitle = \"Galton Survey of Heights\",\n       caption = \"SML 201\",\n       x = \"parent's heights (weighted average)\",\n       y = \"child's height\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#linear-model-1",
    "href": "posts/08_linear_regression/08_linear_regression.html#linear-model-1",
    "title": "8: Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\n\nlin_fit &lt;- lm(child ~ parent, data = heredity_df)\n\n# slope\nsummary(lin_fit)$coefficients[2]\n\n[1] 0.6462906\n\n\nFor every one inch increase in parents’ height, the child’s height increases by about 0.65 inches."
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#prediction-1",
    "href": "posts/08_linear_regression/08_linear_regression.html#prediction-1",
    "title": "8: Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nIf the parents are 69 inches in height, what do we predict for the height of the child?\n\npredict(lin_fit, newdata = data.frame(parent = 69))\n\n       1 \n68.53558 \n\n\nIf the parents are 58 inches in height, what do we predict for the height of the child?\n\npredict(lin_fit, newdata = data.frame(parent = 58))\n\n       1 \n61.42638"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#regression-to-the-mean",
    "href": "posts/08_linear_regression/08_linear_regression.html#regression-to-the-mean",
    "title": "8: Linear Regression",
    "section": "Regression to the Mean",
    "text": "Regression to the Mean\nIn these early studies of heredity, Galton coined the phrase\n\\[\\text{regression to the mean}\\]\nand similar calculations have been called regression ever since."
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#michaelis-and-menton",
    "href": "posts/08_linear_regression/08_linear_regression.html#michaelis-and-menton",
    "title": "8: Linear Regression",
    "section": "Michaelis and Menton",
    "text": "Michaelis and Menton\n\n\n\n\n\nLeonor Michaelis and Maud Menton\n\n\n\n\n\nLeonor Michaelis\n\nBerlin University (1897)\n\nMaud Menton\n\nUniversity of Toronto (1911)\n\nDie Kinetik der Invertinwirkung (1913)\n\\[v = \\frac{V_{\\text{max}}[S]}{K_{m} + [S]}\\]\n\n\\(v\\): reaction rate (micromolars per minute)\n\\([S]\\): substrate concentration (micromolars)"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#enzyme-kinetics",
    "href": "posts/08_linear_regression/08_linear_regression.html#enzyme-kinetics",
    "title": "8: Linear Regression",
    "section": "Enzyme Kinetics",
    "text": "Enzyme Kinetics\n\n\n\n\n\nEssential Cell Biology\n\n\n\n\n\nThe reaction rates of the reaction S \\(\\rightarrow\\) P catalyzed by enzyme E were determined under conditions such that only very little product was formed. Compute the maximum reaction velocity asymptote \\(V_{\\text{max}}\\) and the Michaelis-Menton constant \\(K_{m}\\)\n\n\n\n\n\n\n\n\nMichaelis Menton Experiment\n\n\nreaction rate vs substrate concentration\n\n\nS\nv\n\n\n\n\n0.08\n0.15\n\n\n0.12\n0.21\n\n\n0.54\n0.70\n\n\n1.23\n1.10\n\n\n1.82\n1.30\n\n\n2.72\n1.50\n\n\n4.94\n1.70\n\n\n10.00\n1.80\n\n\n\nDie Kinetik der Invertinwirkung"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#scatterplot-2",
    "href": "posts/08_linear_regression/08_linear_regression.html#scatterplot-2",
    "title": "8: Linear Regression",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nreaction rate (lower case v)\nsubstrate concentration (capital S)\n\n\nMM_df |&gt;\n  ggplot(aes(x = S, y = v)) +\n  geom_smooth(formula = \"y ~ x\", method = \"loess\", se = TRUE) +\n  geom_point(color = \"black\", size = 4) +\n  labs(title = \"Michaelis Menton Enzyme Kinetics Experiment\",\n       subtitle = \"reaction rate vs substrate concentration\",\n       caption = \"Essential Cell Biology\",\n       x = \"substrate concentration (micromolars)\",\n       y = \"reaction rate (micromolars per minute)\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#transformation",
    "href": "posts/08_linear_regression/08_linear_regression.html#transformation",
    "title": "8: Linear Regression",
    "section": "Transformation",
    "text": "Transformation\nHans Lineweaver (George Washington Univ., 1934)\n\\[v = \\frac{V_{\\text{max}}[S]}{K_{m} + [S]} \\quad\\rightarrow\\quad \\frac{1}{v} = \\frac{K_{m}}{V_{\\text{max}}} \\cdot \\frac{1}{[S]} + \\frac{1}{V_{\\text{max}}}\\]\nThe reciprocal of the reaction rate is linear with respect to the reciprocal of the substrate concentration."
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#double-reciprocal-plot",
    "href": "posts/08_linear_regression/08_linear_regression.html#double-reciprocal-plot",
    "title": "8: Linear Regression",
    "section": "Double-Reciprocal Plot",
    "text": "Double-Reciprocal Plot\n\nMM_df &lt;- MM_df |&gt;\n  mutate(rS = 1/S,\n         rv = 1/v)\n\n\nMM_df |&gt;\n  ggplot(aes(x = rS, y = rv)) +\n  geom_smooth(formula = \"y ~ x\", method = \"lm\", se = FALSE) +\n  geom_point(color = \"black\", size = 4) +\n  labs(title = \"Michaelis Menton Enzyme Kinetics Experiment\",\n       subtitle = \"Double Reciprocal Plot\",\n       caption = \"Essential Cell Biology\",\n       x = \"1/[S] (1/micromoles)\",\n       y = \"1/v (minutes per micromolar)\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#linear-model-2",
    "href": "posts/08_linear_regression/08_linear_regression.html#linear-model-2",
    "title": "8: Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\n\nlin_fit &lt;- lm(rv ~ rS, data = MM_df)"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#coefficient-of-determination-1",
    "href": "posts/08_linear_regression/08_linear_regression.html#coefficient-of-determination-1",
    "title": "8: Linear Regression",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\n\nsummary(lin_fit)$adj.r.squared\n\n[1] 0.9995051"
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#extracting-the-constants",
    "href": "posts/08_linear_regression/08_linear_regression.html#extracting-the-constants",
    "title": "8: Linear Regression",
    "section": "Extracting the Constants",
    "text": "Extracting the Constants\n\nslope &lt;- lin_fit$coefficients[2]\nintercept &lt;- lin_fit$coefficients[1]\n\nVmax &lt;- 1/intercept\nKm &lt;- slope * Vmax\n\nprint(paste(\"The Vmax asymptote is \", Vmax))\n\n[1] \"The Vmax asymptote is  1.9894653306508\"\n\nprint(paste(\"The Michaelis-Menton constant is \", Km))\n\n[1] \"The Michaelis-Menton constant is  0.991986524114476\""
  },
  {
    "objectID": "posts/08_linear_regression/08_linear_regression.html#mm-experiment-revisited",
    "href": "posts/08_linear_regression/08_linear_regression.html#mm-experiment-revisited",
    "title": "8: Linear Regression",
    "section": "MM Experiment Revisited",
    "text": "MM Experiment Revisited\n\nMM_df |&gt;\n  ggplot(aes(x = S, y = v)) +\n  geom_smooth(formula = \"y ~ x\", method = \"loess\", se = TRUE) +\n  geom_point(color = \"black\", size = 4) +\n  geom_abline(slope = Km, intercept = 0, color = \"red\") +\n  geom_abline(slope = 0, intercept = Vmax, color = \"purple\") +\n  labs(title = \"Michaelis Menton Enzyme Kinetics Experiment\",\n       subtitle = \"maximum reaction velocity asymptote (purple)\\nMichaelis-Menton constant (red slope)\",\n       caption = \"Essential Cell Biology\",\n       x = \"substrate concentration (micromolars)\",\n       y = \"reaction rate (micromolars per minute)\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html",
    "href": "posts/09_multiple_regression/09_multiple_linear.html",
    "title": "8: Multiple Linear Regression",
    "section": "",
    "text": "library(\"corrplot\")  #visualize correlations simultaneously\nlibrary(\"gt\")        #great tables\nlibrary(\"tidyverse\") #tools for data wrangling and visualization\n\noakland_green &lt;- \"#003831\"\noakland_yellow &lt;- \"#EFB21E\"\n\n# user-defined function\ncor2text &lt;- function(x,y, num_digits = 4){\n  # This function will compute a correlation, round the result, and describe the results\n  # INPUTS:\n  ## x: numerical vector\n  ## y: numerical vector\n  ## num_digits: number of digits for rounding (default: 4)\n  # OUTPUT: string\n  \n  r = cor(x,y, use = \"pairwise.complete.obs\")\n  \n  cor_des &lt;- case_when(\n    r &gt;= 0.7 ~ \"strongly and positively correlated\",\n    r &gt;= 0.4 & r &lt; 0.7 ~ \"slightly and positively correlated\",\n    r &lt;= -0.4 & r &gt; -0.7 ~ \"slightly and negatively correlated\",\n    r &lt;= -0.7 ~ \"strongly and negatively correlated\",\n    .default = \"virtually uncorrelated\"\n  )\n  \n  #return\n  paste0(\"r = \", round(r, num_digits),\n         \", \", cor_des)\n}\nbb_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/data/baseball_data_90s.csv\")\n\noffense_cats &lt;- c(\"R\", \"H\", \"X2B\", \"X3B\", \"HR\", \"BB\", \"SO\", \"SB\")\ndefense_cats &lt;- c(\"RA\", \"ER\", \"HA\", \"HRA\", \"BBA\", \"SOA\", \"E\", \"FP\")"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#start",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#start",
    "title": "8: Multiple Linear Regression",
    "section": "Start",
    "text": "Start\n\n\n\nGoal: Expand to larger regression models\nObjective: Include multiple linear terms and an interaction term\n\n\n\n\n\n\n\nMoneyball (2011)"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#story",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#story",
    "title": "8: Multiple Linear Regression",
    "section": "Story",
    "text": "Story\n\nBookFinance\n\n\n\n\n\n\n\nMoneyball (2003)\n\n\n\n\n\n\nOakland Athletics fielded a competitive team despite having a payroll size around 1/3 of some other franchises\nTraditional scouting vs modern statistics\nIdea: Can we identify qualities (variables) in baseball players that lead to more wins?\n\n\n\n\n\n\n\n\nMLB Team Salaries, 2002\n\n\n\nimage source: Wikimedia Commons"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#data",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#data",
    "title": "8: Multiple Linear Regression",
    "section": "Data",
    "text": "Data\n\nLahmanOffenseDefense\n\n\nToday’s data set comes from the Lahman package, which contains a lot of historical data about Major League Baseball.\n\nLahman package CRAN page\n\n\n\n\nR: runs\nH: hits\nX2B: doubles\nX3B: triples\nHR: home runs\nBB: walks\nSO: strikeouts (by hitters)\nSB: stolen bases\n\n\n\n\nRA: runs allowed\nER: earned runs\nHA: hits allowed\nHRA: home runs allowed\nBBA: walks allowed\nSOA: strikeouts (by pitchers)\nE: errors\nFP: fielding percentage"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#correlation",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#correlation",
    "title": "8: Multiple Linear Regression",
    "section": "Correlation",
    "text": "Correlation\n\nOffenseCodeDefenseCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbb_df |&gt;\n  ggplot(aes(x = R, y = W)) +\n  geom_point(color = oakland_green) + \n  labs(title = \"Wins vs Runs Scored\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", slightly and positively correlated\"),\n       caption = \"seasons 1990 to 1999\",\n       x = \"runs scored\",\n       y = \"wins\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor_value &lt;- cor(bb_df$RA, bb_df$W)\n\nbb_df |&gt;\n  ggplot(aes(x = RA, y = W)) +\n  geom_point(color = oakland_green) + \n  labs(title = \"Wins vs Runs Allowed\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", virtually uncorrelated\"),\n       caption = \"seasons 1990 to 1999\",\n       x = \"runs allowed\",\n       y = \"wins\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#correlation-matrices",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#correlation-matrices",
    "title": "8: Multiple Linear Regression",
    "section": "Correlation Matrices",
    "text": "Correlation Matrices\n\nOffenseCodeDefenseCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbb_df |&gt;\n  select(any_of(offense_cats)) |&gt;\n  cor() |&gt;\n  corrplot.mixed(order = \"FPC\",\n                 upper = \"ellipse\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbb_df |&gt;\n  select(any_of(defense_cats)) |&gt;\n  cor() |&gt;\n  corrplot.mixed(order = \"FPC\",\n                 upper = \"ellipse\")\n\n\n\n\n\n\n\n\n\n\nNew Directions\n\n\n\n\n\nSo far, a sabermetrician might observe and ask\n\nWins are correlated with runs scored\nWhat correlates well with runs scored?"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#model-equation",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#model-equation",
    "title": "8: Multiple Linear Regression",
    "section": "Model Equation",
    "text": "Model Equation\n\nMathCodeInterceptSlopeDetermination\n\n\n\\[\\text{Runs} = \\beta_{0} + \\beta_{1}(\\text{Hits})\\]\n\n\\(\\beta_{0}\\): intercept\n\\(\\beta_{1}\\): change in Runs with respect to Hits\n\n\n\n\nlm(R ~ H, data = bb_df)\n\n\nCall:\nlm(formula = R ~ H, data = bb_df)\n\nCoefficients:\n(Intercept)            H  \n  -108.7903       0.5934  \n\n\n\n\\(\\beta_{0} \\approx -108.7903\\)\n\\(\\beta_{1} \\approx 0.5934\\)\n\n\\[\\text{Runs} = -108.7903 + 0.5934(\\text{Hits})\\]\n\n\nIn a hypothetical scenario where a team has zero hits,\n\\[\\text{Runs} = -108.7903 + 0.5934(0)\\] the model estimates that the baseball team will win about negative 109 games in a season.\n\nsee note about “Removing the intercept” below\n\n\n\nWe continue to intercept the rate of change (or slope)\n\\[\\beta_{1} \\approx 0.5934\\]\nwith language like\n\nFor every additional hit, the number of runs increases by about 0.5934.\n\n\n\nWe can get a sense of how useful this model can be with the coefficient of determination.\n\nmod1 &lt;- lm(R ~ H, data = bb_df) #baseline model\nsummary(mod1)$adj.r.squared\n\n[1] 0.6893222\n\n\n\nAccording to the coefficient of determination, this model (with “Hits” as an explanatory variable) explains about 69 percent of the variance in runs scored.\n\n\n\n\n\n\n\n\n\n\nRemoving the Intercept\n\n\n\n\n\nSometimes an analyst might want to remove the intercept term (here: zero hits should imply zero runs?)\n\\[\\text{Runs} = \\beta_{1}(\\text{Hits})\\]\n\nmod0 &lt;- lm(R ~ H - 1, data = bb_df) #removed intercept\nmod0\n\n\nCall:\nlm(formula = R ~ H - 1, data = bb_df)\n\nCoefficients:\n    H  \n0.517  \n\n\n\nsummary(mod0)$adj.r.squared #removed intercept\n\n[1] 0.993489\n\nsummary(mod1)$adj.r.squared #baseline model\n\n[1] 0.6893222\n\n\nWhile removing the intercept seems great in this simple example, in practice removing the intercept does not tend to generalize to larger models or inclusion of additional data."
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#different-models-different-coefficients",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#different-models-different-coefficients",
    "title": "8: Multiple Linear Regression",
    "section": "Different Models, Different Coefficients",
    "text": "Different Models, Different Coefficients\n\n\n\n\n\n\nCoefficients are different in different models\n\n\n\n\n\n\n\n\n\n\n\n\n\nEarly Baseball Stats Models\n\n\nComparing the coefficients\n\n\ncoefs\nmod1\nmod2\n\n\n\n\nbeta_0\n-108.7903\n-124.4358\n\n\nbeta_1\n0.5934\n0.4382\n\n\nbeta_2\n-\n0.4395\n\n\n\nSML 201\n\n\n\n\n\n\n\n\n\nmod_stats_df &lt;- data.frame(\n  coefs = c(\"beta_0\", \"beta_1\", \"beta_2\"),\n  mod1 = c(-108.7903, 0.5934, \"-\"),\n  mod2 = c(-124.4358, 0.4382, 0.4395)\n)\n\nmod_stats_df |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"SML 201\") |&gt;\n  tab_header(\n    title = \"Early Baseball Stats Models\",\n    subtitle = \"Comparing the coefficients\"\n  ) |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = oakland_green),\n      cell_text(color = oakland_yellow)\n    ),\n    locations = cells_body(columns = mod1)\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = oakland_yellow),\n      cell_text(color = oakland_green)\n    ),\n    locations = cells_body(columns = mod2)\n  )\n\n\n\n\nIn practice, we tend to explore several models through trial-and-error. After choosing a model, we then scrutinize the interpretation of the \\(\\beta\\) coefficients."
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#augmentation",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#augmentation",
    "title": "8: Multiple Linear Regression",
    "section": "Augmentation",
    "text": "Augmentation\nWe can attach new columns and calculations using mutate.\n\nbb_df &lt;- bb_df |&gt;\n  mutate(BA = H/AB,               #batting average\n         OBP = (H + BB + HBP)/AB, #on-base percentage\n         SLG = (H + X2B + 2*X3B + 3*HR)/AB, #slugging percentage\n         OPS = OBP + SLG)         #on-base plus slugging\n\n\nStats like runs, hits, walks, and strikeouts are called count statistics. Baseball players tend to accumulate count statistics with more playing time.\nStats like BA, OBP, and SLGare called rate statistics. These baseball statistics are adjusted over playing time.\nThese derived statistics may be better to evaluate individual baseball players (rather than whole teams).\nAside: yes, it may be silly to add together OBP and SLG (i.e. two rate statistics), but baseball writers really like this calculation."
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#using-the-derived-statistics",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#using-the-derived-statistics",
    "title": "8: Multiple Linear Regression",
    "section": "Using the Derived Statistics",
    "text": "Using the Derived Statistics\nWe build a model for different allocations of explanatory variables.\n\nfit_BA  &lt;- lm(R ~ BA,  data = bb_df)\nfit_OBP &lt;- lm(R ~ OBP, data = bb_df)\nfit_SLG &lt;- lm(R ~ SLG, data = bb_df)\nfit_OPS &lt;- lm(R ~ OBP + SLG, data = bb_df)"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#measuring-the-models",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#measuring-the-models",
    "title": "8: Multiple Linear Regression",
    "section": "Measuring the Models",
    "text": "Measuring the Models\nWe use the coefficients of determination to help us rank the models.\n\nsummary(fit_BA)$adj.r.squared\n\n[1] 0.3445441\n\nsummary(fit_OBP)$adj.r.squared\n\n[1] 0.4279833\n\nsummary(fit_SLG)$adj.r.squared\n\n[1] 0.433078\n\nsummary(fit_OPS)$adj.r.squared\n\n[1] 0.4902423"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#picking-the-best-model",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#picking-the-best-model",
    "title": "8: Multiple Linear Regression",
    "section": "Picking the Best Model",
    "text": "Picking the Best Model\n\ngtCode\n\n\n\n\n\n\n\n\n\n\nDerived Baseball Stats Models\n\n\nComparing the coefficients of determination\n\n\nmodels\nr2_vals\n\n\n\n\nfit_BA\n0.3445\n\n\nfit_OBP\n0.4280\n\n\nfit_SLG\n0.4331\n\n\nfit_OPS\n0.4902\n\n\n\nSML 201\n\n\n\n\n\n\n\n\n\n\n\nmod_stats_df2 &lt;- data.frame(\n  models = paste0(\"fit_\", c(\"BA\", \"OBP\", \"SLG\", \"OPS\")),\n  r2_vals = round(c(summary(fit_BA)$adj.r.squared,\n                    summary(fit_OBP)$adj.r.squared,\n                    summary(fit_SLG)$adj.r.squared,\n                    summary(fit_OPS)$adj.r.squared), 4)\n)\n\nmod_stats_df2 |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"SML 201\") |&gt;\n  tab_header(\n    title = \"Derived Baseball Stats Models\",\n    subtitle = \"Comparing the coefficients of determination\"\n  ) |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = oakland_yellow),\n      cell_text(color = oakland_green,\n                weight = \"bold\")\n    ),\n    locations = cells_body(columns = c(models, r2_vals),\n                           rows = r2_vals == max(r2_vals))\n    # finds maximum value programmatically\n  )"
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#before-interaction",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#before-interaction",
    "title": "8: Multiple Linear Regression",
    "section": "Before Interaction",
    "text": "Before Interaction\nFirst, let us try another multiple linear regression model\n\nVariablesCodeInterceptSlopesDetermination\n\n\n\\[\\text{Wins} = \\beta_{0} + \\beta_{1}(\\text{Runs Scored}) + \\beta_{2}(\\text{Runs Allowed})\\]\n\nresponse variable: Wins\nexplanatory variables:\n\nRuns Scored (offense)\nRuns Allowed (defense)\n\n\n\n\n\nlm(W ~ R + RA, data = bb_df)\n\n\nCall:\nlm(formula = W ~ R + RA, data = bb_df)\n\nCoefficients:\n(Intercept)            R           RA  \n   42.50059      0.12530     -0.07692  \n\n\n\n\nIn a hypothetical scenario where a team has zero runs and zero runs allowed,\n\\[\\text{Wins} = 42.5006 + 0.1253(0) - 0.0769(0)\\]\nthe model estimates that the baseball team will win about 43 games in a season.\n\n\nIn regression, we say that we control for other variables by treating other variables as constants.\n\\[\\text{Wins} = 42.5006 + 0.1253(\\text{Runs Scored}) - 0.0769(\\text{Runs Allowed})\\]\n\nHolding runs allowed constant, for every additional run scored, the number of wins increases by about 0.1253.\nHolding runs scored constant, for every additional run allowed, the number of wins decreases by about 0.0769.\n\n\n\nWith our usage of the coefficient of determination\n\nwithout_interaction &lt;- lm(W ~ R + RA, data = bb_df)\n\nsummary(without_interaction)$adj.r.squared\n\n[1] 0.700125\n\n\n\nAccording to the coefficient of determination, this model (with 2 explanatory variables) explains about 70 percent of the variance in wins."
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#with-an-interaction-term",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#with-an-interaction-term",
    "title": "8: Multiple Linear Regression",
    "section": "With an Interaction Term",
    "text": "With an Interaction Term\nNow let us explore an interaction term\n\nVariablesCodeInterceptSlopesDetermination\n\n\n\\[\\begin{array}{rcl}\n\\text{Wins} & = & \\beta_{0} \\\\\n& & + \\beta_{1}(\\text{Runs Scored}) \\\\\n& & + \\beta_{2}(\\text{Runs Allowed}) \\\\\n& & + \\beta_{3}(\\text{Runs Scored})(\\text{Runs Allowed}) \\\\\n\\end{array}\\]\n\nresponse variable: Wins\nexplanatory variables:\n\nRuns Scored\nRuns Allowed\ninteraction bteween Runs Scored and Runs Allowed\n\n\n\n\n\nlm(W ~ R + RA + R:RA, data = bb_df)\n\n\nCall:\nlm(formula = W ~ R + RA + R:RA, data = bb_df)\n\nCoefficients:\n(Intercept)            R           RA         R:RA  \n -8.896e+01    3.082e-01    1.090e-01   -2.555e-04  \n\n\n\n\nIn a hypothetical scenario where a team has zero runs and zero runs allowed,\n\\[\\text{Wins} = -88.96 + 0.3082(0) + 0.1090(0) - 0.0002(0)(0)\\]\nthe model estimates that the baseball team will win about -89 games in a season.\n\n\nTo get a sense of how many runs a MLB team allows in a season, we can use the summary command.\n\nsummary(bb_df$RA)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  448.0   655.2   721.0   726.5   794.0  1103.0 \n\n\n\nStrong Defense\nSuppose that a MLB team has good defensive skills and allows about 650 runs in a season (i.e. around the 20th percentile).\n\\[\\begin{array}{rcl}\n\\text{Wins} & = & -88.96 + 0.3082(\\text{Runs Scored}) + 0.1090(\\text{Runs Allowed}) - 0.0002(\\text{Runs Scored})(\\text{Runs Allowed}) \\\\\n~ & = & -88.96 + 0.3082(\\text{Runs Scored}) + 0.1090(650) - 0.0002(\\text{Runs Scored})(650) \\\\\n  ~ & = & -18.11 + 0.1782(\\text{Runs Scored})\\\\\n\\end{array}\\]\n\nHolding runs allowed constant at 650, for every additional run scored, the number of wins increases by about 0.1782.\n\n\n\nWeak Defense\nSuppose that a MLB team has weak defensive skills and allows about 800 runs in a season (i.e. around the 80th percentile).\n\\[\\begin{array}{rcl}\n\\text{Wins} & = & -88.96 + 0.3082(\\text{Runs Scored}) + 0.1090(\\text{Runs Allowed}) - 0.0002(\\text{Runs Scored})(\\text{Runs Allowed}) \\\\\n~ & = & -88.96 + 0.3082(\\text{Runs Scored}) + 0.1090(800) - 0.0002(\\text{Runs Scored})(800) \\\\\n  ~ & = & -1.76 + 0.1482(\\text{Runs Scored})\\\\\n\\end{array}\\]\n\nHolding runs allowed constant at 800, for every additional run scored, the number of wins increases by about 0.1482.\n\n\n\n\nWith our usage of the coefficient of determination\n\nwith_interaction &lt;- lm(W ~ R + RA + R:RA, data = bb_df)\n\nsummary(without_interaction)$adj.r.squared\n\n[1] 0.700125\n\nsummary(with_interaction)$adj.r.squared\n\n[1] 0.764043\n\n\n\nAccording to the coefficient of determination, this model (with the interaction term) explains about 76 percent of the variance in wins."
  },
  {
    "objectID": "posts/09_multiple_regression/09_multiple_linear.html#milestone-home-run-totals",
    "href": "posts/09_multiple_regression/09_multiple_linear.html#milestone-home-run-totals",
    "title": "8: Multiple Linear Regression",
    "section": "Milestone Home Run Totals",
    "text": "Milestone Home Run Totals\n\nRecordsCodeZ-ScoresSwitchWhat If\n\n\n\n\n\n\n\nRoger Maris\n\n\n\n\n\n\nRoger Maris hit 61 home runs in 1961\nAaron Judge hit 62 home runs in 2022\n\nAmerican League records\n\n\n\n\n\n\n\n\nAaron Judge\n\n\n\n\n\n\n\nLahman::Batting |&gt;\n  filter(yearID %in% c(\"1961\", \"2022\")) |&gt;\n  filter(AB &gt;= 100) |&gt;\n  group_by(yearID) |&gt;\n  summarize(xbar = mean(HR, na.rm = TRUE),\n            s = sd(HR, na.rm = TRUE))\n\n# A tibble: 2 × 3\n  yearID  xbar     s\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   1961  10.8 10.8 \n2   2022  10.6  8.91\n\n\n\n\n\\[z_{M} = \\frac{61 - \\bar{x}_{2022}}{s_{2022}} = \\frac{61 - 10.7615}{10.7928} \\approx 4.6548\\] Roger Maris’ home run record was about 4.6548 standard deviations above the mean in 1961.\n\\[z_{J} = \\frac{62 - \\bar{x}_{2022}}{s_{2022}} = \\frac{62 - 10.5729}{8.9065} \\approx 5.7741\\]\nAaron Judge’s home run record was about 5.7741 standard deviations above the mean in 2022.\n\n\n\\[4.6548 = \\frac{x_{M} - \\bar{x}_{2022}}{s_{2022}} = \\frac{x_{M} - 10.5729}{8.9065} \\Rightarrow x_{M} \\approx 52.0388\\]\n\\[5.7741 = \\frac{x_{J} - \\bar{x}_{1961}}{s_{1961}} = \\frac{x_{J} - 10.7615}{10.7928} \\Rightarrow x_{J} \\approx 73.0802\\]\n\n\n\n\n\n\n\nRoger Maris\n\n\n\n\n\n\nRoger Maris would have hit 52 home runs is 2022\nAaron Judge would have hit 73 home runs in 1961\n\n\n\n\n\n\n\nAaron Judge"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html",
    "href": "posts/10_modeling_cats/10_modeling_categories.html",
    "title": "10: Modeling Categorical Variables",
    "section": "",
    "text": "library(\"janitor\")   #tools for data cleaning\nlibrary(\"tidyverse\") #tools for data wrangling and visualization\n\nprinceton_orange &lt;- \"#E77500\"\nprinceton_black  &lt;- \"#121212\"\nloan_df &lt;- readr::read_csv(\"loan_data_set.csv\") |&gt;\n  janitor::clean_names()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#start",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#start",
    "title": "10: Modeling Categorical Variables",
    "section": "Start",
    "text": "Start\n\n\n\nGoal: Utilize categorical variables in regression models\nObjective: Explore one-hot encoding and start classification\n\n\n\n\n\n\n\nmultiple slopes!"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#data",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#data",
    "title": "10: Modeling Categorical Variables",
    "section": "Data",
    "text": "Data\n\nDescriptionScenarioResponse VariableExplanatory Variables\n\n\n\n\n“Dream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan.”\n\nSource: Kaggle\n\n\n\n\n\n\n\nDream Home Finance\n\n\n\n\n\n\n“Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.”\n\n\nWe will try to predict the loan amount (i.e. numerical variable)\n\nLoan amount (in thousands of dollars)\n\n\n\n\nGender (of primary applicant)\nMarital status (of primary applicant)\nDependents\nEducation\nSelf-employed\nApplicant income (monthly, in dollars)\nCo-applicant income (monthly, in dollars)\nloan amount terms (in months)\nCredit history\nProperty area"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#cleaning",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#cleaning",
    "title": "10: Modeling Categorical Variables",
    "section": "Cleaning",
    "text": "Cleaning\n\nremove rows that have missing values in the response variable (loan_amount)\nconvert dependents to a numerical variable\n\nhere, replace “+” with nothing\n\ncombine “income” columns\n\nensure all dollar amounts are in the same units (thousands of dollars)\n\nconvert credit_history to a factor variable (i.e. categorical)\nretain relevant columns\n\n\nloan_df &lt;- loan_df |&gt;\n  filter(!is.na(loan_amount)) |&gt;\n  mutate(dependents_num = as.numeric(\n    str_replace(dependents, \"\\\\+\", \"\")\n  )) |&gt;\n  mutate(income = applicant_income/1000 + coapplicant_income/1000) |&gt;\n  mutate(credit_history = factor(credit_history)) |&gt;\n  select(loan_amount, income, dependents_num, gender, married, education, self_employed, credit_history, property_area, loan_status)\n\nAfter cleaning the data, we should report the size of the resultant data frame\n\nnrow(loan_df) #number of observations\n\n[1] 592\n\nncol(loan_df) #number of variables\n\n[1] 10\n\n\nand the structure of the data frame.\n\nstr(loan_df, give.attr = FALSE)\n\ntibble [592 × 10] (S3: tbl_df/tbl/data.frame)\n $ loan_amount   : num [1:592] 128 66 120 141 267 95 158 168 349 70 ...\n $ income        : num [1:592] 6.09 3 4.94 6 9.61 ...\n $ dependents_num: num [1:592] 1 0 0 0 2 0 3 2 1 2 ...\n $ gender        : chr [1:592] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ married       : chr [1:592] \"Yes\" \"Yes\" \"Yes\" \"No\" ...\n $ education     : chr [1:592] \"Graduate\" \"Graduate\" \"Not Graduate\" \"Graduate\" ...\n $ self_employed : chr [1:592] \"No\" \"Yes\" \"No\" \"No\" ...\n $ credit_history: Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 2 2 1 2 2 2 ...\n $ property_area : chr [1:592] \"Rural\" \"Urban\" \"Urban\" \"Urban\" ...\n $ loan_status   : chr [1:592] \"N\" \"Y\" \"Y\" \"Y\" ..."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#scenario-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#scenario-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Scenario 1:",
    "text": "Scenario 1:\n\nresponse variable: loan_amount\nexplanatory variables:\n\nincome\ndependents_num"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#build-the-model",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#build-the-model",
    "title": "10: Modeling Categorical Variables",
    "section": "Build the Model",
    "text": "Build the Model\n\nmod1 &lt;- lm(loan_amount ~ income + dependents_num, data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interpretation",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interpretation",
    "title": "10: Modeling Categorical Variables",
    "section": "Interpretation",
    "text": "Interpretation\nSometimes we interpret the slopes to see if the found coefficients make sense in context.\n\nmod1\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num, data = loan_df)\n\nCoefficients:\n   (Intercept)          income  dependents_num  \n        84.518           8.048           6.943  \n\n\n\nHolding dependents constant, for each $1000 increase in monthly income, the loan amount increases by about $8000\n\n\nHolding income constant, for each additional dependent, the loan amount increases by about $7000"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#determination",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#determination",
    "title": "10: Modeling Categorical Variables",
    "section": "Determination",
    "text": "Determination\n\nsummary(mod1)$adj.r.squared\n\n[1] 0.3955349\n\n\n\nFor this baseline model, the coefficient of determination states that we can explain about 40 percent of the variance in loan amount with these two numerical explanatory variables."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot",
    "title": "10: Modeling Categorical Variables",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nloan_df |&gt;\n  filter(!is.na(credit_history)) |&gt;\n  ggplot(aes(x = income, y = loan_amount, color = credit_history)) +\n  geom_point() +\n  geom_smooth(formula = \"y ~ x\",\n              method = \"lm\",\n              se = FALSE) +\n  labs(title = \"Dream Home Finance\",\n       subtitle = \"Interaction Plot\",\n       caption = \"SML 201\",\n       x = \"combined monthly income (thousands)\",\n       y = \"loan amount (thousands)\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-2",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-2",
    "title": "10: Modeling Categorical Variables",
    "section": "Model 2",
    "text": "Model 2\n\nmod2_without_interaction &lt;- lm(loan_amount ~ income + \n                                 dependents_num +\n                                 credit_history,\n                               data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics",
    "title": "10: Modeling Categorical Variables",
    "section": "Model Statistics",
    "text": "Model Statistics\n\nsummary(mod2_without_interaction)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + credit_history, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-372.17  -28.38   -5.71   21.62  356.55 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      82.5113     8.2910   9.952  &lt; 2e-16 ***\nincome            7.6934     0.4386  17.539  &lt; 2e-16 ***\ndependents_num    8.8323     2.8231   3.129  0.00185 ** \ncredit_history1   2.2122     7.9957   0.277  0.78214    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 65.84 on 526 degrees of freedom\n  (62 observations deleted due to missingness)\nMultiple R-squared:  0.3908,    Adjusted R-squared:  0.3873 \nF-statistic: 112.5 on 3 and 526 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n~ & \\approx & 81.7427 + 6.4019X_{1} + 9.3093X_{2} + 1.9206X_{3}\n\\end{array}\\]\nwhere\n\\[X_{1}: \\text{income}, \\quad X_{2}: \\text{number of dependents}\\]\nand\n\\[X_{3} = \\begin{cases} 1, & \\text{passed credit check} \\\\\n0, & \\text{did not pass credit check} \\\\ \\end{cases}\\]\n\nPassing the credit check increases the home loan by about $2000 (??)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interaction-term",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interaction-term",
    "title": "10: Modeling Categorical Variables",
    "section": "Interaction Term",
    "text": "Interaction Term\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n\\end{array}\\]\n\nmod2_with_interaction &lt;- lm(loan_amount ~ income +\n                              dependents_num +\n                              income:credit_history,\n                            data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#refined-interpretation",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#refined-interpretation",
    "title": "10: Modeling Categorical Variables",
    "section": "Refined Interpretation",
    "text": "Refined Interpretation\n\nsummary(mod2_with_interaction)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + income:credit_history, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-327.08  -28.02   -4.70   21.74  346.79 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             81.7427     4.6271  17.666  &lt; 2e-16 ***\nincome                   6.4019     0.6430   9.957  &lt; 2e-16 ***\ndependents_num           9.3093     2.8080   3.315 0.000979 ***\nincome:credit_history1   1.9206     0.7048   2.725 0.006646 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 65.38 on 526 degrees of freedom\n  (62 observations deleted due to missingness)\nMultiple R-squared:  0.3992,    Adjusted R-squared:  0.3957 \nF-statistic: 116.5 on 3 and 526 DF,  p-value: &lt; 2.2e-16\n\n\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n~ & = & 81.7427 + 6.4019X_{1} + 9.3093X_{2} + 1.9206X_{1}X_{3} \\\\\n\\end{array}\\]\n\nFor a family with \\(X_{2} = 0\\) dependents and bad credit history (\\(X_{3} = 0\\))\n\n\\[Y = 81.7427 + 6.4019X_{1}\\]\n\nFor each $1000 increase in monthly income, the loan amount increases by about $6400.\n\n\nFor a family with \\(X_{2} = 0\\) dependents and good credit history (\\(X_{3} = 1\\))\n\n\\[Y = 81.7427 + 6.4019X_{1} + 1.9206X_{1}\\]\n\nFor each $1000 increase in monthly income, the loan amount increases by about $8300."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#determination-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#determination-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Determination",
    "text": "Determination\n\nsummary(mod2_with_interaction)$adj.r.squared\n\n[1] 0.3957492\n\n\n\nFor this model with an interaction term and the two original explanatory variables, the coefficient of determination shows that we can explain about 40 percent of the variance in the loan amount.\n\n\n\n\n\n\n\nHow Complex Should Models Be?\n\n\n\n\n\nDid you catch that?\n\nmod1 had a coefficient of determination of about 0.3955\nmod2_with_interaction had a coefficient of determination of about 0.3957\n\nWith hardly any gains in explaning variance, an analyst might opt to continue with the simpler model (here: mod1) moving forward in an analysis since it eases interpretability"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nloan_df |&gt;\n  filter(!is.na(credit_history)) |&gt;\n  ggplot(aes(x = income, y = loan_amount, color = education)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(formula = \"y ~ x\",\n              method = \"lm\",\n              se = FALSE) +\n  labs(title = \"Dream Home Finance\",\n       subtitle = \"Parallel Slopes?\",\n       caption = \"SML 201\",\n       x = \"combined monthly income (thousands)\",\n       y = \"loan amount (thousands)\") +\n  scale_color_manual(values = c(\"gray\", \"darkgreen\")) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-3",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-3",
    "title": "10: Modeling Categorical Variables",
    "section": "Model 3",
    "text": "Model 3\n\nmod3_without_interaction &lt;- lm(loan_amount ~ income + \n                                 dependents_num +\n                                 education,\n                               data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Model Statistics",
    "text": "Model Statistics\n\nsummary(mod3_without_interaction)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + education, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-388.68  -28.33   -6.10   20.14  402.21 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            89.1379     4.7793  18.651  &lt; 2e-16 ***\nincome                  7.8672     0.4314  18.238  &lt; 2e-16 ***\ndependents_num          7.4332     2.7706   2.683  0.00751 ** \neducationNot Graduate -17.4739     6.8909  -2.536  0.01148 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 66.82 on 575 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.4043,    Adjusted R-squared:  0.4012 \nF-statistic: 130.1 on 3 and 575 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-2",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-2",
    "title": "10: Modeling Categorical Variables",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n~ & \\approx & 89.1379 + 7.8672X_{1} + 7.4332X_{2} - 17.4739X_{3}\n\\end{array}\\]\nwhere\n\\[X_{1}: \\text{income}, \\quad X_{2}: \\text{number of dependents}\\]\nand\n\\[X_{3} = \\begin{cases} 1, & \\text{did not graduate from college} \\\\\n0, & \\text{graduated college} \\\\ \\end{cases}\\]\n\nThose who did not graduate from college had a home loan value that was lower by about $17500."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interaction-term-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interaction-term-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Interaction Term",
    "text": "Interaction Term\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n\\end{array}\\]\n\nmod3_with_interaction &lt;- lm(loan_amount ~ income +\n                              dependents_num +\n                              income:education,\n                            data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#refined-interpretation-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#refined-interpretation-1",
    "title": "10: Modeling Categorical Variables",
    "section": "Refined Interpretation",
    "text": "Refined Interpretation\n\nsummary(mod3_with_interaction)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + income:education, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-395.44  -28.18   -6.58   21.03  401.70 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   87.3028     4.6628  18.723   &lt;2e-16 ***\nincome                         7.9834     0.4278  18.662   &lt;2e-16 ***\ndependents_num                 7.1590     2.7728   2.582   0.0101 *  \nincome:educationNot Graduate  -2.3047     1.2066  -1.910   0.0566 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 66.98 on 575 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.4014,    Adjusted R-squared:  0.3983 \nF-statistic: 128.5 on 3 and 575 DF,  p-value: &lt; 2.2e-16\n\n\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{3} \\\\\n~ & = & 87.3028 + 7.9834X_{1} + 7.1590X_{2} - 2.3047X_{1}X_{3} \\\\\n\\end{array}\\]\n\nFor a family with \\(X_{2} = 2\\) dependents and graduated from college (\\(X_{3} = 0\\))\n\n\\[Y = 87.3028 + 7.9834X_{1} + 14.3180\\]\n\nFor each $1000 increase in monthly income, the loan amount increases by about $8000.\n\n\nFor a family with \\(X_{2} = 2\\) dependents and did not graduate from college (\\(X_{3} = 1\\))\n\n\\[Y = 81.7427 + 7.9834X_{1} + 14.3180 - 2.3047X_{1}\\]\n\nFor each $1000 increase in monthly income, the loan amount increases by about $5600."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#determination-2",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#determination-2",
    "title": "10: Modeling Categorical Variables",
    "section": "Determination",
    "text": "Determination\n\nsummary(mod3_with_interaction)$adj.r.squared\n\n[1] 0.3983014\n\n\n\nFor this model with an interaction term and the two original explanatory variables, the coefficient of determination shows that we can explain about 40 percent of the variance in the loan amount.\n\n\n\n\n\n\n\nReordering Factors\n\n\n\n\n\nYou may have noticed that R tends to output categorical variables in alphabetical order by default (e.g. the bars in a bar chart). If you want to customize the order presented, you would need to employ a factor variable where you can explicitly set the levels.\n\nloan_df &lt;- loan_df |&gt;\n  mutate(education_fac = \n           factor(education,\n                  levels = c(\"Not Graduate\", \"Graduate\")))\n\nNow, the software will treat “Not Graduate” as the baseline and “Graduate” as the augmentation.\n\nmod4 &lt;- lm(loan_amount ~ income + dependents_num + \n             education_fac,\n           data = loan_df)\nsummary(mod4)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + education_fac, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-388.68  -28.33   -6.10   20.14  402.21 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            71.6640     6.7245  10.657  &lt; 2e-16 ***\nincome                  7.8672     0.4314  18.238  &lt; 2e-16 ***\ndependents_num          7.4332     2.7706   2.683  0.00751 ** \neducation_facGraduate  17.4739     6.8909   2.536  0.01148 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 66.82 on 575 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.4043,    Adjusted R-squared:  0.4012 \nF-statistic: 130.1 on 3 and 575 DF,  p-value: &lt; 2.2e-16\n\n\n\nloan_df |&gt;\n  filter(!is.na(education_fac)) |&gt;\n  ggplot(aes(x = income, y = loan_amount, color = education_fac)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(formula = \"y ~ x\",\n              method = \"lm\",\n              se = FALSE) +\n  labs(title = \"Dream Home Finance\",\n       subtitle = \"Parallel Slopes?\",\n       caption = \"SML 201\",\n       x = \"combined monthly income (thousands)\",\n       y = \"loan amount (thousands)\") +\n  scale_color_manual(values = c(\"gray\", \"#E77500\")) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#one-hot-encoding",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#one-hot-encoding",
    "title": "10: Modeling Categorical Variables",
    "section": "One-Hot Encoding",
    "text": "One-Hot Encoding\nSimilar to previous calculations, our software employs dummy variables or one-hot encoding to represent categories as ones and zeroes.\n\nloan_df |&gt;\n  mutate(rural_bool = ifelse(property_area == \"Rural\", 1, 0),\n         semiu_bool = ifelse(property_area == \"Semiurban\", 1, 0),\n         urban_bool = ifelse(property_area == \"Urban\", 1, 0)) |&gt;\n  select(property_area, rural_bool, semiu_bool, urban_bool) |&gt;\n  sample_n(size = 10, replace = FALSE)\n\n# A tibble: 10 × 4\n   property_area rural_bool semiu_bool urban_bool\n   &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Rural                  1          0          0\n 2 Semiurban              0          1          0\n 3 Semiurban              0          1          0\n 4 Semiurban              0          1          0\n 5 Urban                  0          0          1\n 6 Semiurban              0          1          0\n 7 Semiurban              0          1          0\n 8 Semiurban              0          1          0\n 9 Urban                  0          0          1\n10 Urban                  0          0          1\n\n\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + \\beta_{4}X_{4} \\\\\n\\end{array}\\]\nwhere\n\\[X_{1}: \\text{income}, \\quad X_{2}: \\text{number of dependents}\\]\nand\n\\[\\begin{array}{rcl}\n  X_{3} & = & \\begin{cases} 1, \\text{semiurban area} \\\\ 0, \\text{otherwise} \\\\ \\end{cases} \\\\\n  X_{4} & = & \\begin{cases} 1, \\text{urban area} \\\\ 0, \\text{otherwise} \\\\ \\end{cases} \\\\\n\\end{array}\\]"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-5",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-5",
    "title": "10: Modeling Categorical Variables",
    "section": "Model 5",
    "text": "Model 5\n\nmod5 &lt;- lm(loan_amount ~ income + \n             dependents_num +\n             property_area,\n           data = loan_df)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics-2",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#model-statistics-2",
    "title": "10: Modeling Categorical Variables",
    "section": "Model Statistics",
    "text": "Model Statistics\n\nsummary(mod5)\n\n\nCall:\nlm(formula = loan_amount ~ income + dependents_num + property_area, \n    data = loan_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-402.72  -28.36   -7.05   19.80  409.16 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             89.1639     6.1868  14.412   &lt;2e-16 ***\nincome                   8.0575     0.4275  18.849   &lt;2e-16 ***\ndependents_num           6.9669     2.7760   2.510   0.0124 *  \nproperty_areaSemiurban  -3.3175     6.8229  -0.486   0.6270    \nproperty_areaUrban     -10.8084     7.1188  -1.518   0.1295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 67.1 on 574 degrees of freedom\n  (13 observations deleted due to missingness)\nMultiple R-squared:  0.4002,    Adjusted R-squared:  0.396 \nF-statistic: 95.75 on 4 and 574 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-3",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#interpretation-3",
    "title": "10: Modeling Categorical Variables",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\\begin{array}{rcl}\nY & = & \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + \\beta_{4}X_{4} \\\\\n~ & = & 89.1639 + 8.0575X_{1} + 6.9669X_{2} - 3.3175X_{3} - 10.8084X_{4} \\\\\n\\end{array}\\]\nFor a family with one dependent (\\(X_{2} = 1\\)) and a combined monthly income of $5000 (\\(X_{1} = 5\\)),\n\nif they are seeking a home in a rural area (\\(X_{3} = 0, X_{4} = 0\\)), the loan amount is predicted to be about 136 thousand\nif they are seeking a home in a semi-urban area (\\(X_{3} = 1, X_{4} = 0\\)), the loan amount is predicted to be about 133 thousand (i.e. 3 thousand less than the baseline rural scenario)\nif they are seeking a home in an urban area (\\(X_{3} = 0, X_{4} = 1\\)), the loan amount is predicted to be about 126 thousand (i.e. 10 thousand less than the baseline rural scenario)"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#machine-learning",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#machine-learning",
    "title": "10: Modeling Categorical Variables",
    "section": "Machine Learning",
    "text": "Machine Learning\nIf the response variable is …\n\nnumerical \\(\\rightarrow\\) regression task\ncategorical \\(\\rightarrow\\) classification task"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#one-hot-encoding-1",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#one-hot-encoding-1",
    "title": "10: Modeling Categorical Variables",
    "section": "One-Hot Encoding",
    "text": "One-Hot Encoding\n\nloan_df &lt;- loan_df |&gt;\n  mutate(approved = ifelse(loan_status == \"Y\", 1, 0),\n         approved_fac = factor(approved,\n                               levels = c(0,1)))"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot-2",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#scatterplot-2",
    "title": "10: Modeling Categorical Variables",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nloan_df |&gt;\n  ggplot(aes(x = income, y = approved)) +\n  geom_point(aes(color = approved_fac)) +\n  geom_smooth(formula = \"y ~ x\",\n              method = \"lm\",\n              se = FALSE) +\n  labs(title = \"Dream Home Finance\",\n       subtitle = \"Linear Regression?\",\n       caption = \"SML 201\",\n       x = \"combined monthly income (thousands)\",\n       y = \"loan status\") +\n  scale_color_manual(values = c(\"gray\", \"darkgreen\")) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#logistic-function",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#logistic-function",
    "title": "10: Modeling Categorical Variables",
    "section": "Logistic Function",
    "text": "Logistic Function\n\n\n\n\n\nlogistic function\n\n\n\n\n\n\ndomain: \\((-\\infty, \\infty)\\)\nrange: \\((0,1)\\)\none-to-one and invertible"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#logistic-regression",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#logistic-regression",
    "title": "10: Modeling Categorical Variables",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\n# generalized linear model\nmod6 &lt;- glm(approved_fac ~ income,\n            data = loan_df,\n            family = \"binomial\")"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#extended-model",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#extended-model",
    "title": "10: Modeling Categorical Variables",
    "section": "Extended Model",
    "text": "Extended Model\n\n# generalized linear model\nmod7 &lt;- glm(approved_fac ~ income + dependents_num + credit_history +\n              education + property_area + loan_amount,\n            data = loan_df,\n            family = \"binomial\")"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#logistic-fit",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#logistic-fit",
    "title": "10: Modeling Categorical Variables",
    "section": "Logistic Fit",
    "text": "Logistic Fit\n\nloan_df &lt;- loan_df |&gt;\n  mutate(preds = predict(mod7,\n                         data.frame(income = loan_df$income,\n                                    dependents_num = loan_df$dependents_num,\n                                    credit_history = loan_df$credit_history,\n                                    education = loan_df$education,\n                                    property_area = loan_df$property_area,\n                                    loan_amount = loan_df$loan_amount),\n                         type = \"response\"))"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#machine-predictions",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#machine-predictions",
    "title": "10: Modeling Categorical Variables",
    "section": "Machine Predictions",
    "text": "Machine Predictions\nIt appears that this company rejects about 30 percent of loan applications. Let us make a cutoff point at the 30th percentile in the predictions.\n\ncutoff &lt;- quantile(loan_df$preds, 0.30, na.rm = TRUE)\n\nloan_df |&gt;\n  filter(!is.na(preds)) |&gt;\n  ggplot(aes(x = preds)) +\n  geom_histogram(binwidth = 0.05, color = princeton_black, fill = \"white\") +\n  geom_vline(xintercept = cutoff, color = princeton_orange,\n             linetype = 3, linewidth = 4) +\n  labs(title = \"Machine-Made Predictions\",\n       subtitle = \"through logistic regression\",\n       caption = \"SML 201\",\n       x = \"&lt;== reject ... approve ==&gt;\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#validation",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#validation",
    "title": "10: Modeling Categorical Variables",
    "section": "Validation",
    "text": "Validation\n\nloan_df |&gt;\n  filter(!is.na(preds)) |&gt;\n  mutate(pred_class = ifelse(preds &gt; cutoff, 1, 0)) |&gt;\n  janitor::tabyl(approved_fac, pred_class)\n\n approved_fac  0   1\n            0 97  66\n            1 62 305\n\n\n\\[\\text{accuracy} = \\frac{97 + 305}{97 + 66 + 62 + 305} \\approx 0.7585\\]\nSo far, this automated system would classify the loan applications correctly about 76 percent of the time."
  },
  {
    "objectID": "posts/10_modeling_cats/10_modeling_categories.html#prediction",
    "href": "posts/10_modeling_cats/10_modeling_categories.html#prediction",
    "title": "10: Modeling Categorical Variables",
    "section": "Prediction",
    "text": "Prediction\nPicture a Princeton graduate who makes $10k per month, has two dependents, has good credit, and is seeking a $500k loan for a house in an urban area. Our model says …\n\nthis_prediction = predict(mod7,\n                          data.frame(income = 10,\n                                     dependents_num = 2,\n                                     credit_history = \"1\",\n                                     education = \"Graduate\",\n                                     property_area = \"Urban\",\n                                     loan_amount = 500),\n                          type = \"response\")\n\nprint(paste0(\"The computer model says that we should \",\n             ifelse(this_prediction &gt; cutoff, \"approve\", \"reject\"),\n             \" this application.\"))\n\n[1] \"The computer model says that we should approve this application.\"\n\n\n\n\n\n\n\n\nWhat if the categorical response has more than two levels?\n\n\n\n\n\nIn later machine learning classes, you will encounter\n\nsupport vector machines\nrandom forests"
  }
]