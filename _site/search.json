[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SML 201 (Fall 2024)",
    "section": "",
    "text": "6: Geospatial\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n5: Networks\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n4: Categories\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n3: Variance\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n2: Centrality\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n1: Introductions\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html",
    "href": "posts/01_introduction/01_introduction.html",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce data science\nObjective: Explore a data set with bar graphs and facets\n\n\n\n\n\nImage credit: Steven Geringer"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#start",
    "href": "posts/01_introduction/01_introduction.html#start",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce data science\nObjective: Explore a data set with bar graphs and facets\n\n\n\n\n\nImage credit: Steven Geringer"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#sml-201-introduction-to-data-science",
    "href": "posts/01_introduction/01_introduction.html#sml-201-introduction-to-data-science",
    "title": "1: Introductions",
    "section": "",
    "text": "Fall 2024\nTuesdays and Thursdays\n\n11 AM to 1220 PM: Lewis Library 120\n130 PM to 250 PM: Lewis Library 120\n\nLecturer: Derek\n\nI go by “Derek” or “teacher”\n\n\n\n\n\n\n\n\nCourse Description\n\n\n\n\n\nIntroduction to Data Science provides a practical introduction to the burgeoning field of data science. The course introduces students to the essential tools for conducting data-driven research, including the fundamentals of programming techniques and the essentials of statistics. Students will work with real-world datasets from various domains; write computer code to manipulate, explore, and analyze data; use basic techniques from statistics and machine learning to analyze data; learn to draw conclusions using sound statistical reasoning; and produce scientific reports. No prior knowledge of programming or statistics is required."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#lecturer",
    "href": "posts/01_introduction/01_introduction.html#lecturer",
    "title": "1: Introductions",
    "section": "Lecturer",
    "text": "Lecturer"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "href": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "title": "1: Introductions",
    "section": "Current Research in Pedagogy",
    "text": "Current Research in Pedagogy\n\n\n\n\n\nactive learning\ncomputer programming\nflipped classrooms"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#identity-statement",
    "href": "posts/01_introduction/01_introduction.html#identity-statement",
    "title": "1: Introductions",
    "section": "Identity Statement",
    "text": "Identity Statement\n\n\n\nOriginally from Los Angeles\nMath: easier to understand through graphs\nComputer Programming: years of experience with R, Python, MATLAB, PHP, HTML, etc.\nLearning: drawn to puzzles and manageable tasks\nPersonality: shy, introvert"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#textbooks",
    "href": "posts/01_introduction/01_introduction.html#textbooks",
    "title": "1: Introductions",
    "section": "Textbooks",
    "text": "Textbooks\n\n\n\n\n\nR for Data Science\n\n\n\nThis course will loosely follow\n\nR for Data Science by Hadley Wickham, Mine Cetinkaya-Rundel, and Garrett Grolemund (online textbook)\nStatistical Inference via Data Science by Chester Ismay and Albert Y Kim (online textbook)\n\n\n\n\n\nModern Dive"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#additional-reading",
    "href": "posts/01_introduction/01_introduction.html#additional-reading",
    "title": "1: Introductions",
    "section": "Additional Reading",
    "text": "Additional Reading\nThe following list of books is optional for student studies, but the instructor may use some materials to add depth and interest to the course.\n\n\n\n\n\n\nAdditional Reading\n\n\n\n\n\n\nThe Seven Pillars of Statistical Wisdom by Stephen M Stigler provides a wonderful overview of the history of statistics and the field’s major developments.\nStatistical Rethinking by Richard McElreath is the premier body of work in the field of Bayesian analysis. This resource is great for people who want to build a strong foundation in philosophy and theory in this branch of mathematics.\nTeaching Statistics by Andrew Gelman and Deborah Nolan features a variety of classroom activities that engage audiences at prestigious universities into learning statistical concepts.\nBernoulli’s Fallacy by Aubrey Clayton is a scathing review of the history of statistics and posits that the foundations of the field are flawed."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "href": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "title": "1: Introductions",
    "section": "Cooperative Classroom",
    "text": "Cooperative Classroom\nLearning in a cooperative environment should be stimulating, demanding, and fair. Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations. Below are my expectations for students in this class. This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words. If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.\n\nStudents are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.\nWhen working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others. Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.\nStudents should explore data, make observations, and develop inferences as part of a group. If you use material from published sources, you must provide appropriate attribution.\n\n\n\n(Students will be asked to acknowledge this document in an online form.)\nThis document has been adapted from Scientific Teaching by Jo Handelsman, Sarah Miller, and Christine Pfund\n\n\n\n\nScientific Teaching"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#pep-talk",
    "href": "posts/01_introduction/01_introduction.html#pep-talk",
    "title": "1: Introductions",
    "section": "Pep Talk",
    "text": "Pep Talk\nLearning R can be difficult at first—it is like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you will be using like ggplot2—made this wise observation:\n\n\n\n\n\n\nWisdom from Hadley Wickham\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nIf you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions … e-mail [Derek], etc. I promise you can do this.\n—Andrew Heiss, Georgia State University"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "href": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "title": "1: Introductions",
    "section": "Inclusion Statement",
    "text": "Inclusion Statement\nI value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment)."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#concern-for-bee-populations",
    "href": "posts/01_introduction/01_introduction.html#concern-for-bee-populations",
    "title": "1: Introductions",
    "section": "Concern for Bee Populations",
    "text": "Concern for Bee Populations\n\n\n\n\n\nTime\n\n\n\n\n\n\n\n\nABC"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#finding-data",
    "href": "posts/01_introduction/01_introduction.html#finding-data",
    "title": "1: Introductions",
    "section": "Finding Data",
    "text": "Finding Data\n\nUS Dept of Agriculture\nNational Agricultural Statistics Service\n\n\nLoading DataR Code\n\n\n\n\n# A tibble: 4 × 7\n  Program  Year   Value `Geo Level` State    Commodity `Data Item`              \n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                    \n1 SURVEY   2015 2849500 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n2 SURVEY   2016 2801470 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n3 SURVEY   2017 2694150 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n4 SURVEY   2018 2665880 NATIONAL    US TOTAL HONEY     HONEY, BEE COLONIES - IN…\n\n\n\n\n\nbee_df &lt;- readr::read_csv(\"bee_population.csv\")\nhead(bee_df)"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#presenting-narrative",
    "href": "posts/01_introduction/01_introduction.html#presenting-narrative",
    "title": "1: Introductions",
    "section": "Presenting Narrative",
    "text": "Presenting Narrative"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#why-r",
    "href": "posts/01_introduction/01_introduction.html#why-r",
    "title": "1: Introductions",
    "section": "Why R?",
    "text": "Why R?\n\n\n\n\n\nR\n\n\n\n\n\n\nmatches data science concepts well\nlanguage made for statistics and probability calculations\nsoftware compatibility\neasier to learn\neasier to teach\ngaining popularity in areas such as consulting, finance, epidemiology, genomics, pharmaceuticals, etc."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#r-vs-python",
    "href": "posts/01_introduction/01_introduction.html#r-vs-python",
    "title": "1: Introductions",
    "section": "R vs Python",
    "text": "R vs Python\n\ntablegt code\n\n\n\n\n\n\n\n\n\n\nData Science Programming Languages\n\n\nWhich one is better?\n\n\nR\nPython\n\n\n\n\nData Science\nMachine Learning\n\n\nDashboards\nSoftware Development\n\n\nInteractvity\nObject-Oriented Programming\n\n\nVisualization\nBig Data\n\n\nDebugging\nFaster\n\n\n\nsource: Derek's opinion\n\n\n\n\n\n\n\n\n\n\n\nlanguages_df &lt;- data.frame(\n  R = c(\"Data Science\", \"Dashboards\", \"Interactvity\", \"Visualization\", \"Debugging\"),\n  Python = c(\"Machine Learning\", \"Software Development\", \"Object-Oriented Programming\", \"Big Data\", \"Faster\")\n)\n\nlanguages_df |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"source: Derek's opinion\") |&gt;\n  tab_header(\n    title = \"Data Science Programming Languages\",\n    subtitle = \"Which one is better?\"\n  ) |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = \"#ffc100\")\n    ),\n    locations = cells_body(columns = R)\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = \"#d0cef3\")\n    ),\n    locations = cells_body(columns = Python)\n  )"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#critique",
    "href": "posts/01_introduction/01_introduction.html#critique",
    "title": "1: Introductions",
    "section": "Critique",
    "text": "Critique\n\n\nCritique this graph. What comments do you have about it?"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#continuing-the-narrative",
    "href": "posts/01_introduction/01_introduction.html#continuing-the-narrative",
    "title": "1: Introductions",
    "section": "Continuing the Narrative",
    "text": "Continuing the Narrative\n\nMore DataCodeFacetsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbee_totals_df |&gt;\n  mutate(num_colonies = Value / 1e6) |&gt;\n  ggplot(aes(x = factor(Year), y = num_colonies)) +\n  geom_bar(color = \"#121212\", fill = \"#E77500\",\n           stat = \"identity\") +\n  labs(title = \"US Bee Population\",\n       subtitle = \"Survey of bee colonies\",\n       caption = \"source: USDA NASS\",\n       x = \"year\",\n       y = \"bee colonies (in millions)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbee_states_df |&gt;\n  # filter(Year &gt;= 2015 & Year &lt;= 2018) |&gt;\n  filter(State %in% c(\"NEW JERSEY\", \"CALIFORNIA\")) |&gt;\n  ggplot(aes(x = factor(Year), y = Value)) +\n  facet_wrap(vars(State), ncol = 1, scales = \"free_y\") +\n  geom_bar(color = \"#121212\", fill = \"#E77500\",\n           stat = \"identity\") +\n  labs(title = \"US Bee Population\",\n       subtitle = \"Selection of States\",\n       caption = \"source: USDA NASS\",\n       x = \"year\",\n       y = \"bee colonies\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#epilogue",
    "href": "posts/01_introduction/01_introduction.html#epilogue",
    "title": "1: Introductions",
    "section": "Epilogue",
    "text": "Epilogue\n * inspiration: Wait, does America suddenly have a record number of bees? by Andrew Van Dam"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html",
    "href": "posts/02_centrality/02_Centrality.html",
    "title": "2: Centrality",
    "section": "",
    "text": "Goal: Summarize data by centrality\nObjective: Compute mean, median, and mode\n\n\n\n\n\n\n\nThe limit does not exist!\n\n\n\n\n\n\n\n\ncreate a folder on your computer desktop called “SML 201”\n\nlater: place all code scripts and data sets in this folder\n\nopen RStudio and create a new Quarto document\n\nFile –&gt; New File –&gt; Quarto Document ...\nsave the file into your SML 201 folder\n\nTo run a line of code, the keyboard short cut is\n\nWindows: CTRL + ENTER\nMac: CMD + ENTER"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#start",
    "href": "posts/02_centrality/02_Centrality.html#start",
    "title": "2: Centrality",
    "section": "",
    "text": "Goal: Summarize data by centrality\nObjective: Compute mean, median, and mode\n\n\n\n\n\n\n\nThe limit does not exist!"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#advice",
    "href": "posts/02_centrality/02_Centrality.html#advice",
    "title": "2: Centrality",
    "section": "",
    "text": "create a folder on your computer desktop called “SML 201”\n\nlater: place all code scripts and data sets in this folder\n\nopen RStudio and create a new Quarto document\n\nFile –&gt; New File –&gt; Quarto Document ...\nsave the file into your SML 201 folder\n\nTo run a line of code, the keyboard short cut is\n\nWindows: CTRL + ENTER\nMac: CMD + ENTER"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#definition",
    "href": "posts/02_centrality/02_Centrality.html#definition",
    "title": "2: Centrality",
    "section": "Definition",
    "text": "Definition\nFor a list of data\n\\[\\{a_{1}, a_{2}, ..., a_{n}\\}\\]\nthe mean or average of the data is defined as\n\\[\\bar{x} = \\displaystyle\\frac{1}{n}\\sum_{i = 1}^{n} a_{i}\\] where “x bar” denotes a sample mean"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#in-r",
    "href": "posts/02_centrality/02_Centrality.html#in-r",
    "title": "2: Centrality",
    "section": "In R",
    "text": "In R\nRun each of these lines of code, and describe the code\n\nsome_data &lt;- c(32, 45, 16, 78, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#missing-data",
    "href": "posts/02_centrality/02_Centrality.html#missing-data",
    "title": "2: Centrality",
    "section": "Missing Data",
    "text": "Missing Data\nRun each of these lines of code, and describe the code\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\nsum(some_data)\nlength(some_data)\nsum(some_data) / length(some_data)\nmean(some_data)\nmean(some_data, na.rm = TRUE)"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#loading-the-data",
    "href": "posts/02_centrality/02_Centrality.html#loading-the-data",
    "title": "2: Centrality",
    "section": "Loading the Data",
    "text": "Loading the Data\nI have supplied a couple of data sets to a GitHub repository to ease the loading of data for classroom work.\n\nolympic_df1 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv\")\nolympic_df2 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#summary-statistics",
    "href": "posts/02_centrality/02_Centrality.html#summary-statistics",
    "title": "2: Centrality",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nRun each of these lines of code, and describe the code\n\nmean(olympic_df1$weight)\nmean(olympic_df1$weight, na.rm = TRUE)\n\n\n\n\n\n\n\nThe fix\n\n\n\n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#filter",
    "href": "posts/02_centrality/02_Centrality.html#filter",
    "title": "2: Centrality",
    "section": "Filter",
    "text": "Filter\nFor this demonstration, let us focus on the athletes from Turkey.\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#dotplot",
    "href": "posts/02_centrality/02_Centrality.html#dotplot",
    "title": "2: Centrality",
    "section": "Dotplot",
    "text": "Dotplot\nEarly in an introductory statistics course, a dotplot is useful for visualizing integer data.\n\nmean_1 &lt;- mean(Turkey_df1$age, na.rm = TRUE)\n\nTurkey_df1 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#the-outlier",
    "href": "posts/02_centrality/02_Centrality.html#the-outlier",
    "title": "2: Centrality",
    "section": "The Outlier",
    "text": "The Outlier\n\n\n\n\n\nYusuf Dikec\n\n\n\nimage source: News 18\n\n\n\n\n\nYusuf Dikec\nTurkish sharpshooter\n\nsilver medalist (2024 Olympics)\n10m air pistol mixed team\n\nAge: 51"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#filtered-again",
    "href": "posts/02_centrality/02_Centrality.html#filtered-again",
    "title": "2: Centrality",
    "section": "Filtered Again",
    "text": "Filtered Again\n\nTurkey_df2 &lt;- olympic_df2 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#dotplot-revisited",
    "href": "posts/02_centrality/02_Centrality.html#dotplot-revisited",
    "title": "2: Centrality",
    "section": "Dotplot Revisited",
    "text": "Dotplot Revisited\nEarly in an introductory statistics course, a dotplot is useful for visualizing integer data.\n\nmean_1 &lt;- mean(Turkey_df1$age, na.rm = TRUE)\nmean_2 &lt;- mean(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = mean_1, color = \"blue\", linewidth = 3) +\n  geom_vline(xintercept = mean_2, color = \"blue\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"mean in blue\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#medians",
    "href": "posts/02_centrality/02_Centrality.html#medians",
    "title": "2: Centrality",
    "section": "Medians",
    "text": "Medians\n\nmedian_1 &lt;- median(Turkey_df1$age, na.rm = TRUE)\nmedian_2 &lt;- median(Turkey_df2$age, na.rm = TRUE)\n\nTurkey_df2 |&gt;\n  ggplot(aes(x = age)) +\n  geom_dotplot() +\n  geom_vline(xintercept = median_1, color = \"red\", linewidth = 3) +\n  geom_vline(xintercept = median_2, color = \"red\", linewidth = 3) +\n  labs(title = \"Ages of Turkish Athletics\",\n       subtitle = \"median in red\",\n       caption = \"SML 201\")"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#difference-in-means",
    "href": "posts/02_centrality/02_Centrality.html#difference-in-means",
    "title": "2: Centrality",
    "section": "Difference in Means",
    "text": "Difference in Means\n\nmean_1 - mean_2\n\n[1] -1.92449\n\nabs(mean_1 - mean_2)\n\n[1] 1.92449"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#difference-in-medians",
    "href": "posts/02_centrality/02_Centrality.html#difference-in-medians",
    "title": "2: Centrality",
    "section": "Difference in Medians",
    "text": "Difference in Medians\n\nmedian_1 - median_2\n\n[1] 0\n\nabs(median_1 - median_2)\n\n[1] 0"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#punchline",
    "href": "posts/02_centrality/02_Centrality.html#punchline",
    "title": "2: Centrality",
    "section": "Punchline",
    "text": "Punchline\n\n\n\nInvincible\n\n\n\nThe median is robust against outliers!\nimage source: Know Your Meme"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#why-the-mean",
    "href": "posts/02_centrality/02_Centrality.html#why-the-mean",
    "title": "2: Centrality",
    "section": "Why the mean?",
    "text": "Why the mean?\nLater, we use the mean for:\n\nnormal distributions (“bell curves”)\nlinear regression goes through center of mass\nestimators and other statistical theory"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#which-do-we-use",
    "href": "posts/02_centrality/02_Centrality.html#which-do-we-use",
    "title": "2: Centrality",
    "section": "Which do we use?",
    "text": "Which do we use?\n\n\n\nWhen feasible, compute and report both the mean and median.\n\n\n\n\n\n\n\nWhy not both?\n\n\n\nimage source: Know Your Meme"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#time-series",
    "href": "posts/02_centrality/02_Centrality.html#time-series",
    "title": "2: Centrality",
    "section": "Time Series",
    "text": "Time Series\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  ggplot(aes(x = date, y = n)) +\n  geom_line() +\n  labs(title = \"Parking Tickets in Philadelphia\",\n       subtitle = \"Street Sweeping Violations (2017)\",\n       caption = \"Source: Open Data Philly\",\n       y = \"number of tickets\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#moving-average",
    "href": "posts/02_centrality/02_Centrality.html#moving-average",
    "title": "2: Centrality",
    "section": "Moving Average",
    "text": "Moving Average\n\nConcept357911Code\n\n\nA rolling mean or moving average compues the mean across a group of \\(L\\) (lag) consecutive data points in a time series and slides the “window”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  mutate(roll_mean = zoo::rollapply(\n    n, 3, mean, align = 'left', fill = NA\n  )) |&gt;\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_mean),\n            color = \"blue\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling mean in blue (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/02_centrality/02_Centrality.html#rolling-median",
    "href": "posts/02_centrality/02_Centrality.html#rolling-median",
    "title": "2: Centrality",
    "section": "Rolling Median",
    "text": "Rolling Median\n\n357911Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickets_df |&gt;\n  mutate(roll_median = zoo::rollapply(\n    n, 3, median, align = 'left', fill = NA\n  )) |&gt;\n    ggplot() +\n    geom_point(aes(x = date, y = n),\n               color = \"black\") +\n  geom_line(aes(x = date, y = roll_median),\n            color = \"red\") +\n    labs(title = \"Parking Tickets in Philadelphia\",\n         subtitle = \"Rolling median in red (n = 3 day window)\",\n         caption = \"Source: Open Data Philly\",\n         y = \"number of tickets\") +\n    theme_minimal()"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html",
    "href": "posts/03_variance/03_Variance.html",
    "title": "3: Variance",
    "section": "",
    "text": "Goal: Introduce the concept of variance\nObjective: Compute range, variance, and standard deviation\n\n\n\n\n\n\n\nSpread!"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#start",
    "href": "posts/03_variance/03_Variance.html#start",
    "title": "3: Variance",
    "section": "",
    "text": "Goal: Introduce the concept of variance\nObjective: Compute range, variance, and standard deviation\n\n\n\n\n\n\n\nSpread!"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#centrality",
    "href": "posts/03_variance/03_Variance.html#centrality",
    "title": "3: Variance",
    "section": "Centrality",
    "text": "Centrality\nRecall that we can compute means and medians.\n\nmean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#visualization",
    "href": "posts/03_variance/03_Variance.html#visualization",
    "title": "3: Variance",
    "section": "Visualization",
    "text": "Visualization\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimple_df &lt;- data.frame(A,B)\ntitle_string &lt;- \"Compare and Contrast: &lt;span style='color:blue'&gt;Set A&lt;/span&gt; versus &lt;span style='color:red'&gt;Set B&lt;/span&gt;\"\n\nsimple_df |&gt;\n  ggplot() +\n  geom_point(aes(x = A, y = 1), color = \"blue\", size = 10) +\n  geom_point(aes(x = B, y = 2), color = \"red\", size = 10) +\n  labs(title = title_string,\n       subtitle = \"What is alike?  What is different?\",\n       caption = \"SML 201\",\n       x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),\n        plot.title = element_markdown(face = \"bold\", hjust = 0.5,size = 20),\n        plot.subtitle = element_markdown(hjust = 0.5,size = 15)) +\n  ylim(0,3)"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#aside-range",
    "href": "posts/03_variance/03_Variance.html#aside-range",
    "title": "3: Variance",
    "section": "Aside: Range",
    "text": "Aside: Range\nTo describe variance, an early draft was the range\n\\[\\text{range}(x) = \\text{max}(x) - \\text{min}(x)\\]\n\nhighly affected by outliers\nuses only two data points\n\n\n# range in R computes min and max values\nrange(A)\n\n[1] -3  3\n\nrange(B)\n\n[1] -9  9\n\n# range in statistics\ndiff(range(A))\n\n[1] 6\n\ndiff(range(B))\n\n[1] 18"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#sample-mean",
    "href": "posts/03_variance/03_Variance.html#sample-mean",
    "title": "3: Variance",
    "section": "Sample Mean",
    "text": "Sample Mean\nRecall that we compute the sample mean of the data as\n\\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}\\]\n\nH &lt;- c(75,76,63,62,58)\nxbar &lt;- mean(H)"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#deviations",
    "href": "posts/03_variance/03_Variance.html#deviations",
    "title": "3: Variance",
    "section": "Deviations",
    "text": "Deviations\nNext, we can compute deviations from the mean\n\ndeviations &lt;- H - xbar\ndeviations\n\n[1]  8.2  9.2 -3.8 -4.8 -8.8"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#squared-deviations",
    "href": "posts/03_variance/03_Variance.html#squared-deviations",
    "title": "3: Variance",
    "section": "Squared Deviations",
    "text": "Squared Deviations\nWe don’t need negative signs in this calculations. One way around this is to square the deviations.\n\nsq_deviations &lt;- deviations^2\nsq_deviations\n\n[1] 67.24 84.64 14.44 23.04 77.44"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#tabulation",
    "href": "posts/03_variance/03_Variance.html#tabulation",
    "title": "3: Variance",
    "section": "Tabulation",
    "text": "Tabulation\nSo far we have\n\nTableCode\n\n\n\n\n\n\n\n\n\n\nNathan's Hot Dog Eating Contest\n\n\nRecent winning amounts\n\n\nhot_dogs\nxbar\ndeviations\nsq_deviations\n\n\n\n\n75\n66.8\n8.2\n67.24\n\n\n76\n66.8\n9.2\n84.64\n\n\n63\n66.8\n-3.8\n14.44\n\n\n62\n66.8\n-4.8\n23.04\n\n\n58\n66.8\n-8.8\n77.44\n\n\n\nMen's competition\n\n\n\n\n\n\n\n\n\n\n\nhot_dog_data &lt;- data.frame(hot_dogs = c(75,76,63,62,58))\nhot_dog_data |&gt;\n  mutate(xbar = mean(hot_dogs, na.rm = TRUE),\n         deviations = hot_dogs - xbar,\n         sq_deviations = deviations^2) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"Men's competition\") |&gt;\n  tab_header(\n    title = \"Nathan's Hot Dog Eating Contest\",\n    subtitle = \"Recent winning amounts\") |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  )"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#summarizing",
    "href": "posts/03_variance/03_Variance.html#summarizing",
    "title": "3: Variance",
    "section": "Summarizing",
    "text": "Summarizing\nLike before, we want to summarize a list of numbers.\n\\[s^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2} = \\frac{266.8}{4} = 66.7\\]\nAt this point, the calculation has produced a sample variance\n\nWhy “n-1”? See later session about “Estimators”\nBut what are the units?"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#dimensional-analysis",
    "href": "posts/03_variance/03_Variance.html#dimensional-analysis",
    "title": "3: Variance",
    "section": "Dimensional Analysis",
    "text": "Dimensional Analysis\n\nTableCodeWhat?\n\n\n\n\n\n\n\n\n\n\nNathan's Hot Dog Eating Contest\n\n\nRecent winning amounts\n\n\nhot_dogs\nxbar\ndeviations\nsq_deviations\n\n\n\n\n75\n66.8\n8.2\n67.24 (hot dogs)^2\n\n\n76\n66.8\n9.2\n84.64 (hot dogs)^2\n\n\n63\n66.8\n-3.8\n14.44 (hot dogs)^2\n\n\n62\n66.8\n-4.8\n23.04 (hot dogs)^2\n\n\n58\n66.8\n-8.8\n77.44 (hot dogs)^2\n\n\n\nMen's competition\n\n\n\n\n\n\n\n\n\n\n\nhot_dog_data &lt;- data.frame(hot_dogs = c(75,76,63,62,58))\nhot_dog_data |&gt;\n  mutate(xbar = mean(hot_dogs, na.rm = TRUE),\n         deviations = hot_dogs - xbar,\n         sq_deviations = paste(round(deviations^2,2), \n                               \"(hot dogs)^2\")) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\") |&gt;\n  tab_footnote(footnote = \"Men's competition\") |&gt;\n  tab_header(\n    title = \"Nathan's Hot Dog Eating Contest\",\n    subtitle = \"Recent winning amounts\") |&gt;\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_column_labels()\n  ) |&gt;\n  tab_style(\n    style = cell_text(color = \"red\"),\n    locations = cells_body(columns = sq_deviations)\n  )\n\n\n\nThe sample variance is\n\\[s^{2} = 66.7 \\,(\\text{hot dogs})^{2}\\]\n\n\n\nsquare hot dogs?\n\n\n\nimage created with Canva AI"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#rectify",
    "href": "posts/03_variance/03_Variance.html#rectify",
    "title": "3: Variance",
    "section": "Rectify",
    "text": "Rectify\nIf we need to use these results in subsequent calculations, we can fix the units by taking the square root of the sample variance. This yields the sample standard deviation\n\\[s = \\sqrt{66.7} \\approx 8.1670 \\text{ hot dogs}\\]"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#sse",
    "href": "posts/03_variance/03_Variance.html#sse",
    "title": "3: Variance",
    "section": "SSE",
    "text": "SSE\nFor the sum of squared errors, what value of \\(c\\) will minimize the error?\n\\[\\text{SSE} = \\sum_{i=1}^{n} (x_{i} - c)^{2}, \\quad H = \\{75,76,63,62,58\\}\\]\n\ncvals &lt;- seq(58, 76)\nSSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SSE[i] &lt;- sum((H - cvals[i])^{2})\n}\nmin(SSE)\n\n[1] 267\n\ncvals[which.min(SSE)]\n\n[1] 67\n\n\n\ncvals &lt;- seq(58, 76, by = 0.1)\nSSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SSE[i] &lt;- sum((H - cvals[i])^{2})\n}\nmin(SSE)\n\n[1] 266.8\n\ncvals[which.min(SSE)]\n\n[1] 66.8\n\nmean(H)\n\n[1] 66.8\n\n\nClaim: The sample mean minimizes the sum of squared errors.\n\n\n\n\n\n\n(optional) Calculus proof\n\n\n\n\n\nFor a non-constant data set \\(\\{x_{i}\\}_{i=1}^{n}\\), and for the sum of squared errors\n\\[S(c) = \\sum_{i=1}^{n} (x_{i} - c)^{2}\\]\nwe can set the derivative equal to zero\n\\[\\begin{array}{rcl}\n  0 & = & \\frac{dS}{dc} \\\\\n  0 & = & \\frac{d}{dc} \\sum_{i=1}^{n} (x_{i} - c)^{2} \\\\\n  0 & = & \\sum_{i=1}^{n} \\frac{d}{dc} (x_{i} - c)^{2} \\\\\n  0 & = & \\sum_{i=1}^{n} 2(x_{i} - c) \\\\\n  0 & = &  2\\sum_{i=1}^{n} x_{i} - 2nc \\\\\n  0 & = &  \\sum_{i=1}^{n} x_{i} - nc \\\\\n  nc & = &  \\sum_{i=1}^{n} x_{i} \\\\\n  c & = & \\frac{1}{n}\\sum_{i=1}^{n} x_{i} \\\\\n\\end{array}\\]\nWe recognize that the right-hand side is the sample mean. Since the function was a concave up parabola, we know that this critical point is a global minimum."
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#absolute-value",
    "href": "posts/03_variance/03_Variance.html#absolute-value",
    "title": "3: Variance",
    "section": "Absolute Value",
    "text": "Absolute Value\nWhat if we had used the absolute value instead? We can use a similar argument on the sum of absolute errors.\n\ncvals &lt;- seq(58, 76, by = 0.1)\nSE &lt;- rep(NA, length(cvals))\nfor(i in 1:length(cvals)){\n  SE[i] &lt;- sum(abs(H - cvals[i]))\n}\nmin(SE)\n\n[1] 31\n\ncvals[which.min(SE)]\n\n[1] 63\n\nmedian(H)\n\n[1] 63\n\n\nClaim: The sample median minimizes the sum of absolute errors.\n\\[SE(c) = \\sum_{i=1}^{n} |x_{i} - c|\\]\n\n\n\n\n\n\n(optional) Outline of proof\n\n\n\n\n\n\nargue that the summation is smallest when one of terms is zero\ninterpolate for the case when the number of observations is even"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#data-dow-jones-industrial-average",
    "href": "posts/03_variance/03_Variance.html#data-dow-jones-industrial-average",
    "title": "3: Variance",
    "section": "Data: Dow Jones Industrial Average",
    "text": "Data: Dow Jones Industrial Average\n\n\n\n30 popular stocks\nYear to date\n\nJan 2, 2024\nSept 6, 2024\n\nsource: Yahoo Finance\n\n\n\n\n\ndow_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/03_variance/DOW30.csv\")"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#exploration",
    "href": "posts/03_variance/03_Variance.html#exploration",
    "title": "3: Variance",
    "section": "Exploration",
    "text": "Exploration\n\nhead(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 AAPL   2024-01-02       187.       188.      184.        186. 82488700\n2 AAPL   2024-01-03       184.       186.      183.        184. 58414500\n3 AAPL   2024-01-04       182.       183.      181.        182. 71983600\n4 AAPL   2024-01-05       182.       183.      180.        181. 62303300\n5 AAPL   2024-01-08       182.       186.      182.        186. 59144500\n6 AAPL   2024-01-09       184.       185.      183.        185. 42841800\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\nstr(dow_df, give.attr = FALSE)\n\nspc_tbl_ [5,160 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ticker                : chr [1:5160] \"AAPL\" \"AAPL\" \"AAPL\" \"AAPL\" ...\n $ ref_date              : Date[1:5160], format: \"2024-01-02\" \"2024-01-03\" ...\n $ price_open            : num [1:5160] 187 184 182 182 182 ...\n $ price_high            : num [1:5160] 188 186 183 183 186 ...\n $ price_low             : num [1:5160] 184 183 181 180 182 ...\n $ price_close           : num [1:5160] 186 184 182 181 186 ...\n $ volume                : num [1:5160] 82488700 58414500 71983600 62303300 59144500 ...\n $ price_adjusted        : num [1:5160] 185 184 181 180 185 ...\n $ ret_adjusted_prices   : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ ret_closing_prices    : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ cumret_adjusted_prices: num [1:5160] 1 0.993 0.98 0.976 1 ...\n\n\n\ncolnames(dow_df)\n\n [1] \"ticker\"                 \"ref_date\"               \"price_open\"            \n [4] \"price_high\"             \"price_low\"              \"price_close\"           \n [7] \"volume\"                 \"price_adjusted\"         \"ret_adjusted_prices\"   \n[10] \"ret_closing_prices\"     \"cumret_adjusted_prices\""
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#which-stocks",
    "href": "posts/03_variance/03_Variance.html#which-stocks",
    "title": "3: Variance",
    "section": "Which Stocks?",
    "text": "Which Stocks?\nThe table command tallys the observations in a categorical variable.\n\ntable(dow_df$ticker)\n\n\nAAPL AMGN AMZN  AXP   BA  CAT  CRM CSCO  CVX  DIS  DOW   GS   HD  HON  IBM INTC \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172  172  172 \n JNJ  JPM   KO  MCD  MMM  MRK MSFT  NKE   PG  TRV  UNH    V   VZ  WMT \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#histograms",
    "href": "posts/03_variance/03_Variance.html#histograms",
    "title": "3: Variance",
    "section": "Histograms",
    "text": "Histograms\n\ndow_df |&gt;\n  filter(ticker == \"VZ\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Verizon stock\",\n       subtitle = \"2024 YTD\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndow_df |&gt;\n  filter(ticker == \"GS\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Goldman Sachs stock\",\n       subtitle = \"2024 YTD\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#application-1",
    "href": "posts/03_variance/03_Variance.html#application-1",
    "title": "3: Variance",
    "section": "Application 1",
    "text": "Application 1\nWhich stocks have had the highest average price_close this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(avg_price = mean(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, avg_price) |&gt;\n  distinct() |&gt;\n  arrange(desc(avg_price))\n\n# A tibble: 30 × 2\n   ticker avg_price\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 UNH         516.\n 2 GS          435.\n 3 MSFT        417.\n 4 HD          354.\n 5 CAT         335.\n 6 AMGN        302.\n 7 MCD         275.\n 8 V           273.\n 9 CRM         271.\n10 AXP         227.\n# ℹ 20 more rows\n\n\n\nUnited Health\nGoldman Sachs\nMicrosoft\nHome Depot\nCaterpillar"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#volatility",
    "href": "posts/03_variance/03_Variance.html#volatility",
    "title": "3: Variance",
    "section": "Volatility",
    "text": "Volatility\nWhich stocks have been the most volatile this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, volatility) |&gt;\n  distinct() |&gt;\n  arrange(desc(volatility))\n\n# A tibble: 30 × 2\n   ticker volatility\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 GS           43.5\n 2 UNH          37.5\n 3 CRM          22.2\n 4 CAT          21.9\n 5 AMGN         21.3\n 6 AAPL         20.8\n 7 MSFT         19.5\n 8 AXP          18.9\n 9 BA           17.5\n10 MMM          16.2\n# ℹ 20 more rows\n\n\n\nGoldman Sachs\nUnited Health\nSalesforce\nCaterpillar\nAmgen\n\nWhich stocks have been the most volatile this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, volatility) |&gt;\n  distinct() |&gt;\n  arrange(volatility)\n\n# A tibble: 30 × 2\n   ticker volatility\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 VZ          0.973\n 2 CSCO        1.73 \n 3 DOW         2.29 \n 4 KO          3.58 \n 5 MRK         5.56 \n 6 PG          6.23 \n 7 JNJ         6.23 \n 8 CVX         6.24 \n 9 WMT         6.47 \n10 HON         6.56 \n# ℹ 20 more rows\n\n\n\nVerizon\nCisco\nDow Inc\nCoca-Cola\nMerck"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#coefficient-of-variation",
    "href": "posts/03_variance/03_Variance.html#coefficient-of-variation",
    "title": "3: Variance",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\nWouldn’t the most expensive stocks naturally vary more?\n\\[\\text{CoV} = \\frac{s}{\\bar{x}}\\]\n\n\\(\\bar{x}\\): sample mean\n\\(s\\): sample standard deviation\n\nWhich stocks have the highest coefficients of variation this year?\n\ndow_df |&gt;\n  group_by(ticker) |&gt;\n  mutate(avg_price = mean(price_close, na.rm = TRUE)) |&gt;\n  mutate(volatility = sd(price_close, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(ticker, avg_price, volatility) |&gt;\n  distinct() |&gt;\n  mutate(coef_var = volatility / avg_price) |&gt;\n  arrange(desc(coef_var))\n\n# A tibble: 30 × 4\n   ticker avg_price volatility coef_var\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 INTC        35.1       8.58   0.244 \n 2 MMM         98.2      16.2    0.165 \n 3 NKE         91.6      10.6    0.115 \n 4 AAPL       195.       20.8    0.106 \n 5 WMT         63.3       6.47   0.102 \n 6 GS         435.       43.5    0.100 \n 7 DIS        102.        9.92   0.0971\n 8 BA         187.       17.5    0.0934\n 9 AXP        227.       18.9    0.0833\n10 CRM        271.       22.2    0.0819\n# ℹ 20 more rows\n\n\n\nIntel\n3M\nNike\nApple\nWalmart"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#z-scores-1",
    "href": "posts/03_variance/03_Variance.html#z-scores-1",
    "title": "3: Variance",
    "section": "Z-scores",
    "text": "Z-scores\nSometimes, we want to rescale numerical columns to be able to compare them together.\n\nsummary(dow_df$price_close)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.89   96.86  181.35  198.37  271.92  604.18 \n\n\n\ndow_df &lt;- dow_df |&gt;\n  mutate(price_scaled = scale(price_close)) #z-scores\n\n\nsummary(dow_df$price_scaled)\n\n       V1         \n Min.   :-1.4525  \n 1st Qu.:-0.8215  \n Median :-0.1377  \n Mean   : 0.0000  \n 3rd Qu.: 0.5953  \n Max.   : 3.2842"
  },
  {
    "objectID": "posts/03_variance/03_Variance.html#line-plots",
    "href": "posts/03_variance/03_Variance.html#line-plots",
    "title": "3: Variance",
    "section": "Line Plots",
    "text": "Line Plots\n\nVizCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle_string &lt;- \"&lt;span style='color:blue'&gt;Verizon&lt;/span&gt; and &lt;span style='color:red'&gt;Goldman Sachs&lt;/span&gt;\"\nsubtitle_string &lt;- \"2024 stock prices\"\n\ndow_df |&gt;\n  ggplot() +\n  geom_line(aes(x = ref_date, y = price_close),\n            color = \"blue\", linewidth = 2,\n            data = dow_df |&gt; filter(ticker == \"VZ\")) +\n  geom_line(aes(x = ref_date, y = price_close),\n            color = \"red\", linewidth = 3,\n            data = dow_df |&gt; filter(ticker == \"GS\")) +\n  labs(title = title_string,\n       subtitle = subtitle_string,\n       caption = \"SML 201\",\n       x = \"date\", y = \"closing price\") +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", hjust = 0.5,size = 25),\n        plot.subtitle = element_markdown(hjust = 0.5,size = 20))"
  },
  {
    "objectID": "posts/04_categories/04_categories.html",
    "href": "posts/04_categories/04_categories.html",
    "title": "4: Categories",
    "section": "",
    "text": "Goal: Explore data wrangling with categorical variables\nObjective: Compute counts, make bar graphs, and discuss data\n\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#start",
    "href": "posts/04_categories/04_categories.html#start",
    "title": "4: Categories",
    "section": "",
    "text": "Goal: Explore data wrangling with categorical variables\nObjective: Compute counts, make bar graphs, and discuss data\n\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#data",
    "href": "posts/04_categories/04_categories.html#data",
    "title": "4: Categories",
    "section": "Data",
    "text": "Data\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#queries",
    "href": "posts/04_categories/04_categories.html#queries",
    "title": "4: Categories",
    "section": "Queries",
    "text": "Queries\n\n\nFor the Demographics Survey, here are the variable names that represent the responses to the survey questions.\n\n\n\n\n\n\ndemographics survey"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-ocean-or-snow",
    "href": "posts/04_categories/04_categories.html#example-ocean-or-snow",
    "title": "4: Categories",
    "section": "Example: Ocean or Snow?",
    "text": "Example: Ocean or Snow?\n\ndemo_df |&gt;\n  filter(!is.na(oceanSnow)) |&gt;\n  ggplot(aes(x = oceanSnow)) +\n  geom_bar(aes(fill = oceanSnow),\n           color = \"black\",\n           stat = \"count\")"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-campus-safety",
    "href": "posts/04_categories/04_categories.html#example-campus-safety",
    "title": "4: Categories",
    "section": "Example: Campus Safety",
    "text": "Example: Campus Safety\nOn a scale from 0 to 100—with 0 = very anxious and 100 = comfortable—how safe do you feel on campus?\n\nsummary(demo_df$safety)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2.00   80.00   90.00   87.16   97.25  100.00       5 \n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = safety)) +\n  geom_histogram(binwidth = 5)\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = safety, group = gender)) +\n  geom_density(aes(fill = gender),\n               alpha = 0.5)\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\ndemo_df |&gt;\n  ggplot(aes(x = gender, y = safety)) +\n  geom_boxplot()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-flossing",
    "href": "posts/04_categories/04_categories.html#example-flossing",
    "title": "4: Categories",
    "section": "Example: Flossing",
    "text": "Example: Flossing\n\nsummary(demo_df$flossing)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   2.000   5.000   5.224   7.000  14.000      10"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-football",
    "href": "posts/04_categories/04_categories.html#example-football",
    "title": "4: Categories",
    "section": "Example: Football",
    "text": "Example: Football\n\ndemo_df |&gt;\n  select(football) |&gt;\n  separate_longer_delim(football, delim = \",\") |&gt;\n  count(football) |&gt;\n  arrange(desc(n))\n\n# A tibble: 29 × 2\n   football                 n\n   &lt;chr&gt;                &lt;int&gt;\n 1 &lt;NA&gt;                    40\n 2 New York Giants         14\n 3 Philadelphia Eagles     13\n 4 San Francisco 49ers     11\n 5 Dallas Cowboys           7\n 6 Buffalo Bills            6\n 7 Houston Texas            6\n 8 New England Patriots     6\n 9 Arizona Cardinals        5\n10 New York Jets            5\n# ℹ 19 more rows\n\n\n\ndemo_df |&gt;\n  select(baseball) |&gt;\n  separate_longer_delim(baseball, delim = \",\") |&gt;\n  count(baseball) |&gt;\n  arrange(desc(n))\n\n# A tibble: 28 × 2\n   baseball                  n\n   &lt;chr&gt;                 &lt;int&gt;\n 1 &lt;NA&gt;                     49\n 2 New York Yankees         16\n 3 Boston Red Sox           11\n 4 New York Mets            11\n 5 Philadelphia Phillies    11\n 6 Los Angeles Dodgers       8\n 7 Arizona Diamondbacks      4\n 8 Houston Astros            4\n 9 Miami Marlins             4\n10 San Franciso Giants       4\n# ℹ 18 more rows"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-sleep",
    "href": "posts/04_categories/04_categories.html#example-sleep",
    "title": "4: Categories",
    "section": "Example: Sleep",
    "text": "Example: Sleep"
  },
  {
    "objectID": "posts/04_categories/04_categories.html#example-residential-colleges",
    "href": "posts/04_categories/04_categories.html#example-residential-colleges",
    "title": "4: Categories",
    "section": "Example: Residential Colleges",
    "text": "Example: Residential Colleges"
  },
  {
    "objectID": "posts/05_networks/05_networks.html",
    "href": "posts/05_networks/05_networks.html",
    "title": "5: Networks",
    "section": "",
    "text": "Goal: Visualize network data\nObjective: Arrange paired data into nodes and edges\n\n\n\n\n\n\n\nnetwork terminology\n\n\n\nimage source: MRI Questions\n\n\n\n\n\n\nMoving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#start",
    "href": "posts/05_networks/05_networks.html#start",
    "title": "5: Networks",
    "section": "",
    "text": "Goal: Visualize network data\nObjective: Arrange paired data into nodes and edges\n\n\n\n\n\n\n\nnetwork terminology\n\n\n\nimage source: MRI Questions"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#rbind",
    "href": "posts/05_networks/05_networks.html#rbind",
    "title": "5: Networks",
    "section": "rbind",
    "text": "rbind\n\ndf1 &lt;- music_df |&gt;\n  select(artist1, song1) |&gt;\n  set_names(c(\"artist\", \"song\"))\ndf2 &lt;- music_df |&gt;\n  select(artist2, song2) |&gt;\n  set_names(c(\"artist\", \"song\"))\n\nmusic_long &lt;- df1 |&gt;\n  rbind(df2) |&gt;\n  separate_longer_delim(artist, delim = \", \") |&gt;\n  filter(!is.na(artist)) |&gt;\n  filter(!is.na(song))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#top_n",
    "href": "posts/05_networks/05_networks.html#top_n",
    "title": "5: Networks",
    "section": "top_n",
    "text": "top_n\nWho are the top 5 most frequent artists in the data set?\n\nmusic_long |&gt;\n  count(artist) |&gt;\n  arrange(desc(n)) |&gt;\n  top_n(5, wt = n)\n\n# A tibble: 6 × 2\n  artist                n\n  &lt;chr&gt;             &lt;int&gt;\n1 Taylor Swift         10\n2 Sabrina Carpenter     9\n3 SZA                   7\n4 Daya                  6\n5 Bruno Mars            4\n6 Lauv                  4\n\n\n\ntop_artists &lt;- music_long |&gt;\n  count(artist) |&gt;\n  arrange(desc(n)) |&gt;\n  top_n(5, wt = n) |&gt;\n  pull(artist)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble",
    "href": "posts/05_networks/05_networks.html#node-tibble",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(id = music_long$artist,\n                  label = music_long$artist,\n                  color = \"green\",\n                  shape = \"circle\")\nnode_tbl &lt;- node_tbl |&gt;\n  bind_rows(\n    tibble(id = music_long$song,\n           label = music_long$song,\n           color = \"yellow\",\n           shape = \"circle\")\n  ) |&gt;\n  distinct()"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble",
    "href": "posts/05_networks/05_networks.html#edge-tibble",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from = music_long$artist,\n  to = music_long$song,\n  arrow = \"to\") #directed network"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Song Playlist Network\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#filtered-plot",
    "href": "posts/05_networks/05_networks.html#filtered-plot",
    "title": "5: Networks",
    "section": "Filtered Plot",
    "text": "Filtered Plot\n\nmusic_top &lt;- music_long |&gt;\n  filter(artist %in% top_artists)\n\nnode_tbl &lt;- tibble(id = music_top$artist,\n                  label = music_top$artist,\n                  color = \"green\",\n                  shape = \"circle\")\nnode_tbl &lt;- node_tbl |&gt;\n  bind_rows(\n    tibble(id = music_top$song,\n           label = music_top$song,\n           color = \"yellow\",\n           shape = \"circle\")\n  ) |&gt;\n  distinct()\n\nedge_tbl &lt;- tibble(\n  from = music_top$artist,\n  to = music_top$song)\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Song Playlist Network\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#other-music",
    "href": "posts/05_networks/05_networks.html#other-music",
    "title": "5: Networks",
    "section": "Other Music",
    "text": "Other Music\nWe can negate the %in% to create a complement set of lessor known songs. We can also use the sample function to display a small number of those songs.\n\nmusic_long |&gt;\n  filter(!(artist %in% top_artists)) |&gt;\n  sample_n(10)\n\n# A tibble: 10 × 2\n   artist           song         \n   &lt;chr&gt;            &lt;chr&gt;        \n 1 NewJeans         Right Now    \n 2 Slow Pulp        High         \n 3 Lisa Loeb        Fools Like Me\n 4 Charlie xcx      365          \n 5 The Beatles      Let It Be    \n 6 Yuuri            Dried Flower \n 7 New Jeans        OMG          \n 8 Childish Gambino Riot         \n 9 Harry Styles     Keep Driving \n10 Frank Ocean      Pink + White"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble-1",
    "href": "posts/05_networks/05_networks.html#node-tibble-1",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(id = majors_df$major,\n                  label = majors_df$major,\n                  color = \"#E77500\",\n                  shape = \"circle\") |&gt;\n  bind_rows(\n    tibble(id = majors_df$minor1,\n           label = majors_df$minor1,\n           color = \"#121212\",\n           opacity = 0.5,\n           shape = \"circle\")\n  ) |&gt; \n  bind_rows(\n    tibble(id = majors_df$minor2,\n           label = majors_df$minor2,\n           color = \"#121212\",\n           opacity = 0.5,\n           shape = \"circle\")\n  ) |&gt; \n  distinct(id, .keep_all = TRUE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble-1",
    "href": "posts/05_networks/05_networks.html#edge-tibble-1",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from = majors_df$major,\n  to = majors_df$minor1,\n  color = \"#333333\") |&gt;\n  bind_rows(\n    tibble(from = majors_df$major,\n           to = majors_df$minor2,\n           color = \"#333333\")\n  ) |&gt;\n  filter(!is.na(to))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot-1",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot-1",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Majors and Minors at Princeton\\nAmong SML 201 Students\")"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#node-tibble-2",
    "href": "posts/05_networks/05_networks.html#node-tibble-2",
    "title": "5: Networks",
    "section": "Node Tibble",
    "text": "Node Tibble\n\nnode_tbl &lt;- tibble(\n  id = classes_df$class1,\n  label = classes_df$class1) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class2,\n    label = classes_df$class2\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class3,\n    label = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class4,\n    label = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class5,\n    label = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    id = classes_df$class6,\n    label = classes_df$class6\n  )) |&gt;\n  distinct() |&gt;\n  filter(!is.na(id)) |&gt;\n  filter(id != \"SML 201\") |&gt;\n  separate(id, into = c(\"dept\", \"num\"), \n           sep = \" \", remove = FALSE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#edge-tibble-2",
    "href": "posts/05_networks/05_networks.html#edge-tibble-2",
    "title": "5: Networks",
    "section": "Edge Tibble",
    "text": "Edge Tibble\n\nedge_tbl &lt;- tibble(\n  from   = classes_df$class1,\n  to     = classes_df$class2\n) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class1,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class3\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class2,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class4\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class3,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class4,\n    to   = classes_df$class5\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class4,\n    to   = classes_df$class6\n  )) |&gt;\n  bind_rows(tibble(\n    from = classes_df$class5,\n    to   = classes_df$class6\n  )) |&gt;\n  distinct() |&gt;\n  filter(!is.na(to)) |&gt;\n  filter(from != \"SML 201\") |&gt;\n  separate(from, into = c(\"dept_from\", \"num_from\"), \n           sep = \" \", remove = FALSE) |&gt;\n  separate(to, into = c(\"dept_to\", \"num_to\"), \n           sep = \" \", remove = FALSE)"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#viznetwork-plot-2",
    "href": "posts/05_networks/05_networks.html#viznetwork-plot-2",
    "title": "5: Networks",
    "section": "vizNetwork Plot",
    "text": "vizNetwork Plot\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Current Classes\",\n           submain = \"Among SML 201 Students\") |&gt;\n  visPhysics(maxVelocity = 5,\n             stabilization = list(iterations = 5))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#highlighted-plot",
    "href": "posts/05_networks/05_networks.html#highlighted-plot",
    "title": "5: Networks",
    "section": "Highlighted Plot",
    "text": "Highlighted Plot\n\ndept_abbrev = \"MOL\"\n\nnode_tbl &lt;- node_tbl |&gt;\n  mutate(color = ifelse(dept == dept_abbrev,\n                        \"#E77500\", \"#DDDDDD\"),\n         opacity = ifelse(dept == dept_abbrev,\n                        1.0, 0.5))\nedge_tbl &lt;- edge_tbl |&gt;\n  mutate(color = ifelse(dept_from == dept_abbrev | dept_to == dept_abbrev,\n                        \"#E77500\", \"#DDDDDD\"))\n\n\nvisNetwork(nodes = node_tbl, \n           edges = edge_tbl,\n           main = \"Classes Connected to MOL BIO\",\n           submain = \"Among SML 201 Students\") |&gt;\n  visPhysics(maxVelocity = 5,\n             stabilization = list(iterations = 5))"
  },
  {
    "objectID": "posts/05_networks/05_networks.html#template-files",
    "href": "posts/05_networks/05_networks.html#template-files",
    "title": "5: Networks",
    "section": "",
    "text": "Moving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "lecture_code/session4notes_L02.html",
    "href": "lecture_code/session4notes_L02.html",
    "title": "session 4 notes",
    "section": "",
    "text": "library(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")\n\nRows: 133 Columns: 84\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (38): timestamp, currentCourse, statsBefore, classStanding, major, resid...\ndbl (46): numCourses, GPA, hoursStudying, age, height, shoeSize, weight, cal...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session4notes_L02.html#filtering",
    "href": "lecture_code/session4notes_L02.html#filtering",
    "title": "session 4 notes",
    "section": "Filtering",
    "text": "Filtering\n\ndf2 &lt;- select(demo_df, residentialCollege, languages)\n\ndf3 &lt;- filter(df2, residentialCollege == \"Mathey\")\n\n# sample means\nxbar &lt;- mean(df3$languages, na.rm = TRUE)\nxbar\n\n[1] 2.092308\n\ndf4 &lt;- filter(df2, residentialCollege == \"Forbes\")\nxbar &lt;- mean(df4$languages, na.rm = TRUE)\nxbar\n\n[1] 2.552941\n\n\n\nkey observation: the sample mean can change based on the sampling\n\n\ndf_grouped &lt;- group_by(df2, residentialCollege)\nsummarize(df_grouped,\n          xbar = mean(languages, na.rm = TRUE))\n\n# A tibble: 8 × 2\n  residentialCollege   xbar\n  &lt;chr&gt;               &lt;dbl&gt;\n1 Butler               2.05\n2 Forbes               2.55\n3 Mathey               2.09\n4 New College West     2.53\n5 Rockefeller          2.37\n6 Whitman              2.32\n7 Yeh College          2.29\n8 &lt;NA&gt;               NaN   \n\n\n\nall_means &lt;- summarize(df_grouped,\n          xbar = mean(languages, na.rm = TRUE))\n\n# variables go inside aesthetics\nggplot(all_means, aes(x = residentialCollege, y = xbar)) +\n  \n  # when we want to plot the numbers directly, use \"identity\"\n  geom_bar(color = \"red\", fill = \"green\",stat = \"identity\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`)."
  },
  {
    "objectID": "lecture_code/session4notes_L02.html#more-examples",
    "href": "lecture_code/session4notes_L02.html#more-examples",
    "title": "session 4 notes",
    "section": "More Examples",
    "text": "More Examples\nWhat time do you go to sleep?\n\ntable(demo_df$sleepTime)\n\n\n       1 AM       10 PM       11 PM 12 midnight        2 AM        3 AM \n         33           6          19          52          15           6 \n\n\n\nsummary(demo_df$flossing)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   2.000   5.000   5.224   7.000  14.000      10 \n\n\n\nsummary(demo_df$attractiveness)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   50.00   65.00   63.18   79.00  100.00      16 \n\n\n\nsummary(demo_df$intelligence)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   60.00   70.00   67.52   83.00  100.00      12 \n\n\n\nsummary(demo_df$showers)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2.00    7.00    7.00    7.55    8.00   16.00       4 \n\n\n\ntable(demo_df$drugUse)\n\n\n No Yes \n 99  32 \n\n\n\ntable(demo_df$pancakesWaffles)\n\n\nPancakes  Waffles \n      59       69 \n\n\n\nsummary(demo_df$SAT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0    1500    1540    1617    1560   15560      24 \n\ndemo_df$SAT[demo_df$SAT &gt; 1600] &lt;- NA\ndemo_df$SAT[demo_df$SAT &lt; 400] &lt;- NA\n\nsummary(demo_df$SAT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1100    1500    1540    1516    1560    1600      27"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html",
    "href": "lecture_code/session3notes_L02.html",
    "title": "session 3 notes",
    "section": "",
    "text": "A &lt;- seq(-3,3)\nB &lt;- seq(-9, 9, by = 3)\nA\n\n[1] -3 -2 -1  0  1  2  3\n\nB\n\n[1] -9 -6 -3  0  3  6  9\n\n\n\n\n\nmean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0\n\n\n\n\n\n\nvar(A)\n\n[1] 4.666667\n\nvar(B)\n\n[1] 42\n\n\nThe variance of set B is larger than the variance of set A.\n\n\n\n\nsd(A)\n\n[1] 2.160247\n\nsd(B)\n\n[1] 6.480741\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#centrality",
    "href": "lecture_code/session3notes_L02.html#centrality",
    "title": "session 3 notes",
    "section": "",
    "text": "mean(A)\n\n[1] 0\n\nmean(B)\n\n[1] 0\n\nmedian(A)\n\n[1] 0\n\nmedian(B)\n\n[1] 0"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#variance",
    "href": "lecture_code/session3notes_L02.html#variance",
    "title": "session 3 notes",
    "section": "",
    "text": "var(A)\n\n[1] 4.666667\n\nvar(B)\n\n[1] 42\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#standard-deviation",
    "href": "lecture_code/session3notes_L02.html#standard-deviation",
    "title": "session 3 notes",
    "section": "",
    "text": "sd(A)\n\n[1] 2.160247\n\nsd(B)\n\n[1] 6.480741\n\n\nThe variance of set B is larger than the variance of set A."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#exploration",
    "href": "lecture_code/session3notes_L02.html#exploration",
    "title": "session 3 notes",
    "section": "exploration",
    "text": "exploration\n\nhead(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 AAPL   2024-01-02       187.       188.      184.        186. 82488700\n2 AAPL   2024-01-03       184.       186.      183.        184. 58414500\n3 AAPL   2024-01-04       182.       183.      181.        182. 71983600\n4 AAPL   2024-01-05       182.       183.      180.        181. 62303300\n5 AAPL   2024-01-08       182.       186.      182.        186. 59144500\n6 AAPL   2024-01-09       184.       185.      183.        185. 42841800\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\ntail(dow_df)\n\n# A tibble: 6 × 11\n  ticker ref_date   price_open price_high price_low price_close   volume\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 WMT    2024-08-29       76.0       76.5      75.7        76.4 11856800\n2 WMT    2024-08-30       76.4       77.5      76.2        77.2 23230000\n3 WMT    2024-09-03       77.3       77.8      76.8        77.2 22666100\n4 WMT    2024-09-04       77.3       77.5      76.7        77.2 18442800\n5 WMT    2024-09-05       77.2       77.4      76.4        77.0 13082900\n6 WMT    2024-09-06       76.9       77.3      76.3        76.6 14545900\n# ℹ 4 more variables: price_adjusted &lt;dbl&gt;, ret_adjusted_prices &lt;dbl&gt;,\n#   ret_closing_prices &lt;dbl&gt;, cumret_adjusted_prices &lt;dbl&gt;\n\n\n\nstr(dow_df, give.attr = FALSE)\n\nspc_tbl_ [5,160 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ticker                : chr [1:5160] \"AAPL\" \"AAPL\" \"AAPL\" \"AAPL\" ...\n $ ref_date              : Date[1:5160], format: \"2024-01-02\" \"2024-01-03\" ...\n $ price_open            : num [1:5160] 187 184 182 182 182 ...\n $ price_high            : num [1:5160] 188 186 183 183 186 ...\n $ price_low             : num [1:5160] 184 183 181 180 182 ...\n $ price_close           : num [1:5160] 186 184 182 181 186 ...\n $ volume                : num [1:5160] 82488700 58414500 71983600 62303300 59144500 ...\n $ price_adjusted        : num [1:5160] 185 184 181 180 185 ...\n $ ret_adjusted_prices   : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ ret_closing_prices    : num [1:5160] NA -0.00749 -0.0127 -0.00401 0.02417 ...\n $ cumret_adjusted_prices: num [1:5160] 1 0.993 0.98 0.976 1 ...\n\n\n\ncolnames(dow_df)\n\n [1] \"ticker\"                 \"ref_date\"               \"price_open\"            \n [4] \"price_high\"             \"price_low\"              \"price_close\"           \n [7] \"volume\"                 \"price_adjusted\"         \"ret_adjusted_prices\"   \n[10] \"ret_closing_prices\"     \"cumret_adjusted_prices\""
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#which-stocks",
    "href": "lecture_code/session3notes_L02.html#which-stocks",
    "title": "session 3 notes",
    "section": "Which stocks?",
    "text": "Which stocks?\ntable tallies the amounts in a categorical variable\n\ntable(dow_df$ticker)\n\n\nAAPL AMGN AMZN  AXP   BA  CAT  CRM CSCO  CVX  DIS  DOW   GS   HD  HON  IBM INTC \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172  172  172 \n JNJ  JPM   KO  MCD  MMM  MRK MSFT  NKE   PG  TRV  UNH    V   VZ  WMT \n 172  172  172  172  172  172  172  172  172  172  172  172  172  172"
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#histograms",
    "href": "lecture_code/session3notes_L02.html#histograms",
    "title": "session 3 notes",
    "section": "Histograms",
    "text": "Histograms\nA histogram shows us the distribution of a numerical variable.\n\ndow_df |&gt;\n  filter(ticker == \"VZ\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Verison Stock\",\n       subtitle = \"2024 prices\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndow_df |&gt;\n  filter(ticker == \"GS\") |&gt;\n  ggplot(aes(x = price_close)) +\n  geom_histogram() +\n  labs(title = \"Goldman Sachs Stock\",\n       subtitle = \"2024 prices\",\n       caption = \"SML 201\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lecture_code/session3notes_L02.html#z-scores-1",
    "href": "lecture_code/session3notes_L02.html#z-scores-1",
    "title": "session 3 notes",
    "section": "Z-scores",
    "text": "Z-scores\nSometimes we want to rescale numerical columns to be able to compare them together.\n\nsummary(dow_df$price_close)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.89   96.86  181.35  198.37  271.92  604.18 \n\n\n\ndow_df &lt;- dow_df |&gt;\n  #mutate attachs a new column\n  mutate(price_scaled = scale(price_close))\n\n\nsummary(dow_df$price_scaled)\n\n       V1         \n Min.   :-1.4525  \n 1st Qu.:-0.8215  \n Median :-0.1377  \n Mean   : 0.0000  \n 3rd Qu.: 0.5953  \n Max.   : 3.2842"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html",
    "href": "lecture_code/session2notes_L01.html",
    "title": "session 2 notes",
    "section": "",
    "text": "add up the values\ndivide by amount of values\n\n“c” means “concatenate” (or “combine”)\nto run one line of code: CTRL + ENTER\n\n# create some data\nsome_data &lt;- c(32, 45, 16, 78, 39)\n\nsum(some_data)\n\n[1] 210\n\nlength(some_data)\n\n[1] 5\n\nsum(some_data) / length(some_data)\n\n[1] 42\n\nmean(some_data)\n\n[1] 42\n\n\n\n\nNA for non-applicable, or “missing data”\nBy default, R stops upon missing\n\nwant to avoid the missing data\n\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\n\nmean(some_data)\n\n[1] NA\n\nmean(some_data, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#missing-data",
    "href": "lecture_code/session2notes_L01.html#missing-data",
    "title": "session 2 notes",
    "section": "",
    "text": "NA for non-applicable, or “missing data”\nBy default, R stops upon missing\n\nwant to avoid the missing data\n\n\nsome_data &lt;- c(32, 45, 16, 78, NA, 39)\n\nmean(some_data)\n\n[1] NA\n\nmean(some_data, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#explore-the-data",
    "href": "lecture_code/session2notes_L01.html#explore-the-data",
    "title": "session 2 notes",
    "section": "explore the data",
    "text": "explore the data\n\nhead(olympic_df1)\n\n# A tibble: 6 × 36\n     code name         name_short name_tv gender `function` country_code country\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n1 1532873 AMOYAN Malk… AMOYAN M   Malkha… Male   Athlete    ARM          Armenia\n2 1532874 GALSTYAN Sl… GALSTYAN S Slavik… Male   Athlete    ARM          Armenia\n3 1532944 HARUTYUNYAN… HARUTYUNY… Arsen … Male   Athlete    ARM          Armenia\n4 1532945 TEVANYAN Va… TEVANYAN V Vazgen… Male   Athlete    ARM          Armenia\n5 1533136 BASS BITTAY… BASS BITT… Gina M… Female Athlete    GAM          Gambia \n6 1533176 CAMARA Ebra… CAMARA E   Ebrahi… Male   Athlete    GAM          Gambia \n# ℹ 28 more variables: country_full &lt;chr&gt;, nationality &lt;chr&gt;,\n#   nationality_full &lt;chr&gt;, nationality_code &lt;chr&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;,\n#   disciplines &lt;chr&gt;, events &lt;chr&gt;, birth_date &lt;date&gt;, birth_place &lt;chr&gt;,\n#   birth_country &lt;chr&gt;, residence_place &lt;chr&gt;, residence_country &lt;chr&gt;,\n#   nickname &lt;chr&gt;, hobbies &lt;chr&gt;, occupation &lt;chr&gt;, education &lt;chr&gt;,\n#   family &lt;chr&gt;, lang &lt;chr&gt;, coach &lt;chr&gt;, reason &lt;chr&gt;, hero &lt;chr&gt;,\n#   influence &lt;chr&gt;, philosophy &lt;chr&gt;, sporting_relatives &lt;chr&gt;, …\n\nstr(olympic_df1) #structure\n\nspc_tbl_ [8,687 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code              : num [1:8687] 1532873 1532874 1532944 1532945 1533136 ...\n $ name              : chr [1:8687] \"AMOYAN Malkhas\" \"GALSTYAN Slavik\" \"HARUTYUNYAN Arsen\" \"TEVANYAN Vazgen\" ...\n $ name_short        : chr [1:8687] \"AMOYAN M\" \"GALSTYAN S\" \"HARUTYUNYAN A\" \"TEVANYAN V\" ...\n $ name_tv           : chr [1:8687] \"Malkhas AMOYAN\" \"Slavik GALSTYAN\" \"Arsen HARUTYUNYAN\" \"Vazgen TEVANYAN\" ...\n $ gender            : chr [1:8687] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ function          : chr [1:8687] \"Athlete\" \"Athlete\" \"Athlete\" \"Athlete\" ...\n $ country_code      : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ country           : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ country_full      : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality       : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_full  : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_code  : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ height            : num [1:8687] 0 0 0 0 161 178 0 0 183 0 ...\n $ weight            : num [1:8687] -99 -99 -99 -99 -99 -99 -99 -99 -99 -99 ...\n $ disciplines       : chr [1:8687] \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" ...\n $ events            : chr [1:8687] \"[\\\"Men's Greco-Roman 77kg\\\"]\" \"[\\\"Men's Greco-Roman 67kg\\\"]\" \"[\\\"Men's Freestyle 57kg\\\"]\" \"[\\\"Men's Freestyle 65kg\\\"]\" ...\n $ birth_date        : Date[1:8687], format: \"1999-01-22\" \"1996-12-21\" ...\n $ birth_place       : chr [1:8687] \"YEREVAN\" NA \"MASIS\" \"POKR VEDI\" ...\n $ birth_country     : chr [1:8687] \"Armenia\" NA \"Armenia\" \"Armenia\" ...\n $ residence_place   : chr [1:8687] \"YEREVAN\" \"YEREVAN\" \"YEREVAN\" NA ...\n $ residence_country : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nickname          : chr [1:8687] NA NA NA NA ...\n $ hobbies           : chr [1:8687] NA NA NA NA ...\n $ occupation        : chr [1:8687] NA NA \"Athlete\" \"Athlete\" ...\n $ education         : chr [1:8687] NA NA \"Graduated with a Master's degree from the Armenian State Institute of Physical Culture and Sport (2023)\" \"Studied at the Armenian State Institute of Physical Culture and Sport (Yerevan, ARM)\" ...\n $ family            : chr [1:8687] NA NA \"Wife, Diana (married October 2022). Daughter, Marias (born 2023)\" \"Wife, Sona (married November 2023)\" ...\n $ lang              : chr [1:8687] \"Armenian\" \"Armenian\" \"Armenian\" \"Armenian, Russian\" ...\n $ coach             : chr [1:8687] NA \"Personal: Martin Alekhanyan (ARM).&lt;br&gt;National: Armen Babalaryan (ARM)\" \"National: Habetnak Kurghinyan\" \"National: Habetnak Kurghinyan (ARM)\" ...\n $ reason            : chr [1:8687] NA NA \"While doing karate he noticed wrestlers training and decided to give it a try. He also tried judo but his fathe\"| __truncated__ \"“My family did not like wrestling very much. At first I wanted to do boxing but my older friends advised me to \"| __truncated__ ...\n $ hero              : chr [1:8687] NA NA \"Wrestler Armen Nazaryan (ARM, BUL), two-time Olympic champion (1996, 2000) and 2004 bronze medallist. Eight-tim\"| __truncated__ NA ...\n $ influence         : chr [1:8687] NA NA NA NA ...\n $ philosophy        : chr [1:8687] \"\\\"To become a good athlete, you first have to be a good person.\\\" (ankakh.com, 6 Oct 2018)\" NA \"“Nothing is impossible, set goals in front of you, fight and achieve it.” (Instagram, 13 May 2023)\" NA ...\n $ sporting_relatives: chr [1:8687] \"Uncle, Roman Amoyan (wrestling), 2008 Olympic bronze medallist and two-time European champion in Greco-Roman\" NA NA NA ...\n $ ritual            : chr [1:8687] NA NA NA NA ...\n $ other_sports      : chr [1:8687] NA NA NA NA ...\n $ age               : num [1:8687] 25 28 25 25 29 28 30 27 27 17 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   name = col_character(),\n  ..   name_short = col_character(),\n  ..   name_tv = col_character(),\n  ..   gender = col_character(),\n  ..   `function` = col_character(),\n  ..   country_code = col_character(),\n  ..   country = col_character(),\n  ..   country_full = col_character(),\n  ..   nationality = col_character(),\n  ..   nationality_full = col_character(),\n  ..   nationality_code = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   disciplines = col_character(),\n  ..   events = col_character(),\n  ..   birth_date = col_date(format = \"\"),\n  ..   birth_place = col_character(),\n  ..   birth_country = col_character(),\n  ..   residence_place = col_character(),\n  ..   residence_country = col_character(),\n  ..   nickname = col_character(),\n  ..   hobbies = col_character(),\n  ..   occupation = col_character(),\n  ..   education = col_character(),\n  ..   family = col_character(),\n  ..   lang = col_character(),\n  ..   coach = col_character(),\n  ..   reason = col_character(),\n  ..   hero = col_character(),\n  ..   influence = col_character(),\n  ..   philosophy = col_character(),\n  ..   sporting_relatives = col_character(),\n  ..   ritual = col_character(),\n  ..   other_sports = col_character(),\n  ..   age = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ncolnames(olympic_df1)\n\n [1] \"code\"               \"name\"               \"name_short\"        \n [4] \"name_tv\"            \"gender\"             \"function\"          \n [7] \"country_code\"       \"country\"            \"country_full\"      \n[10] \"nationality\"        \"nationality_full\"   \"nationality_code\"  \n[13] \"height\"             \"weight\"             \"disciplines\"       \n[16] \"events\"             \"birth_date\"         \"birth_place\"       \n[19] \"birth_country\"      \"residence_place\"    \"residence_country\" \n[22] \"nickname\"           \"hobbies\"            \"occupation\"        \n[25] \"education\"          \"family\"             \"lang\"              \n[28] \"coach\"              \"reason\"             \"hero\"              \n[31] \"influence\"          \"philosophy\"         \"sporting_relatives\"\n[34] \"ritual\"             \"other_sports\"       \"age\"               \n\n\n\nmean(olympic_df1$weight)\n\n[1] NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] -93.50138\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  -99.0   -99.0   -99.0   -93.5   -99.0   113.0      11 \n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] 77.68889\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  51.00   67.00   76.50   77.69   88.00  113.00    8417"
  },
  {
    "objectID": "lecture_code/session2notes_L01.html#filter",
    "href": "lecture_code/session2notes_L01.html#filter",
    "title": "session 2 notes",
    "section": "Filter",
    "text": "Filter\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html",
    "href": "lecture_code/session2notes_L02.html",
    "title": "session 2 notes",
    "section": "",
    "text": "add up the numbers\ndivide by the amount of numbers\n\nto run a line of code: CTRL + ENTER\n“c” for concatenate (“combine”)\n\nsome_data &lt;- c(32, 45, 16, 78, 39)\nsum(some_data)\n\n[1] 210\n\nlength(some_data)\n\n[1] 5\n\nsum(some_data) / length(some_data)\n\n[1] 42\n\nmean(some_data)\n\n[1] 42\n\n\n\n\nNA for not applicable (“missing data”)\nR stops calculations upon missing data\n* want to avoid the missing data\n\nsome_data2 &lt;- c(32, 45, 16, 78, NA, 39) #another list\nmean(some_data2)\n\n[1] NA\n\nmean(some_data2, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#missing-data",
    "href": "lecture_code/session2notes_L02.html#missing-data",
    "title": "session 2 notes",
    "section": "",
    "text": "NA for not applicable (“missing data”)\nR stops calculations upon missing data\n* want to avoid the missing data\n\nsome_data2 &lt;- c(32, 45, 16, 78, NA, 39) #another list\nmean(some_data2)\n\n[1] NA\n\nmean(some_data2, na.rm = TRUE)\n\n[1] 42"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#load-data",
    "href": "lecture_code/session2notes_L02.html#load-data",
    "title": "session 2 notes",
    "section": "Load Data",
    "text": "Load Data\n\nolympic_df1 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data.csv\")\n\nRows: 8687 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (31): name, name_short, name_tv, gender, function, country_code, countr...\ndbl   (4): code, height, weight, age\ndate  (1): birth_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nolympic_df2 &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/02_centrality/olympic_data2.csv\")\n\nRows: 11110 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (31): name, name_short, name_tv, gender, function, country_code, countr...\ndbl   (4): code, height, weight, age\ndate  (1): birth_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#explore-data",
    "href": "lecture_code/session2notes_L02.html#explore-data",
    "title": "session 2 notes",
    "section": "Explore Data",
    "text": "Explore Data\n\nhead(olympic_df1)\n\n# A tibble: 6 × 36\n     code name         name_short name_tv gender `function` country_code country\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n1 1532873 AMOYAN Malk… AMOYAN M   Malkha… Male   Athlete    ARM          Armenia\n2 1532874 GALSTYAN Sl… GALSTYAN S Slavik… Male   Athlete    ARM          Armenia\n3 1532944 HARUTYUNYAN… HARUTYUNY… Arsen … Male   Athlete    ARM          Armenia\n4 1532945 TEVANYAN Va… TEVANYAN V Vazgen… Male   Athlete    ARM          Armenia\n5 1533136 BASS BITTAY… BASS BITT… Gina M… Female Athlete    GAM          Gambia \n6 1533176 CAMARA Ebra… CAMARA E   Ebrahi… Male   Athlete    GAM          Gambia \n# ℹ 28 more variables: country_full &lt;chr&gt;, nationality &lt;chr&gt;,\n#   nationality_full &lt;chr&gt;, nationality_code &lt;chr&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;,\n#   disciplines &lt;chr&gt;, events &lt;chr&gt;, birth_date &lt;date&gt;, birth_place &lt;chr&gt;,\n#   birth_country &lt;chr&gt;, residence_place &lt;chr&gt;, residence_country &lt;chr&gt;,\n#   nickname &lt;chr&gt;, hobbies &lt;chr&gt;, occupation &lt;chr&gt;, education &lt;chr&gt;,\n#   family &lt;chr&gt;, lang &lt;chr&gt;, coach &lt;chr&gt;, reason &lt;chr&gt;, hero &lt;chr&gt;,\n#   influence &lt;chr&gt;, philosophy &lt;chr&gt;, sporting_relatives &lt;chr&gt;, …\n\nstr(olympic_df1) #structure\n\nspc_tbl_ [8,687 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code              : num [1:8687] 1532873 1532874 1532944 1532945 1533136 ...\n $ name              : chr [1:8687] \"AMOYAN Malkhas\" \"GALSTYAN Slavik\" \"HARUTYUNYAN Arsen\" \"TEVANYAN Vazgen\" ...\n $ name_short        : chr [1:8687] \"AMOYAN M\" \"GALSTYAN S\" \"HARUTYUNYAN A\" \"TEVANYAN V\" ...\n $ name_tv           : chr [1:8687] \"Malkhas AMOYAN\" \"Slavik GALSTYAN\" \"Arsen HARUTYUNYAN\" \"Vazgen TEVANYAN\" ...\n $ gender            : chr [1:8687] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ function          : chr [1:8687] \"Athlete\" \"Athlete\" \"Athlete\" \"Athlete\" ...\n $ country_code      : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ country           : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ country_full      : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality       : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_full  : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nationality_code  : chr [1:8687] \"ARM\" \"ARM\" \"ARM\" \"ARM\" ...\n $ height            : num [1:8687] 0 0 0 0 161 178 0 0 183 0 ...\n $ weight            : num [1:8687] -99 -99 -99 -99 -99 -99 -99 -99 -99 -99 ...\n $ disciplines       : chr [1:8687] \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" \"['Wrestling']\" ...\n $ events            : chr [1:8687] \"[\\\"Men's Greco-Roman 77kg\\\"]\" \"[\\\"Men's Greco-Roman 67kg\\\"]\" \"[\\\"Men's Freestyle 57kg\\\"]\" \"[\\\"Men's Freestyle 65kg\\\"]\" ...\n $ birth_date        : Date[1:8687], format: \"1999-01-22\" \"1996-12-21\" ...\n $ birth_place       : chr [1:8687] \"YEREVAN\" NA \"MASIS\" \"POKR VEDI\" ...\n $ birth_country     : chr [1:8687] \"Armenia\" NA \"Armenia\" \"Armenia\" ...\n $ residence_place   : chr [1:8687] \"YEREVAN\" \"YEREVAN\" \"YEREVAN\" NA ...\n $ residence_country : chr [1:8687] \"Armenia\" \"Armenia\" \"Armenia\" \"Armenia\" ...\n $ nickname          : chr [1:8687] NA NA NA NA ...\n $ hobbies           : chr [1:8687] NA NA NA NA ...\n $ occupation        : chr [1:8687] NA NA \"Athlete\" \"Athlete\" ...\n $ education         : chr [1:8687] NA NA \"Graduated with a Master's degree from the Armenian State Institute of Physical Culture and Sport (2023)\" \"Studied at the Armenian State Institute of Physical Culture and Sport (Yerevan, ARM)\" ...\n $ family            : chr [1:8687] NA NA \"Wife, Diana (married October 2022). Daughter, Marias (born 2023)\" \"Wife, Sona (married November 2023)\" ...\n $ lang              : chr [1:8687] \"Armenian\" \"Armenian\" \"Armenian\" \"Armenian, Russian\" ...\n $ coach             : chr [1:8687] NA \"Personal: Martin Alekhanyan (ARM).&lt;br&gt;National: Armen Babalaryan (ARM)\" \"National: Habetnak Kurghinyan\" \"National: Habetnak Kurghinyan (ARM)\" ...\n $ reason            : chr [1:8687] NA NA \"While doing karate he noticed wrestlers training and decided to give it a try. He also tried judo but his fathe\"| __truncated__ \"“My family did not like wrestling very much. At first I wanted to do boxing but my older friends advised me to \"| __truncated__ ...\n $ hero              : chr [1:8687] NA NA \"Wrestler Armen Nazaryan (ARM, BUL), two-time Olympic champion (1996, 2000) and 2004 bronze medallist. Eight-tim\"| __truncated__ NA ...\n $ influence         : chr [1:8687] NA NA NA NA ...\n $ philosophy        : chr [1:8687] \"\\\"To become a good athlete, you first have to be a good person.\\\" (ankakh.com, 6 Oct 2018)\" NA \"“Nothing is impossible, set goals in front of you, fight and achieve it.” (Instagram, 13 May 2023)\" NA ...\n $ sporting_relatives: chr [1:8687] \"Uncle, Roman Amoyan (wrestling), 2008 Olympic bronze medallist and two-time European champion in Greco-Roman\" NA NA NA ...\n $ ritual            : chr [1:8687] NA NA NA NA ...\n $ other_sports      : chr [1:8687] NA NA NA NA ...\n $ age               : num [1:8687] 25 28 25 25 29 28 30 27 27 17 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   name = col_character(),\n  ..   name_short = col_character(),\n  ..   name_tv = col_character(),\n  ..   gender = col_character(),\n  ..   `function` = col_character(),\n  ..   country_code = col_character(),\n  ..   country = col_character(),\n  ..   country_full = col_character(),\n  ..   nationality = col_character(),\n  ..   nationality_full = col_character(),\n  ..   nationality_code = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   disciplines = col_character(),\n  ..   events = col_character(),\n  ..   birth_date = col_date(format = \"\"),\n  ..   birth_place = col_character(),\n  ..   birth_country = col_character(),\n  ..   residence_place = col_character(),\n  ..   residence_country = col_character(),\n  ..   nickname = col_character(),\n  ..   hobbies = col_character(),\n  ..   occupation = col_character(),\n  ..   education = col_character(),\n  ..   family = col_character(),\n  ..   lang = col_character(),\n  ..   coach = col_character(),\n  ..   reason = col_character(),\n  ..   hero = col_character(),\n  ..   influence = col_character(),\n  ..   philosophy = col_character(),\n  ..   sporting_relatives = col_character(),\n  ..   ritual = col_character(),\n  ..   other_sports = col_character(),\n  ..   age = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ncolnames(olympic_df1) #column names\n\n [1] \"code\"               \"name\"               \"name_short\"        \n [4] \"name_tv\"            \"gender\"             \"function\"          \n [7] \"country_code\"       \"country\"            \"country_full\"      \n[10] \"nationality\"        \"nationality_full\"   \"nationality_code\"  \n[13] \"height\"             \"weight\"             \"disciplines\"       \n[16] \"events\"             \"birth_date\"         \"birth_place\"       \n[19] \"birth_country\"      \"residence_place\"    \"residence_country\" \n[22] \"nickname\"           \"hobbies\"            \"occupation\"        \n[25] \"education\"          \"family\"             \"lang\"              \n[28] \"coach\"              \"reason\"             \"hero\"              \n[31] \"influence\"          \"philosophy\"         \"sporting_relatives\"\n[34] \"ritual\"             \"other_sports\"       \"age\"               \n\n\n\nmean(olympic_df1$weight)\n\n[1] NA\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] -93.50138\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  -99.0   -99.0   -99.0   -93.5   -99.0   113.0      11 \n\n\n\nolympic_df1$weight[olympic_df1$weight &lt;= 0] &lt;- NA\nolympic_df2$weight[olympic_df2$weight &lt;= 0] &lt;- NA\n\n\nmean(olympic_df1$weight, na.rm = TRUE)\n\n[1] 77.68889\n\nsummary(olympic_df1$weight)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  51.00   67.00   76.50   77.69   88.00  113.00    8417"
  },
  {
    "objectID": "lecture_code/session2notes_L02.html#filter",
    "href": "lecture_code/session2notes_L02.html#filter",
    "title": "session 2 notes",
    "section": "Filter",
    "text": "Filter\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTurkey_df1 &lt;- olympic_df1 |&gt;\n  filter(country_code == \"TUR\")"
  },
  {
    "objectID": "lecture_code/session4notes_L01.html",
    "href": "lecture_code/session4notes_L01.html",
    "title": "session 4 notes",
    "section": "",
    "text": "Loading a CSV file with the read_csv command.\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndemo_df &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/04_categories/sml201survey.csv\")\n\nRows: 133 Columns: 84\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (38): timestamp, currentCourse, statsBefore, classStanding, major, resid...\ndbl (46): numCourses, GPA, hoursStudying, age, height, shoeSize, weight, cal...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "lecture_code/session4notes_L01.html#visualization",
    "href": "lecture_code/session4notes_L01.html#visualization",
    "title": "session 4 notes",
    "section": "Visualization",
    "text": "Visualization\n\ndemo_df |&gt;\n  ggplot(aes(x = fct_rev(fct_infreq(major)), fill = major)) +\n  coord_flip() +\n  geom_bar(stat = \"count\") +\n  labs(title = \"SML 201 students by major\",\n       subtitle = \"Fall 2024\",\n       y = \"number of students\",\n       x = \"\") +\n  theme_minimal() + #removes gray background\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html",
    "href": "posts/06_geospatial/06_geospatial.html",
    "title": "6: Geospatial",
    "section": "",
    "text": "Goal: Visualize geospatial data\nObjective: Merge shapefiles and data files\n\n\n\n\n\n\n\nNJ at a glance\n\n\n\nimage source: Totally Bamboo\n\n\n\n\n\n\nMoving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file\n\n\n\n\n\nnj_health &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_health.csv\")\nnj_pop    &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_pop.csv\")\nnj_shp    &lt;- readr::read_rds(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_shp.rds\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#start",
    "href": "posts/06_geospatial/06_geospatial.html#start",
    "title": "6: Geospatial",
    "section": "",
    "text": "Goal: Visualize geospatial data\nObjective: Merge shapefiles and data files\n\n\n\n\n\n\n\nNJ at a glance\n\n\n\nimage source: Totally Bamboo"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#template-files",
    "href": "posts/06_geospatial/06_geospatial.html#template-files",
    "title": "6: Geospatial",
    "section": "",
    "text": "Moving forward, those who want to type along with the lecture sessio will probably want to use template files\n\nGo to our Canvas Page –&gt; Files –&gt; lecture_notes\nDownload today’s template file\nMove that .qmd file into your SML 201 folder\nOpen that template file"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#load-data",
    "href": "posts/06_geospatial/06_geospatial.html#load-data",
    "title": "6: Geospatial",
    "section": "",
    "text": "nj_health &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_health.csv\")\nnj_pop    &lt;- readr::read_csv(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_pop.csv\")\nnj_shp    &lt;- readr::read_rds(\"https://raw.githubusercontent.com/dsollberger/sml201slides/main/posts/06_geospatial/nj_shp.rds\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#centroids",
    "href": "posts/06_geospatial/06_geospatial.html#centroids",
    "title": "6: Geospatial",
    "section": "Centroids",
    "text": "Centroids\n\n# Calculate the centroid of each hexagon to add the label\n# https://stackoverflow.com/questions/49343958/do-the-values-returned-by-rgeosgcentroid-and-sfst-centroid-differ\ncenters &lt;- data.frame(\n  st_coordinates(st_centroid(nj_shp$geometry)),\n  id=nj_shp$COUNTY)\n\nnj_counties &lt;- nj_shp |&gt;\n  left_join(centers, by = c(\"COUNTY\" = \"id\"))"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#text-for-labels",
    "href": "posts/06_geospatial/06_geospatial.html#text-for-labels",
    "title": "6: Geospatial",
    "section": "Text (for labels)",
    "text": "Text (for labels)\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_text(aes(x = X, y = Y, label = COUNTY)) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#labels",
    "href": "posts/06_geospatial/06_geospatial.html#labels",
    "title": "6: Geospatial",
    "section": "Labels",
    "text": "Labels\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_label(aes(x = X, y = Y, label = COUNTY)) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#subset",
    "href": "posts/06_geospatial/06_geospatial.html#subset",
    "title": "6: Geospatial",
    "section": "Subset",
    "text": "Subset\n\nnj_label_subset &lt;- nj_counties |&gt;\n  filter(COUNTY %in% c(\"MERCER\", \"SUSSEX\", \"SALEM\"))\n\nnj_counties |&gt;\n  ggplot() +\n  geom_sf(aes(fill = COUNTY)) +\n  geom_label(aes(x = X, y = Y, label = COUNTY),\n             data = nj_label_subset,\n             size = 2) +\n  labs(title = \"Counties of New Jersey\",\n       subtitle = \"categorical data\",\n       caption = \"SML 201\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06_geospatial/06_geospatial.html#per-capita",
    "href": "posts/06_geospatial/06_geospatial.html#per-capita",
    "title": "6: Geospatial",
    "section": "Per Capita",
    "text": "Per Capita\n\nnj_df &lt;- nj_df |&gt;\n  left_join(nj_pop, by = c(\"COUNTY\" = \"county\"))\n\n\nnj_df &lt;- nj_df |&gt;\n  mutate(unemployed_per_cap = number_unemployed / population)\n\n\nnj_df |&gt;\n  ggplot() +\n  geom_sf(aes(fill = unemployed_per_cap)) +\n  labs(title = \"New Jersey Unemployment\",\n       subtitle = \"per capita\",\n       caption = \"SML 201\") +\n  scale_fill_distiller(palette = \"OrRd\",\n                       direction = 1) +\n  theme_minimal()"
  }
]